#!/bin/bash
#
# Copyright (c) 2015 EMC Corporation
# All Rights Reserved
#

# ==============================================================
# Uncomment the below line to get tracing output for this script
#set -x

#Configuration file to be used
BASEDIR=$(dirname $0)
CONFIG_FILE=${1}

Usage()
{
    echo 'Usage: sanity <configuration_file> <bourne_ip>|<[bourne_ipv6]> {all | isilon | vplex | vplexexport | vplexsnap | vnxblock | ingestblock | vnxblock_flex_varray | netapp | netappc | recoverpoint | xtremio | srdf |
 vnxfile | datadomainfile | vnxfile_flex_varray | vmaxblock | hds | vmaxblock_flex_varray | combined_block | blocksnapshot | blockmirror | full_copy | blockconsistencygroup | ecs | init | quick |
 errorhandling | vnxe | security | syssvc | audit | monitor | vdc | catalog | recovery | backuprestore} [local|ldap] [<timeslot>] | sanzoning'
    echo 'E.g.:  sanity conf/sanity.conf 137.69.169.21 all'
    echo 'E.g.:  sanity ~/.sanity/sanity.conf 137.69.169.21 isilon'
    echo 'Note: IPv6 needs to be square bracket surrounded. E.g.:  sanity [2620:0:170:2842::180] security'
    echo 'If the env variable DISCOVER_SAN=1 is set: discover and use SAN networking.'
    echo 'E.g.:  sanity conf/sanity.conf 137.69.169.21 audit ldap 2006-03-23T12[:23]'
    exit 2
}

toLower()
{
    echo "$(echo ${1} | tr '[:upper:]' '[:lower:]')"
}

toUpper()
{
    echo "$(echo ${1} | tr '[:lower:]' '[:upper:]')"
}

if [ -f $CONFIG_FILE ]; then
    echo "Using Configuration file $CONFIG_FILE for sanity"
    source ${1}
else
    echo "Configuration file $CONFIG_FILE not found"
    Usage
fi


[ $# -ge 3 ] || Usage
date

init_env_var()
{
    [[ -n "${TEST_APPLIANCE}" ]] && return
    remote_ip="${1}"
    [[ "${remote_ip}" == "localhost" ]] && export TEST_APPLIANCE=no && return 
    local_ip=`ifconfig ${ethdev} 2>/dev/null|awk '/inet addr:/ {print $2}' | sed 's/addr://'`
    [[ "${local_ip}" == "${remote_ip}" ]] && export TEST_APPLIANCE=no && return
    local_fqdn=$(nslookup ${local_ip} | sed -n  's/.*arpa.*name = \(.*\)/\1/p')
    [[ "${local_fqdn%.*}" == "${remote_ip}" ]] && export TEST_APPLIANCE=no && return    
}
init_env_var "${2}"

# Use the environment variable DISCOVER_SAN to determine if 
# SAN Networking should be discovered, thereby allowing zoning to be
# done for the exports.
DISCOVER_SAN=${DISCOVER_SAN:-0}
echo "DISCOVER_SAN: " $DISCOVER_SAN

# By default, we're not running quick sanity
QUICK=${QUICK:-0}

# The token file name will have a suffix which is this shell's PID
# It will allow to run the sanity in parallel
export BOURNE_TOKEN_FILE=${BOURNE_TOKEN_FILE:-"/tmp/token$$.txt"}
BOURNE_SAVED_TOKEN_FILE="/tmp/token_saved.txt"

PATH=$BASEDIR:/bin:/usr/bin:/usr/local/bin
OBJECTORFILENAME="/tmp/testipc.txt"
BOURNE_IPS=${2:-$BOURNE_IPADDR}
HOSTNAME=$BOURNE_IPADDR
IFS=',' read -ra BOURNE_IP_ARRAY <<< "$BOURNE_IPS"
BOURNE_IP=${BOURNE_IP_ARRAY[0]}
IP_INDEX=0

# By default, we're not running quick sanity
QUICK=0

SS=${3}
if [ ${SS} = "vplex" ]; then
        VPLEX_QUICK_PARAM=${4:-'normal'}
	AUTH=${5:-ldap}
	EXTRA_PARAM=${6}
elif [ ${SS} = "recoverpoint" ]; then
        RP_QUICK_PARAM=${4:-'quick'}
	AUTH=${5:-ldap}
	EXTRA_PARAM=${6}
elif [ ${SS} = "vdc" ]; then
        VDC_DEFAULT_ENDPOINT=vdc_dummy_endpoint
        VDC_ENDPOINT_B=${4:-$VDC_DEFAULT_ENDPOINT}
        VDC_ENDPOINT_C=${5:-$VDC_DEFAULT_ENDPOINT}
        if [ -n "${BOURNE_IPV6_MODE}" ]; then
            AUTH=ipv6
        else
            AUTH=ldap
        fi
        echo AUTH=$AUTH
else

	# By default, we're not running quick sanity
	if [ ${SS} = "quick" ]; then
 	    QUICK=1
    else
        QUICK=0
    fi
    echo "QUICK: " $QUICK

    AUTH=${4:-ldap}
    EXTRA_PARAM=${5}
fi

[ -z "${AUTH}" ] && AUTH=${4:-ldap}

case $SS in
    all|isilon|vplex|vplexexport|vplexsnap|netapp|netappc|recoverpoint|srdf|vnxfile|datadomainfile|vnxfile_flex_varray|vnxblock|vnxblock_flex_varray|hds|xtremio|vmaxblock|ingestblock|vmaxblock_flex_varray|combined_block|syssvc|blocksnapshot|blockmirror|full_copy|blockconsistencygroup|ecs|security|monitor|audit|ui|init|quick|errorhandling|vdc|vnxe|recovery|backuprestore|sanzoning)
    ;;

    # These tests are handled by sanity integration tests written with the code
    catalog)
    echo "Running external sanity: ./gradlew -q :sanity:catalog -DSANITY_IP=${BOURNE_IP}"
    (cd $(dirname $0)/../../..; ./gradlew -q :sanity:catalog -DSANITY_IP=${BOURNE_IP})
    exit 0
    ;;

    *)
    Usage
esac

# Webstorage parameters taken from the environment if set.
WS_SETUP_FILESHARE_COUNT=${WS_SETUP_FILESHARE_COUNT:-1}
WS_SETUP_ISILON_FS_SIZE=${WS_SETUP_ISILON_FS_SIZE:-104857600000}
WS_SETUP_VNX_FS_SIZE=${WS_SETUP_VNX_FS_SIZE:-104857600000}
WS_SETUP_NETAPP_FS_SIZE=${WS_SETUP_NETAPP_FS_SIZE:-53687091200}
WS_SETUP_NFS_FS_SIZE=${WS_SETP_NFS_FS_SIZE:-10240000}
WS_SETUP_MODE=0
WS_SETUP_COS=""
WS_SETUP_BUCKETS=""
WS_SETUP_GEO_REPGROUP=${WS_SETUP_GEO_REPGROUP:-""}
if [ ${WS_SETUP+x} ] ; then
    WS_SETUP_MODE=1
    echo "WS_SETUP mode is enabled, output file=${WS_SETUP}"
fi

case $AUTH in
    local|ldap)
    ;;
    ipv6)
        export BOURNE_IPV6_MODE="YES"
	ISI_IP="2620:0:170:2842::6199"
	ISI_SN="6805ca0e0736b7cf7b52af25f8f67c8e6d35"
	VNXF_IP="2620:0:170:2860::60"
	VNXDM_IP="2620:0:170:2860::60"
	VNXF_SN="APM00112400154"
	NETAPPF_IP="2620:0:170:2842:2a0:98ff:fe3d:bab4"
	NETAPPDM_IP="2620:0:170:2842:2a0:98ff:fe3d:bab4"
	NETAPPF_SN="700001322607"
	VMAX_SMIS_IP="2620:0:170:2842:250:56ff:fe91:56af"
	VNX_SMIS_IP="2620:0:170:2842:250:56ff:fe91:56af"
	VNXB_SN="APM00112900837"
	VMAX_SN="000195701430"
	VPLEX_VMAX_SMIS_IP="2620:0:170:2842:250:56ff:fe91:56af"
	VPLEX_VNX1_SMIS_IP="2620:0:170:2842:250:56ff:fe91:56af"
	VPLEX_VMAX_NATIVEGUID="000195701430"
	VPLEX_VNX1_NATIVEGUID="APM00112900837"
	VPLEX_IP="2620:0:170:2842::208"
	VPLEX_GUID="VPLEX+FNM00130900344:FNM00131100242"
	HDS_PROVIDER="lglap095.lss.emc.com"
	HDS_PROVIDER_IP="2620:0:170:2858::95";;
    *)
    Usage
esac

ethdev=`/sbin/ifconfig | grep Ethernet | head -1 | awk '{print $1}'`
if [ "$ethdev" = "" ] ; then
   ethdev=eth0
fi

# COP-16713: Sometimes a linux ethernet interface is more than 9 characters
#            However, ifconfig will only show the first 9.  If the name is 
#            long, run "ip link show", which will give us the full name.
if [ ${#ethdev} > 8 ] ; then
    ethdev=`ip link show | grep ${ethdev} | awk '{print $2}' | awk -F: '{print $1}'`
fi

macaddr=`/sbin/ifconfig ${ethdev} | /usr/bin/awk '/HWaddr/ { print $5 }'`
if [ "$macaddr" = "" ] ; then
    macaddr=`/sbin/ifconfig en0 | /usr/bin/awk '/ether/ { print $2 }'`
fi

seed=`date "+%H%M%S%N"`
seed2b=`printf "%02X" $$ | cut -b1-2`
hostseed=`echo ${macaddr} | awk -F: '{print $5$6}'`
hostbase=host${hostseed}
export BOURNE_API_SYNC_TIMEOUT=700

#
# Zone configuration
#
NH=nh
NH2=nh2
NH3=nh3
FC_ZONE_A=fctz_a
FC_ZONE_B=fctz_b
IP_ZONE=iptz
IP_ZONE2=iptz2
IP_ZONE3=iptz3

FCTZ_A=$NH/$FC_ZONE_A
FCTZ_B=$NH/$FC_ZONE_B

#
# Vdc Configuration
#
VDC_ENDPOINT_B_NAME=vdc_name_B_$$
VDC_ENDPOINT_B_SECRETKEY=
VDC_ENDPOINT_B_CERTCHAIN=
VDC_ENDPOINT_B_ID=
VDC_TEST_PROJECT=vdc_project_$$
VDC_TEST_DISCONN_RECONN_PROJECT=disrecon_vdc_project_$$
VDC_TEST_REMOVE_PROJECT=testremove_vdc_project_$$

#
# Recovery Configuration
#
RECOVERY_CORRUPTED_NODE_IP=

#
# bourne tenant & project configuration
#
SHORTENED_HOST=`hostname`
: ${TENANT=$SHORTENED_HOST}
: ${PROJECT=sanity}

SVCUSER=svcuser

#Local ldap server config.
LOCAL_LDAP_AUTHN_NAME='Local_Ldap_Provider'
LOCAL_LDAP_AUTHN_MODE='ldap'
LOCAL_LDAP_AUTHN_URLS='ldap://'${LOCAL_LDAP_SERVER_IP}
LOCAL_LDAP_AUTHN_DOMAINS=VIPRSANITY.COM
LOCAL_LDAP_AUTHN_SEARCH_BASE='ou=ViPR,dc=viprsanity,dc=com'
LOCAL_LDAP_AUTHN_MANAGER_DN='cn=manager,dc=viprsanity,dc=com'
LOCAL_LDAP_AUTHN_MANAGER_PWD=secret
LOCAL_LDAP_AUTHN_SEARCH_FILTER='uid=%U'
LOCAL_LDAP_AUTHN_AUTHN_GROUP_ATTR=CN
LOCAL_LDAP_AUTHN_PROVIDER_NEWNAME='Local_Ldap_Provider_Updated_Name'
LOCAL_LDAP_AUTHN_WHITELIST='ldapViPR*'
LOCAL_LDAP_AUTHN_SEARCH_SCOPE=SUBTREE
LOCAL_LDAP_AUTHN_GROUP_OBJECT_CLASSES='groupOfNames,groupOfUniqueNames,posixGroup,organizationalRole'
LOCAL_LDAP_AUTHN_GROUP_MEMBER_ATTRIBUTES='member,uniqueMember,memberUid,roleOccupant'

#Local ldap server user and group config.
LOCAL_LDAP_VIPR_USER_GROUP='  ldapViPRGroup_RootTenantOuter    '
LOCAL_LDAP_TENANT_ATTRIBUTE_KEY=title
LOCAL_LDAP_TENANT_ATTRIBUTE_ROOT_TENANT_VALUE=RootTenantUser
LOCAL_LDAP_TENANT_ATTRIBUTE_ROOT_SUBTENANT1_VALUE=SubTenant1User
LOCAL_LDAP_TENANT_ATTRIBUTE_ROOT_SUBTENANT2_VALUE=SubTenant2User
LOCAL_LDAP_SUPERUSER_USERNAME=ldapViPRUser1@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_SUPERUSER_PASSWORD=secret
LOCAL_LDAP_GROUPUSER_USERNAME=ldapViPRUser2@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_GROUPUSER_PASSWORD=secret
LOCAL_LDAP_TENANTADMIN_USERNAME=ldapViPRUser3@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_TENANTADMIN_PASSWORD=secret
LOCAL_LDAP_TENANT_USERNAME=ldapViPRUser4@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_TENANT_PASSWORD=secret
LOCAL_LDAP_TENANT_PROJECT_ADMINS_GROUP=ldapViPRGroup_RootTenantProjectAdmins@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_PROJECT_ADMIN_USERNAME=ldapViPRUser5@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_PROJECT_ADMIN_PASSWORD=secret
LOCAL_LDAP_MAXGROUPSUSER_USERNAME=ldapViPRUser5@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_MAXGROUPSUSER_PASSWORD=secret
LOCAL_LDAP_USER_USERNAME_1=ldapViPRUser6@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_USER_PASSWORD_1=secret
LOCAL_LDAP_USER_USERNAME_2=ldapViPRUser7@${LOCAL_LDAP_AUTHN_DOMAINS}
LOCAL_LDAP_USER_PASSWORD_2=secret


#Secure ldap server config.
LOCAL_SECURE_LDAP_AUTHN_NAME='Local_Secure_Ldap_Provider'
LOCAL_SECURE_LDAP_AUTHN_URLS='ldaps://'${LOCAL_LDAP_SERVER_IP}
LOCAL_SECURE_LDAP_AUTHN_DOMAINS=SECURE.VIPRSANITY.COM
LOCAL_SECURE_LDAP_AUTHN_SEARCH_BASE='dc=secure,dc=viprsanity,dc=com'
LOCAL_SECURE_LDAP_AUTHN_MANAGER_DN='uid=secureManagerDN,dc=secure,dc=viprsanity,dc=com'
LOCAL_SECURE_LDAP_AUTHN_MANAGER_PWD=secret
LOCAL_SECURE_LDAP_AUTHN_WHITELIST='secureViPRGroup*'

#Secure ldap server user and group config.
LOCAL_SECURE_LDAP_TENANT_ATTRIBUTE_KEY=title
LOCAL_SECURE_LDAP_TENANT_ATTRIBUTE_VALUE=SecureViPRUser
LOCAL_SECURE_LDAP_USER_USERNAME=secureLdapViPRUser1@${LOCAL_SECURE_LDAP_AUTHN_DOMAINS}
LOCAL_SECURE_LDAP_USER_PASSWORD=secret
LOCAL_SECURE_LDAP_USER_USERNAME_WITH_SPACES='       secureLdapViPRUser1@'${LOCAL_SECURE_LDAP_AUTHN_DOMAINS}'       '


#
# cos configuration
#
COS_VNXFILE=cosvnxf
COS_VNXE=cosvnxe
COS_ISIFILE=cosisi
COS_NETAPP=cosnetappf
COS_NETAPPC=cosnetappcf
COS_DDFILE=cosdatadomainf
COS_VNXBLOCK=cosvnxb
COS_VNXBLOCK_FC=cosvnxb_fc
COS_VNXBLOCK_ISCSI=cosvnxb_iscsi
COS_VNXBLOCK_THIN=cosvnxb_thin
COS_VNXBLOCK_THICK=cosvnxb_thick
COS_VMAXBLOCK=cosvmaxb
COS_VMAXBLOCK_FC=cosvmaxb_fc
COS_VMAXBLOCK_ISCSI=cosvmaxb_iscsi
COS_VMAXBLOCK_THIN=cosvmaxb_thin
COS_VMAXBLOCK_THICK=cosvmaxb_thick
COS_VMAXBLOCK_SRDF_SOURCE=vpool_srdf_source
COS_VMAXBLOCK_SRDF_TARGET=vpool_srdf_target
COS_RP=cos_rp
COS_RP_BASE=cos_rp_base
COS_HDS=coshds
COS_VNXEBLOCK_CG=cosvnxe_cg
COS_VNXEBLOCK_FC=cosvnxe_fc
COS_VNXEBLOCK_ISCSI=cosvnxe_iscsi
COS_ECS=ecs_vpool

#
# Isilon configuration
#
ISI_DEV=isilon_device
ISI_SMARTCONNECT_IP=${ISI_IP}
ISI_NATIVEGUID=ISILON+$ISI_SN
ISI_SMBFILESHARE1=smbfileshare1$(date +%Y%m%d%H%M%S) 
ISI_SMBFILESHARE2=smbfileshare2$(date +%Y%m%d%H%M%S)
ISI_SMBSNAPSHARE1=smbsnapshare1$(date +%Y%m%d%H%M%S)
ISI_SMBSNAPSHARE2=smbsnapshare2$(date +%Y%m%d%H%M%S) 

#
# ECS configuration
#
ECS_DEV=ecs_device
ECS_NATIVEGUID=ECS+$ECS_SN
ECS_SOFT_QUOTA=1024
ECS_HARD_QUOTA=2048
ECS_BUCKET=bucket-${RANDOM}

#
# VNX file device configuration
#
VNXF_DEV=vnxf_device
VNXF_NATIVEGUID=CELERRA+$VNXF_SN
VNXF_SMBFILESHARE1=smbfileshare1$(date +%Y%m%d%H%M%S) 

#
# XtremIO config
#

XTREMIO=xtremio4
XTREMIOVOL=volXtremIO
XTREMIO_NATIVEGUID=XTREMIO+$XTREMIO_SN
XTREMIO_COS_FC=xtremioTest3
XTREMIO_INGEST_HOST=ingesthost.lss.emc.com
XTREMIO_INGEST_HOST_LABEL=ingesthost

# XtremIO 2nd setup
XTREMIO2=xtremio2
XTREMIO2_NATIVEGUID=XTREMIO+$XTREMIO2_SN

#
# Netapp file device configuration
#
NETAPPF_DEV=netapp_device
NETAPPF_NATIVEGUID=NETAPP+$NETAPPF_SN
NETAPPF_SMBFILESHARE1=smbfileshare1$(date +%Y%m%d%H%M%S) 
NETAPPF_SMBFILESHARE2=smbfileshare2$(date +%Y%m%d%H%M%S)
NETAPPF_SMBSNAPSHARE1=smbsnapshare1$(date +%Y%m%d%H%M%S)
NETAPPF_SMBSNAPSHARE2=smbsnapshare2$(date +%Y%m%d%H%M%S)  

#
# NetApp Cluster Mode device configuration
#
NETAPPCF_DEV=netappc_device
NETAPPCF_NATIVEGUID=NETAPPC+$NETAPPCF_SN
NETAPPCF_SMBFILESHARE1=smbfileshare1$(date +%Y%m%d%H%M%S)
NETAPPCF_SMBFILESHARE2=smbfileshare2$(date +%Y%m%d%H%M%S)
NETAPPCF_SMBSNAPSHARE1=smbsnapshare1$(date +%Y%m%d%H%M%S)
NETAPPCF_SMBSNAPSHARE2=smbsnapshare2$(date +%Y%m%d%H%M%S)

#
# VNXE  device configuration
#
VNXE_DEV=vnxe_device
VNXE_NATIVEGUID=VNXE+$VNXE_SN
VNXE_SMBFILESHARE1=cifs1$(date +%Y%m%d%H%M%S) 

#
# DataDomain file device configuration
#
DATADOMAINF_DEV=datadomainf_device
DATADOMAINF_PROVIDER=datadomain_provider
DATADOMAINF_PROVIDER_INTERFACE=ddmc
DATADOMAINF_NATIVEGUID=$DATADOMAINF_ID
DATADOMAINF_SMBFILESHARE1=smbfileshare1$(date +%Y%m%d%H%M%S)
DATADOMAINF_SMBFILESHARE2=smbfileshare2$(date +%Y%m%d%H%M%S)

#
# SRDF Configuration
#
SRDF_VOLUME=srdfSanity-${HOSTNAME}-${RANDOM}

#
# RecoverPoint configuration
#
RP_SYSTEM_TYPE=rp
RP_REMOVE_BAD_CHARS_HOSTNAME=${HOSTNAME//[^a-zA-Z0-9]/}
RP_MODIFIED_HOSTNAME=${RP_REMOVE_BAD_CHARS_HOSTNAME:0:8}
RP_SANITY_RANDOM=$((RANDOM % 999))

RP_VOLUME=rpSanity-${RP_MODIFIED_HOSTNAME}-${RP_SANITY_RANDOM}-vol
RP_CONSISTENCY_GROUP=rpSanity-${RP_MODIFIED_HOSTNAME}-${RP_SANITY_RANDOM}-cg

RP_VPLEX_VOLUME=rpvpSanity-${RP_MODIFIED_HOSTNAME}-${RP_SANITY_RANDOM}-vol
RP_VPLEX_CONSISTENCY_GROUP=rpvplexSanity-${RP_MODIFIED_HOSTNAME}-${RP_SANITY_RANDOM}-cg

RP_METROPOINT_VOLUME=mpSanity-${RP_MODIFIED_HOSTNAME}-${RP_SANITY_RANDOM}-vol
RP_METROPOINT_CONSISTENCY_GROUP=mpSanity-${RP_MODIFIED_HOSTNAME}-${RP_SANITY_RANDOM}-cg

RP_EXPORT_GROUP=rpSanity-${RP_MODIFIED_HOSTNAME}-${RP_SANITY_RANDOM}
RP_EXPORT_GROUP_HOST=host${hostseed}.sanity.com

#
# Configuration for Simulator
#
RP_PROVIDER_SIMULATOR_IP=$SIMULATOR_IP
SIMULATOR_CISCO_MDS_IP=$SIMULATOR_IP
RP_SIMULATOR_IP=$SIMULATOR_IP
RP_SIMULATOR=rp-sim
PROVIDER_SIMULATOR=provider-sim
FABRIC_SIMULATOR=fabric-sim
SIMULATOR_VSAN_11=VSAN_11
SIMULATOR_VSAN_12=VSAN_12
VPLEX_PROVIDER_SIMULATOR=$PROVIDER_SIMULATOR
VPLEX_PROVIDER_SIMULATOR_IP=$SIMULATOR_IP
VPLEX_SIMULATOR=vplex-sim

#
# Full copy configuration
#
FULL_COPY_VOLUME=full-copy-test-${HOSTNAME}-${RANDOM}

#
# MIRROR (VMAX) block device configuration
#
COS_MIRROR=cosmirror
COS_MIRROR_WITH_OPTIONAL=cosmirror_with_optional
COS_MIRROR_WITH_2_MIRRORS=cosmirror_max_2
COS_MIRROR_BEFORE_CHANGE=cosmirror_before_change
COS_MIRROR_AFTER_CHANGE=cosmirror_after_change
COS_MIRROR_VNX=cosmirror_vnx
COS_VMAX_CG_MIRROR=cosvmax_cg_mirror

#
# Export group configuration
#
VNX_VOLUME=VnxSanityVol-${HOSTNAME}-${RANDOM}
VNX_META_VOLUME=VnxSanityMeta-${HOSTNAME}-${RANDOM}
VNXEXPORT_GROUP=VnxExp${RANDOM}
VNXEXPORT_GROUP_HOST=host.vnx.export${seed}
VMAX_VOLUME=VmaxSanity-${HOSTNAME}-${RANDOM}
VMAX_META_VOLUME=VmaxSanityMeta-${HOSTNAME}-${RANDOM}
VMAXEXPORT_GROUP=VmaxExp${RANDOM}
VMAXEXPORT_GROUP_HOST=host.vnx.export${seed}
VMAX_VNXEXPORT_GROUP=VmaxVnxExp-${RANDOM}
VMAX_VNXEXPORT_GROUP_HOST=vmax.vnx.export${seed}
XTREMIOEXPORT_GROUP_HOST=host.xtremio.export${seed}
XTREMIOEXPORT_GROUP=XtremIOExp${RANDOM}
BLOCKEXPORT_GROUP=BlockSanityExportGroup-${HOSTNAME}-${RANDOM}
MIRROR_VOLUME=VmaxMirror-${HOSTNAME}-${RANDOM}
MIRROR_VOLUME_VNX=VnxMirror-${HOSTNAME}-${RANDOM}
CONSISTENCY_GROUP_SRDF=${RANDOM}
CONSISTENCY_GROUP=consistency-group-`date +%s | cut -c5-10`
CONSISTENCY_GROUP_SNAPSHOT=group-snapshot-`date +%s | cut -c5-10`
VNX_COS_GROUP=vnx-cos-group-`date +%s | cut -c5-10`
VMAX_COS_GROUP=vmax-cos-group-`date +%s | cut -c5-10`

#
# fileshare tests configuration
#
# Min 1GB FS
FS_SIZE=1073741824
FS_SIZEMB=1024MB
# Expand size 1.5GB FS
FS_EXPAND_SIZE=1610612736
FSEXP_RO_EPS="www.ferrari.com www.porsche.com"
FSEXP_RW_EPS="www.lexus.com www.infiniti.com www.acura.com"
FSEXP_SHARED_VARRAY_RW_EPS="client1.emc.com client2.emc.com"
FSEXP_ROOT_EPS="www.honda.com"
FSEXP1="www.ford.com"
FSEXP2="www.gmc.com"
FSEXP3="www.pontiac.com"
FSEXP4="www.kia.com"
FSEXP_DEFAULT_EPS="$FSEXP1 $FSEXP2 $FSEXP3"
SNAPEXP_DEFAULT_EPS="www.emc.com www.abc.com www.amazon.com"
FS_VNXE_SIZE=2000000000
FS_VNXE_EXPAND_SIZE=3000000000

# Alternate configuration file for alternate hardware/variables
ALTERNATE_CONFIG_FILE=myhardware.conf
if [ -f ${ALTERNATE_CONFIG_FILE} ]
then
   source ${ALTERNATE_CONFIG_FILE}
fi

pwwn()
{
    idx=$1
    echo 50:${macaddr}:${idx}
}

nwwn()
{
    idx=$1
    echo 51:${macaddr}:${idx}
}

wwnIdx() {
    i=$1
    j=$2
    k=$(($i - 1))
    k=$((2 * $k))
    k=$(($j + $k))
    echo $k
}

#
# block tests configuration
#
BLK_SIZE=1073741824
BLK_SIZE_EXPAND=2147483648 # 2GB
BLK_SIZE_EXPAND_2=2462056448 # 2GB + 300MB
BLK_SIZE_EXPAND_3=2566914048 # 2GB + 400MB
BLK_LUN1=1
BLK_LUN2=2
BLK_LUN3=3
BLK_CLIENT_FC=`pwwn ${seed2b}`
BLK_CLIENT_FC_NODE=`nwwn ${seed2b}`
HOSTNAME=`hostname`
BLK_CLIENT_iSCSI=iqn.2010-01.com.emc.snafu-${HOSTNAME}_${seed}
BLK_HOSTID=sanity-host-${HOSTNAME}-${seed}

export BOURNE_IPADDR="$BOURNE_IP"

source sanity_utils

# search configuration
TAG=$(tr -dc A-Za-z0-9_ < /dev/urandom | head -c 4)
SEARCH_PREFIX=$(echo $TAG|head -c 2)

#
# run commands and check for exit status
#
run()
{
    cmd=$*
    echo === $cmd
    $cmd 2>&1
    status=$?
    set_undo $cmd

    if [ $status -ne 0 ] ; then
        echo '**********************************************************************'
        echo $cmd failed
        echo '**********************************************************************'
        exit $status
    fi
}

balance()
{
    cmd=$*
    echo $cmd
    $cmd --ip=${BOURNE_IP_ARRAY[$IP_INDEX]}
    if [ $((IP_INDEX+1)) -ge ${#BOURNE_IP_ARRAY[@]} ]; then 
        IP_INDEX=0
    else
        IP_INDEX=$((IP_INDEX+1))
    fi       
}

#
# Creates a neighborhood
# Sets up one IP transport zone and one FC transport zone
#
zone_setup()
{
    # do this only once
    neighborhood show $NH  &> /dev/null && return $?

    neighborhood create $NH
    if [ "$EXTRA_PARAM" = "search" ] ; then
        neighborhood search $(echo $NH | head -c 2)
        neighborhood tag $NH $TAG
        neighborhood search $SEARCH_PREFIX --tag true
    fi

    neighborhood create $NH2

    transportzone create $IP_ZONE $NH --type IP
    if [ "$EXTRA_PARAM" = "search" ] ; then
        transportzone search $(echo $IP_ZONE | head -c 2)
        transportzone tag $NH/$IP_ZONE $TAG
        transportzone search $SEARCH_PREFIX --tag true
    fi

    # Set the object transport zone
    # Cleanup just in case... Ignore errors because grep will exit with non-zero if
    # it doesn't match anything (which is the case if the object transport zone
    # isn't set).
    trap - ERR

    transportzone add $NH/$IP_ZONE $FSEXP1
    transportzone add $NH/$IP_ZONE $FSEXP2
    transportzone add $NH/$IP_ZONE $FSEXP3


    #
    # set up zone for cisco switch simulator
    #
    if [ $QUICK -eq 1 ]; then
        cisco_mds_quick_setup_once
    elif [ $DISCOVER_SAN -eq 1 ]; then
        brocade_setup_once
    else
        transportzone create $FC_ZONE_A $NH --type FC
        transportzone create $FC_ZONE_B $NH --type FC
        transportzone add    $NH/$FC_ZONE_A $BLK_CLIENT_FC
    fi

    for i in A1 A2 A3 A4 A5 A6 A7 A8 C1 C2 C3 C4 C5 C6 C7 C8
    do
        wwn=`pwwn $i`
    
        echo "Adding $wwn to zone $FCTZ_A..."
	transportzone add $FCTZ_A $wwn
    done


    for i in B1 B2 B3 B4 B5 B6 B7 B8 D1 D2 D3 D4 D5 D6 D7 D8
    do
        wwn=`pwwn $i`
        echo "Adding $wwn to zone $FCTZ_B..."
        transportzone add $FCTZ_B $wwn
    done

}

brocade_setup_once() 
{
    # Do once
    nsys=`networksystem list | wc -l`
    [ "$nsys" -gt 0 ] && return;

    #Discover the Brocade SAN switch.
    echo "Discovering brocade ..."
    networksystem create $BROCADE_NETWORK brocade --smisip $BROCADE_IP --smisport 5988 --smisuser $BROCADE_USER --smispw $BROCADE_PW --smisssl false
    sleep 30

    transportzone listall
    transportzone assign FABRIC_losam082-fabric $NH
    transportzone assign FABRIC_vplex154nbr2 $NH2
    VPLEX_TZ1=$NH/FABRIC_losam082-fabric
    VPLEX_TZ2=$NH2/FABRIC_vplex154nbr2
    FC_ZONE_A=FABRIC_losam082-fabric
    FC_ZONE_B=FABRIC_vplex154nbr2
    FCTZ_A=$NH/$FC_ZONE_A
    FCTZ_B=$NH2/$FC_ZONE_B
}

cisco_mds_quick_setup_once()
{
    # Do once - Discover Cisco MDS simulator switch
    echo "Discover Cisco MDS simulator switch"
    networksystem create CiscoMdsSimulator  mds --devip $SIMULATOR_CISCO_MDS --devport 22 --username $SIMULATOR_CISCO_MDS_USER --password $SIMULATOR_CISCO_MDS_PW
   
    transportzone listall

#    VPLEX_TZ1=$NH/FABRIC_losam082-fabric
#    VPLEX_TZ2=$NH2/FABRIC_vplex154nbr2
    FC_ZONE_A=VSAN_11
    FC_ZONE_B=VSAN_12
    FCTZ_A=$NH/$FC_ZONE_A
    FCTZ_B=$NH2/$FC_ZONE_B


    transportzone assign VSAN_11 $NH
    transportzone assign VSAN_12 $NH

#   add ports to VSAN_11
    transportzone add $FCTZ_A 51:00:50:56:9F:01:3B:A1
    transportzone add $FCTZ_A 51:00:50:56:9F:01:3B:A2
    transportzone add $FCTZ_A 51:00:50:56:9F:01:3B:A3
    transportzone add $FCTZ_A 51:00:50:56:9F:01:3B:A4
}


#
# Setup clusters, hosts, etc.
# Setup two clusters with 2 hosts each. Each host has initiators
# in transport zone A and B
#
host_setup()
{
    # do this only once
    cluster show $TENANT/sanityCluster1 &> /dev/null && return $?

    echo "Setup hosts and clusters on for $TENANT started"
    proj=$PROJECT
    tenant=$TENANT

    for i in 1 2
    do
        cluster=sanityCluster$i
        cluster create $cluster $tenant --project $proj
        j=1
        while [ $j -lt 3 ]
        do
            host=$hostbase$tenant$i$j
            k=`wwnIdx $i $j`
            echo $k
            nwwn=`nwwn $i$j`
            pwwn1=`pwwn A$k`
            pwwn2=`pwwn B$k`
            pwwn3=`pwwn C$k`
            pwwn4=`pwwn D$k`
            echo  ${pwwn1}
            hosts create $host $tenant Windows ${host}.lss.emc.com --port 8111 --username user --password 'password' --osversion 1.0 --cluster ${tenant}/${cluster}
            initiator create $host FC ${pwwn1} --node ${nwwn}
            initiator create $host FC ${pwwn2} --node ${nwwn}
            initiator create $host FC ${pwwn3} --node ${nwwn}
            initiator create $host FC ${pwwn4} --node ${nwwn}

	    #
	    # create host initiator for quick sanity
	    #
	    if [ $QUICK -eq 1 ]; then
        	initiator create $host FC 51:00:50:56:9F:01:3B:A$k  --node 50:00:50:56:9F:01:3B:$i$j
            fi

            j=$(( $j + 1 ))
        done
    done

    echo "Setup hosts and clusters on for $TENANT ended"
}


#
# create a tenant and project for running the sanity tests
#
tenant_setup()
{
    security add_authn_provider $LOCAL_LDAP_AUTHN_MODE $LOCAL_LDAP_AUTHN_URLS $LOCAL_LDAP_AUTHN_MANAGER_DN $LOCAL_LDAP_AUTHN_MANAGER_PWD $LOCAL_LDAP_AUTHN_SEARCH_BASE $LOCAL_LDAP_AUTHN_SEARCH_FILTER $LOCAL_LDAP_AUTHN_AUTHN_GROUP_ATTR "$LOCAL_LDAP_AUTHN_NAME" $LOCAL_LDAP_AUTHN_DOMAINS "$LOCAL_LDAP_AUTHN_WHITELIST" $LOCAL_LDAP_AUTHN_SEARCH_SCOPE --group_object_classes "$LOCAL_LDAP_AUTHN_GROUP_OBJECT_CLASSES" --group_member_attributes "$LOCAL_LDAP_AUTHN_GROUP_MEMBER_ATTRIBUTES"
    security get_authn_provider "$LOCAL_LDAP_AUTHN_NAME"
    if [ "$EXTRA_PARAM" = "search" ] ; then
        security search_authn_provider $(echo $LOCAL_LDAP_AUTHN_NAME | head -c 2)
        security tag_authn_provider "$LOCAL_LDAP_AUTHN_NAME" $TAG
        security search_authn_provider $SEARCH_PREFIX --tag true
    fi

    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        tenant add_group $LOCAL_LDAP_AUTHN_DOMAINS "$LOCAL_LDAP_VIPR_USER_GROUP"
        security login $LOCAL_LDAP_GROUPUSER_USERNAME $LOCAL_LDAP_GROUPUSER_PASSWORD
        security login $SYSADMIN $SYSADMIN_PASSWORD
        tenant add_attribute $LOCAL_LDAP_AUTHN_DOMAINS $LOCAL_LDAP_TENANT_ATTRIBUTE_KEY $LOCAL_LDAP_TENANT_ATTRIBUTE_ROOT_TENANT_VALUE 
        security add_tenant_role subject_id $LOCAL_LDAP_SUPERUSER_USERNAME TENANT_ADMIN
        security add_zone_role subject_id $LOCAL_LDAP_SUPERUSER_USERNAME SYSTEM_ADMIN
        security add_zone_role subject_id $LOCAL_LDAP_SUPERUSER_USERNAME SYSTEM_MONITOR
        security add_zone_role subject_id $LOCAL_LDAP_SUPERUSER_USERNAME SECURITY_ADMIN 
        security add_zone_role subject_id $LOCAL_LDAP_SUPERUSER_USERNAME SYSTEM_AUDITOR
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
        security verify_user_roles "SYSTEM_ADMIN,SYSTEM_MONITOR,SECURITY_ADMIN,SYSTEM_AUDITOR,TENANT_ADMIN"
    fi
}

#
# create a tenant and project for running the sanity tests
#
project_setup()
{
    tenant show $TENANT &> /dev/null && return $?
    tenant create $TENANT $LOCAL_LDAP_AUTHN_DOMAINS 'OU' ${seed}
    echo "Tenant $TENANT created."
    if [ "$EXTRA_PARAM" = "search" ] ; then
        tenant search $(echo $TENANT | head -c 2)
        tenant tag "$TENANT" $TAG
        tenant search $SEARCH_PREFIX --scope $TENANT --tag true
    fi

    project show $PROJECT &> /dev/null && return $?
    project create $PROJECT --tenant $TENANT 
    if [ "$EXTRA_PARAM" = "search" ] ; then
        project search $(echo $PROJECT | head -c 2)
        project tag "$PROJECT" $TAG
        project search $SEARCH_PREFIX --scope $TENANT --tag true
    fi
}

#
# setup 3 types of cos
# -- file cos for isilon tests
# -- file cos for vnx tests
# -- block cos for vnx FC & iSCSI test
#
isilon_cos_setup()
{
    echo "setting up isilon COS"
    cos create file $COS_ISIFILE 				\
            			    --description 'CoS for Isilon' true 	\
                            --protocols NFS CIFS --max_snapshots 10 \
                            --provisionType 'Thin' \
			    --neighborhoods $NH
    ROOT_TENANT=`tenant root|tail -1`
    cos allow $COS_ISIFILE file $ROOT_TENANT
    if [ "$EXTRA_PARAM" = "search" ] ; then
        cos search $(echo $COS_ISIFILE | head -c 2) --resource_type file_vpool
        cos tag "$COS_ISIFILE" "file" $TAG
        cos search $SEARCH_PREFIX --tag true --resource_type file_vpool
    fi
}

ecs_cos_setup()
{
    echo "setting up ECS cos-vpool"
    cos create object $COS_ECS --description 'cos_vpool for ECS' true --protocols S3 --provisionType 'Thick' --neighborhoods $NH
}

vnxfile_cos_setup()
{
    echo "setting up VNX COS"
    cos create file $COS_VNXFILE 				\
			             --description 'CoS for VNX file' true \
                         --protocols NFS CIFS --max_snapshots 10    \
                         --provisionType 'Thin' \
		         --neighborhoods $NH
    ROOT_TENANT=`tenant root|tail -1`
    cos allow $COS_VNXFILE file $ROOT_TENANT
}

netapp_cos_setup()
{
    cos create file $COS_NETAPP 				\
			 --description 'CoS for NETAPP' false 	\
                         --protocols NFS CIFS --max_snapshots 10 --provisionType 'Thin' \
			 --neighborhoods $NH
    ROOT_TENANT=`tenant root|tail -1`
    cos allow $COS_NETAPP file $ROOT_TENANT
}

netappc_cos_setup()
{
    cos create file $COS_NETAPPC                                \
                         --description 'CoS for NETAPPC' false   \
                         --protocols NFS CIFS --max_snapshots 10 --provisionType 'Thin' \
                         --neighborhoods $NH
    ROOT_TENANT=`tenant root|tail -1`
    cos allow $COS_NETAPPC file $ROOT_TENANT
}

vnxe_cos_setup()
{
    echo "setting up VNXe COS"
    cos create file $COS_VNXE 				\
			             --description 'CoS for VNXe file' true \
                         --protocols NFS CIFS --max_snapshots 10    \
                         --provisionType 'Thin' \
		         --neighborhoods $NH
    ROOT_TENANT=`tenant root|tail -1`
    cos allow $COS_VNXE file $ROOT_TENANT
    
    cos create block $COS_VNXEBLOCK_CG                            \
                         --description 'CoS for VNXe block cg' true         \
                         --protocols iSCSI                   \
                         --numpaths 2 \
                         --max_snapshots 10 \
                         --system_type vnxe \
                         --provisionType 'Thin' \
                         --neighborhoods $NH \
                         --multiVolumeConsistency 
                         
    cos create block $COS_VNXEBLOCK_FC 				\
			 --description 'CoS for VNX block FC' true 	\
                         --protocols FC 			\
                         --numpaths 2 \
                         --max_snapshots 10 \
	                	 --system_type vnxe \
                         --provisionType 'Thin' \
                         --neighborhoods $NH

    cos create block $COS_VNXEBLOCK_ISCSI 			\
			 --description 'CoS for VNXe block iSCSI' true \
                         --protocols iSCSI			\
                         --numpaths 2 \
                         --max_snapshots 10 \
	                  --system_type vnxe \
                         --provisionType 'Thin' \
                         --expandable true \
                         --neighborhoods $NH
                                 
    echo "end: vnxe_cos_setup"
}

datadomainfile_cos_setup()
{
    cos create file $COS_DDFILE                \
             --description 'CoS for DATADOMAIN file' true   \
             --protocols NFS CIFS --max_snapshots 10 \
             --provisionType 'Thin' \
             --long_term_retention 'true' \
             --neighborhoods $NH
    ROOT_TENANT=`tenant root|tail -1`
    cos allow $COS_DDFILE file $ROOT_TENANT
}

vnxblock_cos_setup()
{
    echo "begin: vnxblock_cos_setup"
    if [ $QUICK -eq 0 ]; then
      cos create block $COS_VNXBLOCK 				\
			 --description 'CoS for VNX block' true 	\
                         --protocols FC iSCSI			\
                         --numpaths 2 \
                         --max_snapshots 10 \
	                 --system_type vnxblock \
                         --provisionType 'Thin' \
                         --neighborhoods $NH
    else 
      cos create block $COS_VNXBLOCK                            \
                         --description 'CoS for VNX block' true         \
                         --protocols FC                    \
                         --numpaths 2 \
                         --max_snapshots 10 \
                         --system_type vnxblock \
                         --provisionType 'Thin' \
                         --neighborhoods $NH
    fi
    
    if [ "$EXTRA_PARAM" = "search" ] ; then
        cos search $(echo $COS_VNXBLOCK | head -c 2) --resource_type block_vpool
        cos tag "$COS_VNXBLOCK" "block" $TAG
        cos search $SEARCH_PREFIX --tag true --resource_type block_vpool
    fi

    cos create block $COS_VNXBLOCK_FC 				\
			 --description 'CoS for VNX block FC' true 	\
                         --protocols FC 			\
                         --numpaths 2 \
                         --max_snapshots 10 \
	                 --system_type vnxblock \
                         --provisionType 'Thin' \
                         --neighborhoods $NH

    cos create block $COS_VNXBLOCK_ISCSI 			\
			 --description 'CoS for VNX block iSCSI' true \
                         --protocols iSCSI			\
                         --numpaths 2 \
                         --max_snapshots 10 \
	                 --system_type vnxblock \
                         --provisionType 'Thin' \
			 --neighborhoods $NH


    cos create block $COS_VNXBLOCK_THIN 				\
    			 --description 'VNX thin storage' true      \
                             --protocols FC iSCSI	    \
                             --numpaths 2 \
                             --max_snapshots 10 \
	                 --system_type vnxblock \
                             --provisionType 'Thin' \
                             --expandable true \
                         --neighborhoods $NH

    cos create block $COS_VNXBLOCK_THICK 				\
    			 --description 'VNX thick storage' true      \
                             --protocols FC iSCSI	    \
                             --numpaths 2 \
                             --max_snapshots 10 \
	                 --system_type vnxblock \
                             --provisionType 'Thick' \
                             --expandable true \
                         --neighborhoods $NH
                                 
    echo "end: vnxblock_cos_setup"
}

xtremio_cos_setup()
{
    cos create block $XTREMIO_COS_FC                          \
                         --description 'CoS for XtremIO block FC' true      \
                         --protocols FC                         \
                         --numpaths 1 \
                         --max_snapshots 10 \
                         --system_type xtremio \
                         --provisionType 'Thin' \
                         --neighborhoods $NH
    cos allow $XTREMIO_COS_FC block $TENANT  
    echo "end: xtremio_cos_setup"
}

xtremio_setup()
{
    networksystem show $BROCADE_NETWORK &> /dev/null && return $?
    networksystem create $BROCADE_NETWORK brocade --smisip $BROCADE_IP --smisport 5988 --smisuser $BROCADE_USER --smispw $BROCADE_PW --smisssl false
    discoveredsystem show $XTREMIO_NATIVEGUID &> /dev/null && return $?
    discoveredsystem create $XTREMIO xtremio $XTREMIO_IP 443 $XTREMIO_USER $XTREMIO_PASSWD --serialno=$XTREMIO_SN

    project_setup

    echo "Setup ACLs on neighborhood for $TENANT"
    run neighborhood allow $NH $TENANT
    run neighborhood allow $NH $TENANT
    run transportzone assign ${SRDF_VMAXA_VSAN} $NH
    for storageport in ${XTREMIO_INI}
    do
      run transportzone add $NH/${SRDF_VMAXA_VSAN} ${storageport}
    done
    for porta in ${XTREMIO_STORAGE_PORTS}
           do
              storageport update $XTREMIO_NATIVEGUID FC --addvarrays $NH
           done
    #Add the host ports to the network which contians the storage ports
    for i in A1 A2 A3 A4 A5 A6 A7 A8 C1 C2 C3 C4 C5 C6 C7 C8
    do
        wwn=`pwwn $i`
    
        echo "Adding $wwn to zone $SRDF_VMAXA_VSAN..."
	transportzone add $SRDF_VMAXA_VSAN $wwn
    done


    for i in B1 B2 B3 B4 B5 B6 B7 B8 D1 D2 D3 D4 D5 D6 D7 D8
    do
        wwn=`pwwn $i`
        echo "Adding $wwn to zone $SRDF_VMAXA_VSAN..."
        transportzone add $SRDF_VMAXA_VSAN $wwn
    done
    xtremio_cos_setup
}

xtremio_tests()
{
   echo 'xtremio tests invoked'
   export_xtremio_tests

}

export_xtremio_tests()
{
  storagedevice discover_all
  xtremio_block_tests  $XTREMIOEXPORT_GROUP $XTREMIOEXPORT_GROUP_HOST $XTREMIOVOL $XTREMIO_COS_FC $XTREMIOVOL $XTREMIO_COS_FC
}

xtremio_block_tests()
{
    export_name=$1
    export_host=$2
    v1=${3}1
    cos1=$4
    v2=${5}2
    cos2=$6

    run volume create ${v1} $PROJECT $NH $cos1 $BLK_SIZE --thinVolume true

    run volume create ${v2} $PROJECT $NH $cos2 $BLK_SIZE --thinVolume true

    xtremio_export_test ${export_name}1 ${v1} ${v2}

    run volume bulkget

    run volume delete $PROJECT/${v1} --wait
    run volume delete $PROJECT/${v2} --wait
}


xtremio_export_test()
{
    snap1_label=snap1-${HOSTNAME}-${RANDOM}
    vol1=$PROJECT/$2
    vol2=$PROJECT/$3
    snap1=${vol1}/${snap1_label}
    proj=$PROJECT
    tenant=$TENANT
    c=1
    h=1
    expname=$1
    hostname=$hostbase$tenant$c$h
    echo $vol1 $vol2 $proj $tenant $hostname $expname

    exp=$proj/$expname
    nwwn=`nwwn $i$j`
    k=`wwnIdx $c $h`
    pwwn1=`pwwn A$k`
    pwwn2=`pwwn B$k`
    pwwn3=`pwwn C$k`
    pwwn4=`pwwn D$k`

    run blocksnapshot create $vol1 ${snap1_label}

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi blocksnapshots $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group create $proj $expname $NH --volspec "$vol1+1,$snap1+2" --inits "$hostname/$pwwn1"
    run export_group show $exp
    run export_group update $exp --addVolspec "$vol2+3" --remVols $vol1
    run export_group show $exp
    run export_group update $exp --remInits "$hostname/$pwwn1"
    run export_group show $exp
    run export_group update $exp --remVols $vol2,$snap1
    run export_group show $exp

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi exportgroups $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group delete $exp
    run blocksnapshot delete $snap1
}


#
# SRDF
#
srdf_setup()
{
    echo 'SRDF setup'
    srdf_setup_once
    srdf_common_setup
}

srdf_setup_once()
{ 
    login_nd_configure_smtp_nd_add_licenses
    tenant_setup
    run blockconsistencygroup create $PROJECT $CONSISTENCY_GROUP_SRDF
    networksystem show $BROCADE_NETWORK &> /dev/null && return $?
    networksystem create $BROCADE_NETWORK brocade --smisip $BROCADE_IP --smisport 5988 --smisuser $BROCADE_USER --smispw $BROCADE_PW --smisssl false
    smisprovider show $SRDF_VMAXA_SMIS_DEV &> /dev/null && return $?
    smisprovider create $SRDF_VMAXA_SMIS_DEV $SRDF_VMAXA_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
    smisprovider show $SRDF_VMAXB_SMIS_DEV &> /dev/null && return $?
    smisprovider create $SRDF_VMAXB_SMIS_DEV $SRDF_VMAXB_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false

    # Adding additional array in order to test pool matching.
    # smisprovider show $VMAX_SMIS_DEV &> /dev/null && return $?
    # smisprovider create $VMAX_SMIS_DEV $VMAX_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
    smisprovider show $VNX_SMIS_DEV &> /dev/null && return $?
    smisprovider create $VNX_SMIS_DEV $VNX_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false

    storagedevice discover_all --ignore_error
    discoveredsystem show $SRDF_VMAXA_NATIVEGUID &> /dev/null && return $?
    discoveredsystem show $SRDF_VMAXB_NATIVEGUID &> /dev/null && return $?
}

srdf_common_setup() {

    #zone_setup - for CDP use NH as the protection neighborhood as well
    echo 'Adding endpoints to transport zone'
    run transportzone assign ${SRDF_VMAXA_VSAN} $NH
    # TODO: Try to get rid of this; these should be in the network already.
    for storageport in ${SRDF_VMAXA_STORAGEPORTS}
    do 
      run transportzone add $NH/${SRDF_VMAXA_VSAN} ${storageport}
    done
    echo 'Done adding endpoints to network'
    run transportzone assign ${SRDF_VMAXB_VSAN} $NH
    for storageport in ${SRDF_VMAXB_STORAGEPORTS}
    do 
      run transportzone add ${NH}/${SRDF_VMAXB_VSAN} ${storageport}
    done
    echo 'Done adding endpoints to network'

    project_setup

    echo "Setup ACLs on neighborhood for $TENANT"
    run neighborhood allow $NH $TENANT
    run neighborhood allow $NH $TENANT

    srdf_cos_setup
}

srdf_cos_setup()
{
    # Create the target first so it exists when we create the source vpool
    cos show $COS_VMAXBLOCK_SRDF_TARGET block &> /dev/null && return $?
    cos create block $COS_VMAXBLOCK_SRDF_TARGET		          \
			 --description 'Target Virtual Pool for SRDF Protection' true \
			 --protocols FC 		          \
			 --numpaths 1				  \
			 --max_snapshots 10 			  \
			 --provisionType 'Thick'	          \
			 --neighborhoods $NH                      \
                         --multiVolumeConsistency                  \
                         --system_type vmax			

    cos update block $COS_VMAXBLOCK_SRDF_TARGET --storage ${SRDF_VMAXB_NATIVEGUID}
    cos update block $COS_VMAXBLOCK_SRDF_TARGET --storage ${SRDF_VMAXA_NATIVEGUID}
    cos allow $COS_VMAXBLOCK_SRDF_TARGET block $TENANT

    cos show ${COS_VMAXBLOCK_SRDF_SOURCE}_sync block &> /dev/null && return $?
    cos create block ${COS_VMAXBLOCK_SRDF_SOURCE}_sync                 \
			 --description 'Source Virtual Pool for Synchronous SRDF Protection' true \
			 --protocols FC 		        \
			 --numpaths 1				\
			 --max_snapshots 10			\
	                 --provisionType 'Thick'	        \
                         --system_type vmax                     \
			 --neighborhoods $NH                    \
			 --srdf "${NH}:${COS_VMAXBLOCK_SRDF_TARGET}:SYNCHRONOUS"

    cos update block ${COS_VMAXBLOCK_SRDF_SOURCE}_sync --storage ${SRDF_VMAXA_NATIVEGUID}
    cos update block ${COS_VMAXBLOCK_SRDF_SOURCE}_sync --storage ${SRDF_VMAXB_NATIVEGUID}
    cos allow ${COS_VMAXBLOCK_SRDF_SOURCE}_sync block $TENANT

    cos show ${COS_VMAXBLOCK_SRDF_SOURCE}_async block &> /dev/null && return $?
    cos create block ${COS_VMAXBLOCK_SRDF_SOURCE}_async                 \
			 --description 'Source Virtual Pool for Asynchronous SRDF Protection' true \
			 --protocols FC 		        \
			 --numpaths 1				\
			 --max_snapshots 10			\
	                 --provisionType 'Thick'	        \
                         --system_type vmax                     \
			 --neighborhoods $NH                    \
                         --multiVolumeConsistency               \
			 --srdf "${NH}:${COS_VMAXBLOCK_SRDF_TARGET}:ASYNCHRONOUS"

    cos update block ${COS_VMAXBLOCK_SRDF_SOURCE}_async --storage ${SRDF_VMAXA_NATIVEGUID}
    cos update block ${COS_VMAXBLOCK_SRDF_SOURCE}_async --storage ${SRDF_VMAXB_NATIVEGUID}
    cos allow ${COS_VMAXBLOCK_SRDF_SOURCE}_async block $TENANT

}

srdf_cos_matcher_test()
{
    # Match various pool criterias, ensure SRDF vpools produce the right pools
    echo "BEGIN: Virtual Pool matching test: right now these tests are visually verified!"
    run cos match block true --protocols FC 		        \
			 --numpaths 1				\
			 --max_snapshots 10			\
	                 --provisionType 'Thick'	        \
			 --neighborhoods $NH                    \
                         --multiVolumeConsistency               \
			 --srdf "${NH}:${COS_VMAXBLOCK_SRDF_TARGET}:ASYNCHRONOUS"
    #expectN=`grep "name" /tmp/file.txt | wc -l`
    #if [ $expectN -eq 3 ]
    #then
    #   echo "Expected 3 storage pools, got $expectN instead"
    #   fail;
    #fi   
    echo "END: Virtual Pool matching test: right now these tests are visually verified!"
}

srdf_cos_change()
{
   # Create non-protected volume, then move it to a cos that has protection
   srdfvolumecc="${SRDF_VOLUME}-coschange"
   run volume create ${srdfvolumecc} $PROJECT $NH $COS_VMAXBLOCK_SRDF_TARGET 1GB
   echo "Created volume, now sleeping..."
   sleep 60
   echo "Changing cos..."
   run volume change_cos $PROJECT/${srdfvolumecc} ${COS_VMAXBLOCK_SRDF_SOURCE}_sync
   echo "Changed cos"
   sleep 60
   echo "Deleting volume"
   run volume delete $PROJECT/${srdfvolumecc} --wait
}


srdf_cos_change_meta()
{
   # Create non-protected meta volume, then move it to a cos that has protection
   srdfvolumeccmeta="${SRDF_VOLUME}-coschangemeta"
   run volume create ${srdfvolumeccmeta} $PROJECT $NH $COS_VMAXBLOCK_SRDF_TARGET 300GB
   echo "Created volume, now sleeping..."
   sleep 60
   echo "Changing cos..."
   run volume change_cos $PROJECT/${srdfvolumeccmeta} ${COS_VMAXBLOCK_SRDF_SOURCE}_sync
   echo "Changed cos"
   sleep 60
   echo "Deleting volume"
   run volume delete $PROJECT/${srdfvolumeccmeta} --wait
}



srdf_basic_sync_test()
{
   srdfvolume="${SRDF_VOLUME}_sync"
   run volume create ${srdfvolume}1 $PROJECT $NH ${COS_VMAXBLOCK_SRDF_SOURCE}_sync 1GB
   sleep 300
   #run volume create ${srdfvolume}2 $PROJECT $NH ${COS_VMAXBLOCK_SRDF_SOURCE}_sync 1GB --consistencygroup $CONSISTENCY_GROUP_SRDF
   #run volume create ${srdfvolume}3 $PROJECT $NH ${COS_VMAXBLOCK_SRDF_SOURCE}_sync 1GB --count 2
   #run volume delete $PROJECT/${srdfvolume}2 --wait
   run volume delete $PROJECT/${srdfvolume}1 --wait
   #run volume delete $PROJECT/${srdfvolume}3-1 --wait
   #run volume delete $PROJECT/${srdfvolume}3-2 --wait
}

srdf_basic_async_test()
{
   srdfvolume="${SRDF_VOLUME}_async"
   run volume create ${srdfvolume}1 $PROJECT $NH ${COS_VMAXBLOCK_SRDF_SOURCE}_async 1GB --consistencyGroup $CONSISTENCY_GROUP_SRDF
   run volume create ${srdfvolume}2 $PROJECT $NH ${COS_VMAXBLOCK_SRDF_SOURCE}_async 1GB --consistencyGroup $CONSISTENCY_GROUP_SRDF
   echo "Created 2 volumes... now going to sleep..."
   sleep 60
   echo "Deleting volumes..."
   #run volume create ${srdfvolume}3 $PROJECT $NH ${COS_VMAXBLOCK_SRDF_SOURCE}_async 1GB --count 2
   run volume delete $PROJECT/${srdfvolume}2 --wait
   run volume delete $PROJECT/${srdfvolume}1 --wait
   #run volume delete $PROJECT/${srdfvolume}3-1 --wait
   #run volume delete $PROJECT/${srdfvolume}3-2 --wait
}

srdf_tests()
{
   echo 'Run SRDF tests'
   echo 'About to run cos matcher test'
   srdf_cos_matcher_test
   echo 'About to run basic SRDF async test'
   sleep 60
   srdf_basic_async_test
   echo 'About to run basic SRDF sync test'
   sleep 60
   srdf_basic_sync_test
   echo 'About to run SRDF cos change test'
   sleep 60
   srdf_cos_change
   echo 'About to run SRDF cos change test for meta volume'
   sleep 60
   srdf_cos_change_meta
   echo 'Done Running SRDF tests'
}

vmax_cos_setup()
{
    if [ $QUICK -eq 0 ]; then
       cos create block $COS_VMAXBLOCK				\
			 --description 'CoS for VMAX block FC+iSCSI' true 	\
                         --protocols FC iSCSI 			\
                         --numpaths 2 \
                         --max_snapshots 10 \
                         --provisionType 'Thin' \
	                 --system_type vmax \
                         --expandable true \
                         --neighborhoods $NH
    else
       cos create block $COS_VMAXBLOCK                          \
                         --description 'CoS for VMAX block FC+iSCSI' true       \
                         --protocols FC                   \
                         --numpaths 2 \
                         --max_snapshots 10 \
                         --provisionType 'Thin' \
                         --system_type vmax \
                         --expandable true \
                         --neighborhoods $NH
    fi

    cos create block $COS_VMAXBLOCK_FC				\
			 --description 'CoS for VMAX block FC' true 	\
                         --protocols FC 			\
                         --numpaths 2 \
                         --max_snapshots 10 \
	                 --system_type vmax \
                         --provisionType 'Thin' \
			 --neighborhoods $NH

    cos create block $COS_VMAXBLOCK_ISCSI			\
			 --description 'CoS for VMAX block iSCSI' true \
                         --protocols iSCSI 			\
                         --numpaths 2 \
                         --max_snapshots 10 \
	                 --system_type vmax \
                         --provisionType 'Thin' \
			 --neighborhoods $NH

    cos create block $COS_VMAXBLOCK_THIN 				\
    			 --description 'VMAX thin storage' true      \
                             --protocols FC iSCSI	    \
                             --numpaths 2 \
                             --max_snapshots 10 \
	                     --system_type vmax \
                             --provisionType 'Thin' \
                             --expandable true \
                         --neighborhoods $NH

    cos create block $COS_VMAXBLOCK_THICK 				\
    			 --description 'VMAX thick storage' true      \
                             --protocols FC iSCSI	    \
                             --numpaths 2  \
                             --max_snapshots 10 \
	                     --system_type vmax \
                             --provisionType 'Thick' \
			 --neighborhoods $NH
}

mirrorblock_cos_setup()
{
    cos create block $COS_MIRROR                       \
           --description 'VMAX Mirror block FC' true   \
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --max_mirrors 10           \
                            --provisionType 'Thin'     \
	                    --system_type vmax \
                            --expandable false \
			    --neighborhoods $NH

    cos create block $COS_MIRROR_WITH_OPTIONAL         \
           --description 'VMAX Mirror block FC with optional CoS' true   \
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --max_mirrors 1            \
                            --provisionType 'Thin'     \
                            --mirror_cos $COS_VMAXBLOCK_FC   \
	                    --system_type vmax \
                            --expandable false \
			    --neighborhoods $NH

    cos create block $COS_MIRROR_WITH_2_MIRRORS        \
           --description 'VMAX Mirror block FC with 2 mirrors maximum' true   \
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --max_mirrors 2            \
                            --provisionType 'Thin'     \
	                    --system_type vmax \
                            --expandable false \
			    --neighborhoods $NH

    cos create block $COS_MIRROR_BEFORE_CHANGE         \
           --description 'VMAX block FC with no mirrors explicitly' true   \
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --max_mirrors 0            \
                            --provisionType 'Thin'     \
	                    --system_type vmax \
                            --expandable false \
			    --neighborhoods $NH

    cos create block $COS_MIRROR_AFTER_CHANGE          \
           --description 'VMAX block FC with 1 mirror explicitly' true   \
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --max_mirrors 1            \
                            --provisionType 'Thin'     \
	                    --system_type vmax \
                            --expandable false \
			    --neighborhoods $NH

    cos create block $COS_MIRROR_VNX                   \
			    --description 'VNX block mirror' true 	\
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --max_mirrors 3            \
                            --provisionType 'Thin'     \
	                    --system_type vmax \
                            --expandable false \
			    --neighborhoods $NH

    cos create block $COS_VMAX_CG_MIRROR \
                            --description 'CoS for VMAX block FC' true \
                            --protocols FC \
                            --numpaths 2 \
                            --max_snapshots 10 \
                            --max_mirrors 10 \
                            --system_type vmax \
                            --expandable false \
                            --provisionType 'Thin' \
                            --neighborhoods $NH \
                            --multiVolumeConsistency
}

consistencygroup_block_cos_setup()
{
    # Create CoS for VNX
    cos create block $VNX_COS_GROUP                       \
           --description 'Consistency Group Block VNX CoS' true   \
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --provisionType 'Thin'     \
			    --neighborhoods $NH        \
                            --multiVolumeConsistency   

    cos update block $VNX_COS_GROUP --storage $VNXB_NATIVEGUID
    cos allow $VNX_COS_GROUP block $TENANT

    # Create CoS for VMAX
    cos create block $VMAX_COS_GROUP                       \
           --description 'Consistency Group Block VMAX CoS' true   \
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --provisionType 'Thin'     \
			    --neighborhoods $NH                \
                            --multiVolumeConsistency

    cos update block $VMAX_COS_GROUP --storage $VMAX_NATIVEGUID
    cos allow $VMAX_COS_GROUP block $TENANT

    # Create CoS without the MultiVolumeConsistency attribute
    COS_GROUP_INVALID=cos-group-no-multivolumeconsistency"$date"
    cos create block $COS_GROUP_INVALID                       \
           --description 'Consistency Group Block VirtualPool with no multiVolumeConsistency' true   \
                            --protocols FC iSCSI       \
                            --numpaths 1               \
                            --max_snapshots 10         \
                            --provisionType 'Thin'     \
			    --neighborhoods $NH
}

vplex_cos_setup()
{
    cos create block cosvplexlocal                            \
                     --description 'Local CoS for VPlex' false \
                     --protocols FC                           \
                     --numpaths 2                             \
                     --provisionType 'Thin'                   \
                     --highavailability vplex_local           \
                     --neighborhoods $NH $NH2                 \
                     --max_snapshots 1                        \
                     --max_mirrors 1                          \
                     --expandable false 

    cos allow cosvplexlocal block $TENANT
    if [ "${VPLEX_QUICK_PARAM}" = "quick" ]; then
	cos update block cosvplexlocal --storage $VPLEX_SIM_VMAX1_NATIVEGUID
	cos update block cosvplexlocal --storage $VPLEX_SIM_VMAX2_NATIVEGUID
	cos update block cosvplexlocal --storage $VPLEX_SIM_VMAX3_NATIVEGUID
    else
	cos update block cosvplexlocal --storage $VPLEX_VNX1_NATIVEGUID
	if [ "$AUTH" != 'ipv6' ] ; then
	    cos update block cosvplexlocal --storage $VPLEX_VNX2_NATIVEGUID
	fi
	cos update block cosvplexlocal --storage $VPLEX_VMAX_NATIVEGUID
    fi

    cos create block cosvplexdist                                   \
                     --description 'Distributed CoS for VPlex' false \
                     --protocols FC                                 \
                     --numpaths 2                                   \
                     --provisionType 'Thin'                         \
                     --highavailability vplex_distributed           \
                     --neighborhoods $NH $NH2                       \
                     --haNeighborhood $NH2                          \
                     --max_snapshots 1                              \
                     --max_mirrors 1                                \
                     --mirror_cos cosvplexlocal                     \
                     --expandable false

    cos allow cosvplexdist block $TENANT
    if [ "${VPLEX_QUICK_PARAM}" = "quick" ]; then
	cos update block cosvplexdist --storage $VPLEX_SIM_VMAX1_NATIVEGUID
	cos update block cosvplexdist --storage $VPLEX_SIM_VMAX2_NATIVEGUID
	cos update block cosvplexdist --storage $VPLEX_SIM_VMAX3_NATIVEGUID
    else
	cos update block cosvplexdist --storage $VPLEX_VNX1_NATIVEGUID
	cos update block cosvplexdist --storage $VPLEX_VMAX_NATIVEGUID
    fi
}

vplex_setup()
{
    vplex_setup_once
}

vplex_setup_once()
{
    if [ "$AUTH" == 'ipv6' ] ; then
	echo "Setting up VPLEX environment for IPv6"
	# Discover the storage systems 
	smisprovider create $VPLEX_VMAX_SMIS_DEV_NAME $VPLEX_VMAX_SMIS_IP 5988 $VPLEX_SMIS_USER "$VPLEX_SMIS_PASSWD" false
	storageprovider create $VPLEX_DEV_NAME $VPLEX_IP 443 $VPLEX_USER "$VPLEX_PASSWD" vplex
	storagedevice discover_all
	storagedevice list
	storageport list $VPLEX_VNX1_NATIVEGUID
	storageport list $VPLEX_VMAX_NATIVEGUID
	storageport list $VPLEX_GUID

	# Setup the varrays. $NH contains VPLEX cluster-1 and $NH2 contains VPLEX cluster-2.
	storageport update $VPLEX_GUID FC --group director-1-1-A --addvarrays $NH
	storageport update $VPLEX_GUID FC --group director-1-1-B --addvarrays $NH
	storageport update $VPLEX_GUID FC --group director-2-1-A --addvarrays $NH2
	storageport update $VPLEX_GUID FC --group director-2-1-B --addvarrays $NH2
	# The arrays are assigned to individual varrays as well.
	storageport update $VPLEX_VNX1_NATIVEGUID FC --addvarrays $NH
	storageport update $VPLEX_VMAX_NATIVEGUID FC --addvarrays $NH2        
    elif [ "${VPLEX_QUICK_PARAM}" = "quick" ]; then
	echo "Setting up VPLEX environment connected to simulators on: ${VPLEX_SIM_IP}"

	# Discover the Brocade SAN switch.
	echo "Configuring MDS/Cisco Simulator using SSH on: $VPLEX_SIM_MDS_IP"
	run networksystem create $FABRIC_SIMULATOR  mds --devip $VPLEX_SIM_MDS_IP --devport 22 --username $VPLEX_SIM_MDS_USER --password $VPLEX_SIM_MDS_PW
	transportzone listall
	run transportzone assign ${SIMULATOR_VSAN_11} ${NH}
        run transportzone assign ${SIMULATOR_VSAN_12} ${NH2}

	# Discover the storage systems 
	echo "Discovering back-end storage arrays using ECOM/SMIS simulator on: $VPLEX_SIM_SMIS_IP..."
	smisprovider show $VPLEX_SIM_SMIS_DEV_NAME &> /dev/null && return $?
	run smisprovider create $VPLEX_SIM_SMIS_DEV_NAME $VPLEX_SIM_SMIS_IP 5988 $VPLEX_SIM_SMIS_USER "$VPLEX_SIM_SMIS_PASSWD" false

	echo "Discovering VPLEX using simulator on: ${VPLEX_SIM_IP}..."
	storageprovider show $VPLEX_SIM_DEV_NAME &> /dev/null && return $?
	run storageprovider create $VPLEX_SIM_DEV_NAME $VPLEX_SIM_IP 443 $VPLEX_SIM_USER "$VPLEX_SIM_PASSWD" vplex
	run storagedevice discover_all

	# Setup the varrays. $NH contains VPLEX cluster-1 and $NH2 contains VPLEX cluster-2.
	run storageport update $VPLEX_SIM_VPLEX_GUID FC --group director-1-1-A --addvarrays $NH
	run storageport update $VPLEX_SIM_VPLEX_GUID FC --group director-1-1-B --addvarrays $NH
	run storageport update $VPLEX_SIM_VPLEX_GUID FC --group director-2-1-A --addvarrays $NH2
	run storageport update $VPLEX_SIM_VPLEX_GUID FC --group director-2-1-B --addvarrays $NH2
	# The arrays are assigned to individual varrays as well.
	run storageport update $VPLEX_SIM_VMAX1_NATIVEGUID FC --addvarrays $NH
	run storageport update $VPLEX_SIM_VMAX3_NATIVEGUID FC --addvarrays $NH
	run storageport update $VPLEX_SIM_VMAX2_NATIVEGUID FC --addvarrays $NH2
	vplex_cos_setup
	VPLEX_GUID=$VPLEX_SIM_VPLEX_GUID
	CLUSTER1NET_NAME=$CLUSTER1NET_SIM_NAME
        echo "Done setting up VPLEX environment..."
    else
	echo "Setting up VPLEX environment for IPv4"

	#Discover the Brocade SAN switch.
	brocade_setup_once

	# Discover the storage systems 
	echo "Discovering Storage Assets"
	smisprovider show $VPLEX_VMAX_SMIS_DEV_NAME &> /dev/null && return $?
	run smisprovider create $VPLEX_VMAX_SMIS_DEV_NAME $VPLEX_VMAX_SMIS_IP 5988 $VPLEX_SMIS_USER "$VPLEX_SMIS_PASSWD" false
	run smisprovider create $VPLEX_VNX1_SMIS_DEV_NAME $VPLEX_VNX1_SMIS_IP 5988 $VPLEX_SMIS_USER "$VPLEX_SMIS_PASSWD" false
	run smisprovider create $VPLEX_VNX2_SMIS_DEV_NAME $VPLEX_VNX2_SMIS_IP 5988 $VPLEX_SMIS_USER "$VPLEX_SMIS_PASSWD" false
	storageprovider show $VPLEX_DEV_NAME &> /dev/null && return $?
	run storageprovider create $VPLEX_DEV_NAME $VPLEX_IP 443 $VPLEX_USER "$VPLEX_PASSWD" vplex
	run storagedevice discover_all
	storagedevice list
	storageport list $VPLEX_VNX1_NATIVEGUID --v
	storageport list $VPLEX_VMAX_NATIVEGUID --v
	storageport list $VPLEX_VNX2_NATIVEGUID --v
	storageport list $VPLEX_GUID --v
	sleep 90
	storageport list $VPLEX_GUID --v

	# Setup the varrays. $NH contains VPLEX cluster-1 and $NH2 contains VPLEX cluster-2.
	run storageport update $VPLEX_GUID FC --group director-1-1-A --addvarrays $NH
	run storageport update $VPLEX_GUID FC --group director-1-1-B --addvarrays $NH
	run storageport update $VPLEX_GUID FC --group director-2-1-A --addvarrays $NH2
	run storageport update $VPLEX_GUID FC --group director-2-1-B --addvarrays $NH2
	storageport list $VPLEX_GUID --v
	# The arrays are assigned to individual varrays as well.
	run storageport update $VPLEX_VNX1_NATIVEGUID FC --addvarrays $NH
	run storageport update $VPLEX_VNX2_NATIVEGUID FC --addvarrays $NH
	run storageport update $VPLEX_VMAX_NATIVEGUID FC --addvarrays $NH2
	vplex_cos_setup
	storageport list $VPLEX_GUID --v
    fi
}

#
# vplex tests
#
vplex_tests()
{
    storageport list $VPLEX_GUID --v
    if [ "$AUTH" != 'ipv6' ] ; then
	echo "**** Executing VPLEX tests"

	hname=$(hostname)
	if [ $hname = "standalone" ]; then
	    hname=$SHORTENED_HOST
	fi
	echo "hostname is $hname"
	
	localVolume1=$hname-${RANDOM}-VPlexLocal1
	localVolume2=$hname-${RANDOM}-VPlexLocal2
	localMirror1=$hname-${RANDOM}-VPlexLocalMirror1
	localMirror2=$hname-${RANDOM}-VPlexLocalMirror2
	sourceSideSuffix=-0
	localSnapshot=$hname-${RANDOM}-VPlexLocalSnap
	distVolume1=$hname-${RANDOM}-VPlexDist1
	distSrcLocalMirror1=$hname-${RANDOM}-srcLocalMirror1
	distSnapshot=$hname-${RANDOM}-VPlexDist1Snap
	distVolume2=$hname-${RANDOM}-VPlexDist2
	distSrcLocalMirror2=$hname-${RANDOM}-srcLocalMirror2
	host=$PROJECT.lss.emc.com
	hostLbl=$PROJECT
	PWWN1=10:00:00:E0:7E:00:00:0F
	WWNN1=20:00:00:E0:7E:00:00:0F
	PWWN2=10:00:00:90:FA:18:0E:99
	WWNN2=20:00:00:90:FA:18:0E:99

	echo "**** Creating VPLEX local volumes"
	run volume create $localVolume1 $PROJECT $NH cosvplexlocal $BLK_SIZE
	run volume create $localVolume2 $PROJECT $NH cosvplexlocal $BLK_SIZE --count=2
	
	echo "**** Creating VPLEX local mirrors"
	run blockmirror attach  $PROJECT/$localVolume1 $localMirror1 1
	run blockmirror attach  $PROJECT/$localVolume2-1 $localMirror2 1

	echo "**** Deleting VPLEX local mirror"
	run blockmirror deactivate  $PROJECT/$localVolume2-1 $localMirror2$sourceSideSuffix

	echo "**** Creating VPLEX distributed volumes"
	run volume create $distVolume1 $PROJECT $NH cosvplexdist $BLK_SIZE
	run volume create $distVolume2 $PROJECT $NH cosvplexdist $BLK_SIZE

	echo "**** Creating local mirrors for the Distributed volumes on the source side"
	run blockmirror attach  $PROJECT/$distVolume1 $distSrcLocalMirror1 1
	run blockmirror attach  $PROJECT/$distVolume2 $distSrcLocalMirror2 1
	
	echo "**** Deleting local mirror for the VPLEX Distributed volume"
	run blockmirror deactivate  $PROJECT/$distVolume2 $distSrcLocalMirror2$sourceSideSuffix
	
	echo "**** Creating host"
	hosts create $hostLbl $TENANT Windows $host --port 8111 --username user --password 'password' --osversion 1.0
	
	echo "**** Creating initiators"
	initiator create $hostLbl FC $PWWN1 --node $WWNN1
	initiator create $hostLbl FC $PWWN2 --node $WWNN2
	
	echo "**** Adding WWNs to Network"
	run transportzone add ${NH}/${CLUSTER1NET_NAME} $PWWN1
	run transportzone add ${NH}/${CLUSTER1NET_NAME} $PWWN2
	
	echo "**** Exporting VPLEX volumes to host in varray " $NH
	run export_group create $PROJECT $hname-1$host $NH --volspec "$PROJECT/$distVolume1+1" --inits "$hostLbl/$PWWN1","$hostLbl/$PWWN2"
	run export_group update $PROJECT/$hname-1$host --addVolspec $PROJECT/$distVolume2+2
	run export_group update $PROJECT/$hname-1$host --addVolspec $PROJECT/$localVolume1+3
	run export_group update $PROJECT/$hname-1$host --addVolspec $PROJECT/$localVolume2-1+4
	
	echo "**** Exporting VPLEX volumes to host in varray " $NH2
        # run export_group create $PROJECT $hname-2$host $NH2 --volspec "$PROJECT/$distVolume1+1" --inits "$hostLbl/$PWWN2"
	echo "Exports for $distVolume1"
	volume exports "$PROJECT/$distVolume1" --v
	echo "Exports for $distVolume2"
	volume exports "$PROJECT/$distVolume2" --v
	echo "Exports for $localVolume1"
	volume exports "$PROJECT/$localVolume1" --v
	echo "Exports for $localVolume2-1"
	volume exports "$PROJECT/$localVolume1" --v

	echo "**** Creating VPLEX volume snapshots"
	run blocksnapshot create $PROJECT/$localVolume1 $localSnapshot
	blocksnapshot list $PROJECT/$localVolume1
	blocksnapshot show $PROJECT/$localVolume1/$localSnapshot
	run blocksnapshot create $PROJECT/$distVolume1 $distSnapshot
	blocksnapshot list $PROJECT/$distVolume1
	blocksnapshot show $PROJECT/$distVolume1/$distSnapshot

	echo "**** Restoring VPLEX volume snapshots"
        # Must deactivate mirrors before restoring snapshots now.
	run blockmirror deactivate  $PROJECT/$localVolume1 $localMirror1$sourceSideSuffix
	run blocksnapshot restore $PROJECT/$localVolume1/$localSnapshot
	run blockmirror deactivate  $PROJECT/$distVolume1 $distSrcLocalMirror1$sourceSideSuffix
	run blocksnapshot restore $PROJECT/$distVolume1/$distSnapshot

	echo "**** Deleting VPLEX volume snapshots"
	run blocksnapshot delete $PROJECT/$localVolume1/$localSnapshot
	run blocksnapshot delete $PROJECT/$distVolume1/$distSnapshot

	echo "**** Deleting VPLEX exports"
	run export_group delete $PROJECT/$hname-1$host
	# run export_group delete $PROJECT/$hname-2$host

	echo "**** Deleting VPLEX volumes"
	run volume delete $PROJECT/$localVolume1 --wait
	run volume delete $PROJECT/$localVolume2-1 --wait
        run volume delete $PROJECT/$localVolume2-2 --wait

	run volume delete $PROJECT/$distVolume1 --wait
	run volume delete $PROJECT/$distVolume2 --wait

	echo "**** Deleting Host"
	hosts delete $hostLbl

	echo "**** Completed VPLEX Tests"
    fi
}

# Run vplexexport test externally
vplexexport_setup() {
    vplex_setup_once
}
vplexexport_tests() {
    echo "************* Running export-tests/vplexexport.sh  *****************"
    run export-tests/vplexexport.sh test1
}

sanzoning_setup()
{
    sanzoning_setup_once
}

sanzoning_setup_once()
{
    vmaxblock_discovery
    vnxblock_discovery
}

# Sanzoning Tests
sanzoning_tests()
{
    echo "************* Running export-tests/sanzoning.sh  *****************"
#    run export-tests/sanzoning.sh addvolumezonecheck
#   run export-tests/sanzoning.sh cleanup
    run export-tests/sanzoning.sh sanzonereuse
}

vmaxblock_discovery()
{
    # do this only once
    smisprovider show $VMAX_SMIS_DEV &> /dev/null && return $?

    if [ $QUICK -eq 0 ]; then
       smisprovider create $VMAX_SMIS_DEV $VMAX_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
    fi

    storagedevice discover_all --ignore_error
}

vnxblock_discovery()
{
    # Discover VNX block array
    smisprovider show $VNX_SMIS_DEV &> /dev/null && return $?

    if [ $QUICK -eq 0 ]; then
       smisprovider create $VNX_SMIS_DEV $VNX_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
    else
       smisprovider create $VNX_SMIS_DEV $SIMULATOR_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
    fi

    storagedevice discover_all --ignore_error
}

######################### Start of RecoverPoint ############################
#
# RecoverPoint can be run in a simulated and physical environment.
#

#########################
# RecoverPoint Vpool create
#########################

# All varrays for regular targets
rp_targets()
{
    run cos create block rp_targets$1 $POOLS_AUTO_MATCH \
        --description 'RP-Targets' \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 $RECOVERPOINT_VARRAY2 $RECOVERPOINT_VARRAY3 $RECOVERPOINT_VARRAY4 \
        --max_snapshots 10
}

# All varrays for RP+VPLEX targets
rpvplex_targets()
{
    run cos create block rpvplex_targets$1 true \
        --description 'RP+VPLEX-Targets' \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 $RECOVERPOINT_VARRAY2 $RECOVERPOINT_VARRAY3 $RECOVERPOINT_VARRAY4 \
        --max_snapshots 10 \
        --highavailability vplex_local
}

# All varrays for HA
rpvplex_ha()
{
    run cos create block rpvplex_ha$1 true \
        --description 'HA' \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 $RECOVERPOINT_VARRAY2 $RECOVERPOINT_VARRAY3 $RECOVERPOINT_VARRAY4 \
        --highavailability vplex_local
}

# Regular vpool used as base for change vpool tests
rp_regular()
{
    run cos create block rp_regular$1 true \
        --description 'Regular-vpool-used-as-base-for-change-vpool-tests' \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --max_snapshots 10
}

# Regular VPLEX local vpool used as base for change vpool tests
rpvplex_local_regular()
{
    run cos create block rpvplex_local_regular$1 true \
        --description 'Regular-VPLEX-local-vpool-used-as-base-for-change-vpool-tests' \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --highavailability vplex_local
}

# Regular VPLEX dist vpool used as base for change vpool tests
rpvplex_dist_regular()
{
    run cos create block rpvplex_dist_regular$1 true \
        --description 'Regular-VPLEX-dist-vpool-used-as-base-for-change-vpool-tests' \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --highavailability vplex_distributed \
        --haNeighborhood $RECOVERPOINT_VARRAY2 \
        --haCos rpvplex_ha
}

# RP CDP
rp_cdp()
{
    run cos create block rp_cdp$1 $POOLS_AUTO_MATCH \
        --description 'RP-Source-CDP'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY1':rp_targets'$1':min' \
        --max_snapshots 10 \
        --rp_copy_mode ASYNCHRONOUS \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES
}

# RP CRR
rp_crr()
{
    run cos create block rp_crr$1 $POOLS_AUTO_MATCH \
        --description 'RP-Source-CRR'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY3':rp_targets'$1':min' \
        --rp_copy_mode ASYNCHRONOUS \
        --max_snapshots 10 \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES
}

# RP CLR
rp_clr()
{
    run cos create block rp_clr$1 $POOLS_AUTO_MATCH \
        --description 'RP-Source-CLR'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY1':rp_targets'$1':min',$RECOVERPOINT_VARRAY3':rp_targets'$1':min' \
        --max_snapshots 10 \
        --rp_copy_mode ASYNCHRONOUS \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES
}

# RP+VPLEX CDP
rpvplex_cdp()
{
    run cos create block rpvplex_cdp$1 true \
        --description 'RP+VPLEX-Source-CDP'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY1':rp_targets'$1':min' \
        --rp_copy_mode ASYNCHRONOUS \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES \
        --highavailability vplex_local
}

# RP+VPLEX CRR
rpvplex_crr()
{
    run cos create block rpvplex_crr$1 true \
        --description 'RP+VPLEX-Source-CRR'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY3':rp_targets'$1':min' \
        --rp_copy_mode ASYNCHRONOUS \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES \
        --highavailability vplex_distributed \
        --haNeighborhood $RECOVERPOINT_VARRAY2 \
        --haCos rpvplex_ha
}

# RP+VPLEX CLR
rpvplex_clr()
{
    run cos create block rpvplex_clr$1 true \
        --description 'RP+VPLEX-Source-CLR'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY1':rp_targets'$1':min',$RECOVERPOINT_VARRAY3':rp_targets'$1':min' \
        --rp_copy_mode ASYNCHRONOUS \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES \
        --highavailability vplex_distributed \
        --haNeighborhood $RECOVERPOINT_VARRAY2 \
        --haCos rpvplex_ha
}

# MetroPoint CDP
mp_cdp()
{
    run cos create block mp_cdp$1 true \
        --description 'MetroPoint-Source-CDP'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY1':rp_targets'$1':min',$RECOVERPOINT_VARRAY2':rp_targets'$1':min' \
        --rp_copy_mode ASYNCHRONOUS \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES \
        --highavailability vplex_distributed \
        --haNeighborhood $RECOVERPOINT_VARRAY2 \
        --haCos rpvplex_ha \
        --metropoint true \
        --activeProtectionAtHASite false
}

# MetroPoint CRR
mp_crr()
{
    run cos create block mp_crr$1 true \
        --description 'MetroPoint-Source-CRR'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY3':rp_targets'$1':min' \
        --rp_copy_mode ASYNCHRONOUS \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES \
        --highavailability vplex_distributed \
        --haNeighborhood $RECOVERPOINT_VARRAY2 \
        --haCos rpvplex_ha \
        --metropoint true \
        --activeProtectionAtHASite false
}

# MetroPoint CLR
mp_clr()
{
    run cos create block mp_clr$1 true \
        --description 'MetroPoint-CLR'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --protectionCoS $RECOVERPOINT_VARRAY1':rp_targets'$1':min',$RECOVERPOINT_VARRAY2':rp_targets'$1':min',$RECOVERPOINT_VARRAY3':rp_targets'$1':min' \
        --rp_copy_mode ASYNCHRONOUS \
        --rp_rpo_value 5 \
        --rp_rpo_type MINUTES \
        --highavailability vplex_distributed \
        --haNeighborhood $RECOVERPOINT_VARRAY2 \
        --haCos rpvplex_ha \
        --metropoint true \
        --activeProtectionAtHASite false
}

# RP - NO PROTECTION
rp_noprotection()
{
    cos create block rp_noprotection$1 true \
        --description 'RP - NO PROTECTION'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency
}

# RP+VPLEX LOCAL - NO PROTECTION
rpvplexlocal_noprotection()
{
    cos create block rpvplexlocal_noprotection$1 true \
        --description 'RP+VPLEX LOCAL - NO PROTECTION'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --highavailability vplex_local
}

# RP+VPLEX DIST - NO PROTECTION
rpvplexdist_noprotection()
{
    cos create block rpvplexdist_noprotection$1 true \
        --description 'RP+VPLEX DIST - NO PROTECTION'  \
        --protocols FC \
        --numpaths 2 \
        --provisionType 'Thin' \
        --neighborhoods $RECOVERPOINT_VARRAY1 \
        --multiVolumeConsistency \
        --highavailability vplex_distributed \
        --haNeighborhood $RECOVERPOINT_VARRAY2 \
        --haCos rpvplex_ha
}

rp_vpool_setup()
{
    rp_targets
    rp_regular
    rp_cdp
    rp_crr
    rp_clr
    rp_noprotection
    if [ "${RPVPLEX_TESTS}" = "1" ]; then
	rpvplex_targets
	rpvplex_ha
	rpvplex_cdp
	rpvplex_crr
	rpvplex_clr
	mp_cdp
	mp_crr
	mp_clr
	rpvplexlocal_noprotection
	rpvplexdist_noprotection
    fi
}

rp_varray_setup()
{
    echo '*** Recoverpoint varray setup ***'

    # Create Virtual Array
    run neighborhood create $RECOVERPOINT_VARRAY1
    run neighborhood allow $RECOVERPOINT_VARRAY1 $TENANT
    run neighborhood allow $RECOVERPOINT_VARRAY1 `tenant root`

    run neighborhood create $RECOVERPOINT_VARRAY2
    run neighborhood allow $RECOVERPOINT_VARRAY2 $TENANT
    run neighborhood allow $RECOVERPOINT_VARRAY2 `tenant root`

    run neighborhood create $RECOVERPOINT_VARRAY3
    run neighborhood allow $RECOVERPOINT_VARRAY3 $TENANT
    run neighborhood allow $RECOVERPOINT_VARRAY3 `tenant root`

    run neighborhood create $RECOVERPOINT_VARRAY4
    run neighborhood allow $RECOVERPOINT_VARRAY4 $TENANT
    run neighborhood allow $RECOVERPOINT_VARRAY4 `tenant root`
}

rp_network_setup()
{
    echo '*** Recoverpoint network setup ***'

    networksystem create $RECOVERPOINT_BROCADE_NETWORK brocade --smisip $RECOVERPOINT_BROCADE_NETWORK_PROVIDER --smisport 5988 --smisuser $RECOVERPOINT_BROCADE_NETWORK_PROVIDER_USERNAME --smispw "$RECOVERPOINT_BROCADE_NETWORK_PROVIDER_PASSWORD" --smisssl false
    sleep 20
    transportzone listall
}

rp_smis_setup()
{
    echo '*** Recoverpoint SMIS setup ***'

    for var in A B C D
    do
        provider='RECOVERPOINT_SMIS_PROVIDER_'$var
        provider=${!provider}

        provider_ip='RECOVERPOINT_SMIS_PROVIDER_'$var'_IP'
        provider_ip=${!provider_ip}

        array_guid='RECOVERPOINT_STORAGE_ARRAY_'$var'_GUID'
        array_guid=${!array_guid}

        if [ "$array_guid" != "NONE" ]; then
            if [ "$RECOVERPOINT_XIO" = "1" ]; then
                echo 'Using XTremeIO'

                discoveredsystem show $XTREMIO_NATIVEGUID &> /dev/null && return $?
                discoveredsystem create $XTREMIO xtremio $XTREMIO_IP 443 $XTREMIO_USER $XTREMIO_PASSWD --serialno=$XTREMIO_SN
            else
                smisprovider create $provider $provider_ip $SMIS_PORT $SMIS_USER $SMIS_PASSWORD false
            fi
        fi
    done

    if [ "${RPVPLEX_TESTS}" = "1" ]; then
	rp_vplex_setup
    fi

    echo '*** Recoverpoint discover storage systems ***'
    run storagedevice discover_all
    storagedevice list
}

rp_vplex_setup()
{
    echo '*** Recoverpoint VPLEX setup ***'

    # Create VPLEX
    if [ "$RECOVERPOINT_VPLEX_A" != "NONE" ]; then
        storageprovider create $RECOVERPOINT_VPLEX_A $RECOVERPOINT_VPLEX_A_IP $RECOVERPOINT_VPLEX_A_PORT $RECOVERPOINT_VPLEX_A_USER $RECOVERPOINT_VPLEX_A_PASSWORD vplex
    fi

    if [ "$RECOVERPOINT_VPLEX_B" != "NONE" ]; then
        storageprovider create $RECOVERPOINT_VPLEX_B $RECOVERPOINT_VPLEX_B_IP $RECOVERPOINT_VPLEX_B_PORT $RECOVERPOINT_VPLEX_B_USER $RECOVERPOINT_VPLEX_B_PASSWORD vplex
    fi
}

rp_port_setup()
{
    echo '*** Recoverpoint port setup ***'

    if [ "$RECOVERPOINT_STORAGE_ARRAY_A_GUID" != "NONE" ]; then
        storageport update $RECOVERPOINT_STORAGE_ARRAY_A_GUID FC --addvarrays $RECOVERPOINT_VARRAY1
    fi

    if [ "$RECOVERPOINT_STORAGE_ARRAY_B_GUID" != "NONE" ]; then
        storageport update $RECOVERPOINT_STORAGE_ARRAY_B_GUID FC --addvarrays $RECOVERPOINT_VARRAY2
    fi

    if [ "$RECOVERPOINT_STORAGE_ARRAY_C_GUID" != "NONE" ]; then
        storageport update $RECOVERPOINT_STORAGE_ARRAY_C_GUID FC --addvarrays $RECOVERPOINT_VARRAY3
    fi

    if [ "$RECOVERPOINT_STORAGE_ARRAY_D_GUID" != "NONE" ]; then
        storageport update $RECOVERPOINT_STORAGE_ARRAY_D_GUID FC --addvarrays $RECOVERPOINT_VARRAY4
    fi

    #VPLEX
    # Override port to varray assigments for VPLEX clusters to prevent port mixing in clusters
    # Source Site
    # Cluster 1
    if [ "$RECOVERPOINT_VPLEX_A" != "NONE" ] && [ "$RECOVERPOINT_STORAGE_ARRAY_A_GUID" != "NONE" ]; then
        storageport update $RECOVERPOINT_VPLEX_A_GUID FC --group director-1-1-A --addvarrays $RECOVERPOINT_VARRAY1
        storageport update $RECOVERPOINT_VPLEX_A_GUID FC --group director-1-1-B --addvarrays $RECOVERPOINT_VARRAY1
    fi
    # Cluster 2
    if [ "$RECOVERPOINT_VPLEX_A" != "NONE" ] && [ "$RECOVERPOINT_STORAGE_ARRAY_B_GUID" != "NONE" ]; then
        storageport update $RECOVERPOINT_VPLEX_A_GUID FC --group director-2-1-A --addvarrays $RECOVERPOINT_VARRAY2
        storageport update $RECOVERPOINT_VPLEX_A_GUID FC --group director-2-1-B --addvarrays $RECOVERPOINT_VARRAY2
    fi

    # Target Site
    # Cluster 1
    if [ "$RECOVERPOINT_VPLEX_B" != "NONE" ] && [ "$RECOVERPOINT_STORAGE_ARRAY_C_GUID" != "NONE" ]; then
        storageport update $RECOVERPOINT_VPLEX_B_GUID FC --group director-1-1-A --addvarrays $RECOVERPOINT_VARRAY3
        storageport update $RECOVERPOINT_VPLEX_B_GUID FC --group director-1-1-B --addvarrays $RECOVERPOINT_VARRAY3
    fi

    # Cluster 2
    if [ "$RECOVERPOINT_VPLEX_B" != "NONE" ] && [ "$RECOVERPOINT_STORAGE_ARRAY_D_GUID" != "NONE" ]; then
        storageport update $RECOVERPOINT_VPLEX_B_GUID FC --group director-2-1-A --addvarrays $RECOVERPOINT_VARRAY4
        storageport update $RECOVERPOINT_VPLEX_B_GUID FC --group director-2-1-B --addvarrays $RECOVERPOINT_VARRAY4
    fi
}

rp_protection_system_setup()
{
    echo '*** Recoverpoint protection system setup ***'

    protectionsystem show $RECOVERPOINT &> /dev/null && return $?

    run protectionsystem create $RECOVERPOINT \
    $RP_SYSTEM_TYPE \
    $RECOVERPOINT_IP \
    $RECOVERPOINT_PORT \
    $RECOVERPOINT_USER \
    $RECOVERPOINT_PASSWORD \
    1
}

rp_cg_setup()
{
    echo '*** Recoverpoint CG setup ***'

    run blockconsistencygroup create $PROJECT $RP_CONSISTENCY_GROUP
    if [ "${RPVPLEX_TESTS}" = "1" ]; then
	run blockconsistencygroup create $PROJECT $RP_VPLEX_CONSISTENCY_GROUP
	run blockconsistencygroup create $PROJECT $RP_METROPOINT_CONSISTENCY_GROUP
    fi
}

rp_isolate_rpa_clusters()
{
    if [ "$RP_USE_RPA_ISOLATION" = "1" ]; then
        echo '*** Recoverpoint isolate RPA clusters ***'

        run protectionsystem update --ip ${remote_ip} --name $RECOVERPOINT --cluster $RECOVERPOINT_RPA_CLUSTER1 --addvarrays $RECOVERPOINT_VARRAY1
        run protectionsystem update --ip ${remote_ip} --name $RECOVERPOINT --cluster $RECOVERPOINT_RPA_CLUSTER3 --addvarrays $RECOVERPOINT_VARRAY2
        run protectionsystem update --ip ${remote_ip} --name $RECOVERPOINT --cluster $RECOVERPOINT_RPA_CLUSTER4 --addvarrays $RECOVERPOINT_VARRAY3
    fi
}

recoverpoint_exports_tests()
{
    rpsnap=rpsnap-${RP_MODIFIED_HOSTNAME}-${RANDOM}
    blocksnap=blocksnap-${RP_MODIFIED_HOSTNAME}-${RANDOM}
    rpexport=$PROJECT/$RP_EXPORT_GROUP

    #Create RP/Block snapshots
    echo 'Create snapshots'
    run blocksnapshot create ${PROJECT}/${rpvolume} ${rpsnap} --type rp
    run blocksnapshot create ${PROJECT}/${rpvolume} ${blocksnap}
    run blocksnapshot activate ${PROJECT}/${rpvolume}/${blocksnap}
    run blocksnapshot delete ${PROJECT}/${rpvolume}/${blocksnap}
    run blocksnapshot create ${PROJECT}/${rpvolume}-target-${rp_src_varray} ${blocksnap}-${rp_src_varray}
    run blocksnapshot delete ${PROJECT}/${rpvolume}-target-${rp_src_varray}/${blocksnap}-${rp_src_varray}-${rp_src_varray}

    PWWN1=`pwwn 6F`;
    NWWN1=`pwwn 7F`;
    run hosts create ${RP_EXPORT_GROUP_HOST} $TENANT Windows ${RP_EXPORT_GROUP_HOST} --port 8111 --username $RP_HOST_USER --password '$RP_HOST_PW' --osversion 1.0
    run initiator create ${RP_EXPORT_GROUP_HOST} FC $PWWN1 --node $NWWN1

    if [ "$PARAM" = "vmaxblock" ]; then
        run transportzone add ${rp_src_varray}/${RP_VMAXB_VSAN} $PWWN1
    elif [ "$PARAM" = "vnxblock" ]; then
        run transportzone add ${rp_src_varray}/${RP_VNXB_VSAN} $PWWN1
    else
        # simulators being used
        run transportzone add ${rp_src_varray}/${SIMULATOR_VSAN_11} $PWWN1
    fi

    sleep 20

    echo 'recoverpoint exports'
    run export_group create $PROJECT ${RP_EXPORT_GROUP} ${rp_src_varray} --volspec ${PROJECT}/${rpvolume}/${rpsnap}-${rp_src_varray} --inits "${RP_EXPORT_GROUP_HOST}/$PWWN1"
    run export_group show ${rpexport}
    run export_group update ${rpexport} --remVol ${PROJECT}/${rpvolume}/${rpsnap}-${rp_src_varray}
    run export_group update ${rpexport} --addVolspec ${PROJECT}/${rpvolume}/${rpsnap}-${rp_src_varray}
    run export_group show ${rpexport}
    # CTRL-4638: --remInits will not call RP device controller to disable bookmark.
    #run export_group update ${rpexport} --remInits "${RP_EXPORT_GROUP_HOST}/$PWWN1"
    #run export_group update ${rpexport} --addInits "${RP_EXPORT_GROUP_HOST}/$PWWN1"
    run export_group show ${rpexport}
    run export_group delete ${rpexport}

    # currently having a volume and an RP snap in the same export group and deleting that export group doesn't work (CTRL?)
    #echo 'Running export of RP snapshot when volume already exists in mask'
    #run export_group create $PROJECT ${RP_EXPORT_GROUP}2 $NH --volspec ${PROJECT}/${rpvolume} --inits "${RP_EXPORT_GROUP_HOST}/$PWWN1"
    #run export_group update ${rpexport}2 --addVolspec ${PROJECT}/${rpvolume}/${rpsnap}-${NH}
    #run export_group update ${rpexport}2 --remVol ${PROJECT}/${rpvolume}/${rpsnap}-${NH}
    #run export_group update ${rpexport}2 --addVolspec ${PROJECT}/${rpvolume}/${rpsnap}-${NH}
    #run export_group delete ${rpexport}2

    echo 'done with RP exports, cleaning up'
    run blocksnapshot delete ${PROJECT}/${rpvolume}/${rpsnap}-${NH}
    run hosts delete ${RP_EXPORT_GROUP_HOST}
    echo 'done with recoverpoint exports cleanup'
}

recoverpoint_auto_snapshot_cleanup_test()
{
    echo '*** RP snapshot tests ***'
    rpsnap=rpsnap_for_cleanup-${RP_MODIFIED_HOSTNAME}-${RANDOM}
    blocksnap=blocksnap-${RP_MODIFIED_HOSTNAME}-${RANDOM}

    src_volume=${1}
    tgt_volume=${2}
    src_varray=${3}

    # Create RP/Block snapshot
    echo 'Create snapshot'
    run blocksnapshot create ${PROJECT}/${src_volume} ${rpsnap} --type rp
    run blocksnapshot show ${PROJECT}/${src_volume}/${rpsnap}-${src_varray} | grep inactive | grep false
    run protectionsystem discover $RECOVERPOINT

    echo 'Unaffected RP bookmark is being checked after RP discovery to ensure it is still active'
    run blocksnapshot show ${PROJECT}/${src_volume}/${rpsnap}-${src_varray} | grep inactive | grep false

    echo 'Stopping protection for the copy and then re-enabling'
    run volume change_link ${PROJECT}/${src_volume} stop ${PROJECT}/${tgt_volume} rp
    sleep 15
    run volume change_link ${PROJECT}/${src_volume} start ${PROJECT}/${tgt_volume} rp

    echo 'Re-run discovery, RP bookmark should be cleaned up automatically'
    sleep 10
    run protectionsystem discover $RECOVERPOINT

    echo 'Removed RP bookmark is being checked after RP discovery to ensure it is no longer active'
    # Use "fail" instead of run because we expect this bookmark to fail.
    fail blocksnapshot show ${PROJECT}/${src_volume}/${rpsnap}-${src_varray}
}

recoverpoint_ingest_setup()
{
    echo '*** RP ingest setup ***'

    INGEST_NATIVEGUID=$VMAX1_SIMULATOR_NATIVEGUID
    RP_NATIVEGUID=$RECOVERPOINT_RP_SIM_NATIVEGUID
    if [ "$RP_QUICK_PARAM" != "quick" ]; then
	INGEST_NATIVEGUID=$RECOVERPOINT_STORAGE_ARRAY_A_GUID
	RP_NATIVEGUID=$RECOVERPOINT_RP_NATIVEGUID
    fi

    if [ ${RP_CRR} = "1" -o ${RP_CLR} = "1" ]; then
	INGEST_NATIVEGUID2=$RECOVERPOINT_STORAGE_ARRAY_C_GUID
    fi	

    if [ "${RP_INGEST_SHORTCIRCUITTEST}" = "0" ]; then
        # Discover unmanaged volumes on the array
	run storagedevice discover_namespace $INGEST_NATIVEGUID 'UNMANAGED_VOLUMES'

	if [ ${RP_CRR} = "1" -o ${RP_CLR} = "1" ]; then
	    run storagedevice discover_namespace $INGEST_NATIVEGUID2 'UNMANAGED_VOLUMES'
	fi	

        # Especially with the simulator, the previous RP discovery may still be running
	state=`protectionsystem list | grep ${RP_SIMULATOR} | awk '{print $(NF-1)}'`
	while [ "$state" = "IN_PROGRESS" ]; do
	    echo "Waiting for RP protection discovery to complete..."
	    sleep 10
	    state=`protectionsystem list | grep ${RP_SIMULATOR} | awk '{print $(NF-1)}'`
	done

        # Sleep 5 to get past discovery required timeframe
	sleep 10

	run protectionsystem discover_namespace $RP_NATIVEGUID 'UNMANAGED_CGS'
    fi 
}

recoverpoint_ingest_test()
{
    echo '*** RP ingest tests ***'

    # Some more thought needs to go into this, how to integrate this into the regular test suite
    # and efficiently take into the account the test variables for RP.

    vpool=${1}

    # Set up labels for ingest
    RECOVERPOINT_INGEST_VOL1_SRC=${RECOVERPOINT_INGEST_VOL1BASE}_${vpool}
    RECOVERPOINT_INGEST_VOL1_SRC_JRNL=${RECOVERPOINT_INGEST_VOL1_SRC}-${RECOVERPOINT_VARRAY1}-journal-1
    RECOVERPOINT_INGEST_SNAPSHOT_VARRAY=${RECOVERPOINT_VARRAY1}
    if [ "${vpool}" = "rp_cdp" ]; then
	RECOVERPOINT_INGEST_VOL1_TGT=${RECOVERPOINT_INGEST_VOL1_SRC}-target-${RECOVERPOINT_VARRAY1}
	RECOVERPOINT_INGEST_VOL1_TGT_JRNL=${RECOVERPOINT_INGEST_VOL1_SRC}-${RECOVERPOINT_VARRAY1}-journal-2
    elif [ "${vpool}" = "rp_crr" ]; then
	RECOVERPOINT_INGEST_VOL1_TGT=${RECOVERPOINT_INGEST_VOL1_SRC}-target-${RECOVERPOINT_VARRAY3}
	RECOVERPOINT_INGEST_VOL1_TGT_JRNL=${RECOVERPOINT_INGEST_VOL1_SRC}-${RECOVERPOINT_VARRAY3}-journal-1
	RECOVERPOINT_INGEST_SNAPSHOT_VARRAY=${RECOVERPOINT_VARRAY3}
    elif [ "${vpool}" = "rp_clr" ]; then
	RECOVERPOINT_INGEST_VOL1_V1TGT=${RECOVERPOINT_INGEST_VOL1_SRC}-target-${RECOVERPOINT_VARRAY1}
	RECOVERPOINT_INGEST_VOL1_V1TGT_JRNL=${RECOVERPOINT_INGEST_VOL1_SRC}-${RECOVERPOINT_VARRAY1}-journal-2
	RECOVERPOINT_INGEST_VOL1_V3TGT=${RECOVERPOINT_INGEST_VOL1_SRC}-target-${RECOVERPOINT_VARRAY3}
	RECOVERPOINT_INGEST_VOL1_V3TGT_JRNL=${RECOVERPOINT_INGEST_VOL1_SRC}-${RECOVERPOINT_VARRAY3}-journal-1

	# For post-ingest operations
	RECOVERPOINT_INGEST_VOL1_TGT=${RECOVERPOINT_INGEST_VOL1_V1TGT}
	RECOVERPOINT_INGEST_SNAPSHOT_VARRAY=${RECOVERPOINT_VARRAY3}
    fi

    if [ "${vpool}" = "rp_cdp" ]; then
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_TGT}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_TGT_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_cdp $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC}"
    elif [ "${vpool}" = "rp_crr" ]; then
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY3} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_TGT}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY3} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_TGT_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_crr $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC}"
    elif [ "${vpool}" = "rp_clr" ]; then
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_V1TGT}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_V1TGT_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY3} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_V3TGT}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY3} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_V3TGT_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_clr $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC}"
    fi

    # now perform failover tests
    recoverpoint_failover_test "${RECOVERPOINT_INGEST_VOL1_SRC}" "${RECOVERPOINT_INGEST_VOL1_TGT}"
    # Add a volume to the protection
    RECOVERPOINT_INGEST_VOL1_CG=${RECOVERPOINT_INGEST_VOL1_CGBASE}_${vpool}
    run volume create "${RECOVERPOINT_INGEST_VOL1_SRC}"-2 ${PROJECT} ${RECOVERPOINT_VARRAY1} ${vpool} 8GB --consistencyGroup ViPR-"${RECOVERPOINT_INGEST_VOL1_CG}"

    # Remove a volume from the protection
    run volume delete ${PROJECT}/"${RECOVERPOINT_INGEST_VOL1_SRC}"-2 --wait

    # Inventory-only remove of RP volume (Note: Don't put "run" in front of this one)
    volume delete ${PROJECT}/"${RECOVERPOINT_INGEST_VOL1_SRC}" --vipronly

    # Recreate unmanaged volumes/protection sets
    run storagedevice discover_namespace $INGEST_NATIVEGUID 'UNMANAGED_VOLUMES'

    if [ ${vpool} = "rp_crr" -o ${vpool} = "rp_clr" ]; then
	run storagedevice discover_namespace $INGEST_NATIVEGUID2 'UNMANAGED_VOLUMES'
    fi	

    run protectionsystem discover_namespace $RP_NATIVEGUID 'UNMANAGED_CGS'

    # Re-ingest
    if [ "${vpool}" = "rp_cdp" ]; then
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_cdp $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_TGT}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_TGT_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC_JRNL}"
    elif [ "${vpool}" = "rp_crr" ]; then
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_crr $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY3} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_TGT}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY3} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_TGT_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC_JRNL}"
    elif [ "${vpool}" = "rp_clr" ]; then
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_clr $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_V1TGT}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_V1TGT_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY3} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_V3TGT}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY3} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_V3TGT_JRNL}"
	run unmanagedvolume ingest_unexport ${RECOVERPOINT_VARRAY1} rp_targets $PROJECT --volspec "${RECOVERPOINT_INGEST_VOL1_SRC_JRNL}"
    fi
   
    # Run snapshot test
    recoverpoint_auto_snapshot_cleanup_test "${RECOVERPOINT_INGEST_VOL1_SRC}" "${RECOVERPOINT_INGEST_VOL1_TGT}" ${RECOVERPOINT_INGEST_SNAPSHOT_VARRAY}

    # Inventory-only remove of RP volume (Note: Don't put "run" in front of this one)
    volume delete ${PROJECT}/"${RECOVERPOINT_INGEST_VOL1_SRC}" --vipronly
}

recoverpoint_ingest_primer()
{
    vpool=${1}

    # In order to be able to ingest RP CGs, you need RP CGs to exist out there already.
    # This method will create those CGs.  For now, it's likely you'll run this, then
    # kill off your DB and run the ingest test
    RECOVERPOINT_INGEST_VOL1_CG=${RECOVERPOINT_INGEST_VOL1_CGBASE}_${vpool}
    run blockconsistencygroup create ${PROJECT} ${RECOVERPOINT_INGEST_VOL1_CG}
    run volume create ${RECOVERPOINT_INGEST_VOL1_SRC}_${vpool} ${PROJECT} ${RECOVERPOINT_VARRAY1} ${vpool} 1GB --consistencyGroup ${RECOVERPOINT_INGEST_VOL1_CG}
    volume delete ${PROJECT}/${RECOVERPOINT_INGEST_VOL1_SRC}_${vpool} --vipronly
}

recoverpoint_failover_test()
{
    echo '*** RP failover tests ***'

    src_volume=${1}
    tgt_volume=${2}

    echo 'Verify the current state of the source and target vols'
    run volume verify ${PROJECT}/${src_volume} personality SOURCE
    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
    run volume verify ${PROJECT}/${src_volume} link_status IN_SYNC
    run volume verify ${PROJECT}/${tgt_volume} personality TARGET
    run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
    run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC

    echo 'Failover'
    run volume change_link ${PROJECT}/${src_volume} failover ${PROJECT}/${tgt_volume} rp

    echo 'Verify post failover'
    run volume verify ${PROJECT}/${src_volume} personality SOURCE
    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
    run volume verify ${PROJECT}/${src_volume} link_status FAILED_OVER
    run volume verify ${PROJECT}/${tgt_volume} personality TARGET
    run volume verify ${PROJECT}/${tgt_volume} access_state READWRITE
    run volume verify ${PROJECT}/${tgt_volume} link_status FAILED_OVER

    echo 'Cancel the failover'
    run volume change_link ${PROJECT}/${src_volume} failover-cancel ${PROJECT}/${tgt_volume} rp

    echo 'Verify post cancel, everything should be back to the start'
    run volume verify ${PROJECT}/${src_volume} personality SOURCE
    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
    run volume verify ${PROJECT}/${src_volume} link_status IN_SYNC
    run volume verify ${PROJECT}/${tgt_volume} personality TARGET
    run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
    run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC

    echo 'Failover again'
    run volume change_link ${PROJECT}/${src_volume} failover ${PROJECT}/${tgt_volume} rp

    echo 'Verify post failover'
    run volume verify ${PROJECT}/${src_volume} personality SOURCE
    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
    run volume verify ${PROJECT}/${src_volume} link_status FAILED_OVER
    run volume verify ${PROJECT}/${tgt_volume} personality TARGET
    run volume verify ${PROJECT}/${tgt_volume} access_state READWRITE
    run volume verify ${PROJECT}/${tgt_volume} link_status FAILED_OVER

    echo 'Swap'
    run volume change_link ${PROJECT}/${src_volume} swap ${PROJECT}/${tgt_volume} rp

    echo 'Verify post swap'
    run volume verify ${PROJECT}/${src_volume} personality TARGET
    run volume verify ${PROJECT}/${src_volume} access_state NOT_READY
    run volume verify ${PROJECT}/${src_volume} link_status IN_SYNC
    run volume verify ${PROJECT}/${tgt_volume} personality SOURCE
    run volume verify ${PROJECT}/${tgt_volume} access_state READWRITE
    run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC

# Expand not working yet, might make separate test for just expand
#run volume expand ${PROJECT}/${tgt_volume} ${RP_SIZE_EXPAND}

    echo 'Failover once again, post swap'
    run volume change_link ${PROJECT}/${tgt_volume} failover ${PROJECT}/${src_volume} rp

    echo 'Verify post failover, post swap'
    run volume verify ${PROJECT}/${src_volume} personality TARGET
    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
    run volume verify ${PROJECT}/${src_volume} link_status FAILED_OVER
    run volume verify ${PROJECT}/${tgt_volume} personality SOURCE
    run volume verify ${PROJECT}/${tgt_volume} access_state READWRITE
    run volume verify ${PROJECT}/${tgt_volume} link_status FAILED_OVER

    echo 'Swap back'
    run volume change_link ${PROJECT}/${tgt_volume} swap ${PROJECT}/${src_volume} rp

    echo 'Verify post swap back, everything should be back to normal'
    run volume verify ${PROJECT}/${src_volume} personality SOURCE
    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
    run volume verify ${PROJECT}/${src_volume} link_status IN_SYNC
    run volume verify ${PROJECT}/${tgt_volume} personality TARGET
    run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
    run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC
}

recoverpoint_cg_failover_test()
{
	# The name of the consistency group to swap
	cg_name=${1}
	# The source source volume - an arbitrary source volume from the CG
	src_volume=${2}
	# The virtual array corresonding to the source volume (src_volume)
	src_varray=${3}
	# The target volume name used to identify all target volumes
	tgt_volumes=${4}
	# The swap target virtual arrays
	tgt_varrays=${5}

	echo '*** RP consistency group failover/swap tests ***'

	# Test the CG swap and swap-back for every target virtual array
	for tgt_varray in ${tgt_varrays}
	do
		echo 'Verify the current state of the source and target vols'
	    run volume verify ${PROJECT}/${src_volume} personality SOURCE
	    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
	    run volume verify ${PROJECT}/${src_volume} link_status IN_SYNC
		
		for tgt_volume in ${tgt_volumes}
		do
	    	run volume verify ${PROJECT}/${tgt_volume} personality TARGET
	    	run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
	    	run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC
		done
		
	    echo 'Failover'
	    run blockconsistencygroup failover $cg_name --copyType rp --targetVarray $tgt_varray
		
	    echo 'Verify post failover'
	    run volume verify ${PROJECT}/${src_volume} personality SOURCE
	    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
	    run volume verify ${PROJECT}/${src_volume} link_status FAILED_OVER
		
		# Post-failover target verification
		for tgt_volume in ${tgt_volumes}
		do
			# If the volume corresponds to the target varray used for the failover we
			# need to verify different values
			if [[ $tgt_volume == *$tgt_varray* ]]
			then
			    run volume verify ${PROJECT}/${tgt_volume} personality TARGET
			    run volume verify ${PROJECT}/${tgt_volume} access_state READWRITE
			    run volume verify ${PROJECT}/${tgt_volume} link_status FAILED_OVER
			else
		    	run volume verify ${PROJECT}/${tgt_volume} personality TARGET
		    	run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
		    	run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC
			fi
		done
		
	    echo 'Cancel the failover'
	    run blockconsistencygroup failover_cancel $cg_name --copyType rp --targetVarray $tgt_varray

	    echo 'Verify post failover cancel, everything should be back to the start'
	    run volume verify ${PROJECT}/${src_volume} personality SOURCE
	    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
	    run volume verify ${PROJECT}/${src_volume} link_status IN_SYNC
		
		for tgt_volume in ${tgt_volumes}
		do
	    	run volume verify ${PROJECT}/${tgt_volume} personality TARGET
	    	run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
	    	run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC
		done
		
	    echo 'Failover again'
	    run blockconsistencygroup failover $cg_name --copyType rp --targetVarray $tgt_varray
		
	    echo 'Verify post failover'
	    run volume verify ${PROJECT}/${src_volume} personality SOURCE
	    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
	    run volume verify ${PROJECT}/${src_volume} link_status FAILED_OVER
		
		# Post-failover target verification
		for tgt_volume in ${tgt_volumes}
		do
			# If the volume corresponds to the target varray used for the failover we
			# need to verify different values
			if [[ $tgt_volume == *$tgt_varray* ]]
			then
			    run volume verify ${PROJECT}/${tgt_volume} personality TARGET
			    run volume verify ${PROJECT}/${tgt_volume} access_state READWRITE
			    run volume verify ${PROJECT}/${tgt_volume} link_status FAILED_OVER
			else
		    	run volume verify ${PROJECT}/${tgt_volume} personality TARGET
		    	run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
		    	run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC
			fi
		done
		
	    echo 'Swap'
	   	run blockconsistencygroup swap $cg_name --copyType rp --targetVarray $tgt_varray

	    echo 'Verify post swap'
	    # Post-swap source verification
	    run volume verify ${PROJECT}/${src_volume} personality TARGET
	    run volume verify ${PROJECT}/${src_volume} access_state NOT_READY
	    run volume verify ${PROJECT}/${src_volume} link_status IN_SYNC
		
		# Post-swap target verification
		for tgt_volume in ${tgt_volumes}
		do
		    run volume verify ${PROJECT}/${tgt_volume} personality SOURCE
		    run volume verify ${PROJECT}/${tgt_volume} access_state READWRITE
		    run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC
		done
		
	    echo 'Failover once again, post swap'
	    run blockconsistencygroup failover $cg_name --copyType rp --targetVarray $tgt_varray

	    echo 'Verify post failover, post swap'
	    run volume verify ${PROJECT}/${src_volume} personality TARGET
	    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
	    run volume verify ${PROJECT}/${src_volume} link_status FAILED_OVER
		
		for tgt_volume in ${tgt_volumes}
		do
			# If the volume corresponds to the target varray used for the failover we
			# need to verify different values
			if [[ $tgt_volume == *$tgt_varray* ]]
			then
			    run volume verify ${PROJECT}/${tgt_volume} personality SOURCE
			    run volume verify ${PROJECT}/${tgt_volume} access_state READWRITE
			    run volume verify ${PROJECT}/${tgt_volume} link_status FAILED_OVER
			else
		    	run volume verify ${PROJECT}/${tgt_volume} personality SOURCE
		    	run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
		    	run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC
			fi
		done
		
	    echo 'Swap back'
		# Swap-back
		run blockconsistencygroup swap $cg_name --copyType rp --targetVarray $src_varray

	    echo 'Verify post swap back, everything should be back to normal'
		# swap-back source verification
	    run volume verify ${PROJECT}/${src_volume} personality SOURCE
	    run volume verify ${PROJECT}/${src_volume} access_state READWRITE
	    run volume verify ${PROJECT}/${src_volume} link_status IN_SYNC
		
		# swap-back target verification
		for tgt_volume in ${tgt_volumes}
		do
	    	run volume verify ${PROJECT}/${tgt_volume} personality TARGET
	    	run volume verify ${PROJECT}/${tgt_volume} access_state NOT_READY
	    	run volume verify ${PROJECT}/${tgt_volume} link_status IN_SYNC
		done
	done
}

recoverpoint_vpool_change_test()
{
    base_volume=${1}
    noprotection_vpool=${2}
    rp_vpool=${3}
    rp_cg=${4}

    echo 'Change Virtual Pool - Remove Protection'
    run volume change_cos ${PROJECT}/${base_volume} ${noprotection_vpool}

    echo 'Change Virtual Pool - Add Protection'
    run volume change_cos ${PROJECT}/${base_volume} ${rp_vpool} --consistencyGroup ${rp_cg}
}

recoverpoint_add_journal_volume()
{
   copy_name=${1}
   journ_varray=${2} 
   journ_vpool=${3}     
   rp_cg=${4}

   echo '*** RP add journal volume ***'
   run volume add_journal ${copy_name} $PROJECT ${journ_varray} ${journ_vpool} 10GB --consistencyGroup ${rp_cg} --count=1  
}

# Simulator setup
recoverpoint_simulator_setup()
{
    echo 'Sim running'
    project_setup
    rp_varray_setup


    syssvc $CONFIG_FILE localhost set_prop controller_discovery_refresh_interval 5
    #    elif [ "$PARAM" = "simulator" ]; then

    # Simulators being used
#    echo 'Using simulators in recoverpoint_setup_once'
#    smisprovider show $PROVIDER_SIMULATOR &> /dev/null && return $?
     # smisprovider create $PROVIDER_SIMULATOR $RP_PROVIDER_SIMULATOR_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
     run smisprovider create $PROVIDER_SIMULATOR $RP_PROVIDER_SIMULATOR_IP $RP_VMAX_SMIS_SIM_PORT $SMIS_USER "$SMIS_PASSWD" false
     run networksystem create $FABRIC_SIMULATOR  mds --devip $SIMULATOR_CISCO_MDS_IP --devport 22 --username $RP_FABRIC_SIM_USER --password $RP_FABRIC_SIM_PW
#
#    transportzone listall
#    echo 'sleeping 30s after network system create to allow for discovery'
     run transportzone assign ${SIMULATOR_VSAN_11} $RECOVERPOINT_VARRAY1
#
     storagedevice discover_all
#    storagedevice list
#
     
     POOLS_AUTO_MATCH=false

     RECOVERPOINT=$RP_SIMULATOR
     RECOVERPOINT_IP=$RP_SIMULATOR_IP
     rp_protection_system_setup

     run protectionsystem update --ip ${remote_ip} --name $RECOVERPOINT --cluster site_1rp1 --addvarrays $RECOVERPOINT_VARRAY1
     run protectionsystem update --ip ${remote_ip} --name $RECOVERPOINT --cluster site_2rp1 --addvarrays $RECOVERPOINT_VARRAY2
     run protectionsystem update --ip ${remote_ip} --name $RECOVERPOINT --cluster site_3rp1 --addvarrays $RECOVERPOINT_VARRAY3

     run storagepool update $VMAX1_SIMULATOR_NATIVEGUID --nhadd $RECOVERPOINT_VARRAY1 --type block
     run storagepool update $VMAX2_SIMULATOR_NATIVEGUID --nhadd $RECOVERPOINT_VARRAY2 --type block

     # Simulator adjustments to cos (shouldn't be needed but RP simulator only sees a subset of what's on the network)
     rp_targets
     run cos update block rp_targets --storage $VMAX1_SIMULATOR_NATIVEGUID
     rp_cdp
     run cos update block rp_cdp --storage $VMAX1_SIMULATOR_NATIVEGUID

#
#        # VPLEX
#        VPLEX_DEV_NAME=$VPLEX_SIMULATOR
#        VPLEX_IP=$SIMULATOR_IP
#        storageprovider show $VPLEX_DEV_NAME &> /dev/null && return $?
#        run storageprovider create $VPLEX_DEV_NAME $VPLEX_IP 443 $VPLEX_USER "$VPLEX_PASSWD" vplex
#        run storagedevice discover_all
#        transportzone assign ${SIMULATOR_VSAN_11} $NH
#
#        # simulators being used

#
#        # simulators being used
#        echo 'Using simulators in recoverpoint_common_setup'
#        transportzone assign ${SIMULATOR_VSAN_11} $NH
#        RP_NATIVE_GUID=$VMAX1_SIMULATOR_NATIVEGUID
#    fi
}


recoverpoint_common_setup()
{
    project_setup
    rp_varray_setup
    rp_network_setup
    rp_smis_setup
    rp_port_setup
    rp_protection_system_setup
    sleep 30
    rp_isolate_rpa_clusters
    rp_vpool_setup
}

recoverpoint_setup()
{
    POOLS_AUTO_MATCH=true
    if [ "$RP_RUN_SETUP" = "1" ]; then
        if [ "$RP_QUICK_PARAM" = "quick" ]; then
            echo '*** RecoverPoint Simulator setup ***'
            recoverpoint_simulator_setup
        else
            echo '*** RecoverPoint setup ***'
            recoverpoint_common_setup
        fi
    fi
}

recoverpoint_cleanup_volumes()
{
    vol=${1}
    volcount=${2}

    # Cleanup volumes
    if [ "$volcount" = "1" ]; then
        run volume delete $PROJECT/${vol} --wait
    else
        for (( i=1; i<=$volcount; i++ ))
        do
            run volume delete $PROJECT/${vol}-$i --wait
        done
    fi
}

recoverpoint_cleanup_cgs()
{
    # Cleanup CGs
    if [ "${RP_INGESTTEST}" = "0" ]; then
	run blockconsistencygroup delete $RP_CONSISTENCY_GROUP
	if [ "${RPVPLEX_TESTS}" = "1" ]; then
	    run blockconsistencygroup delete $RP_VPLEX_CONSISTENCY_GROUP
	    run blockconsistencygroup delete $RP_METROPOINT_CONSISTENCY_GROUP
	fi
    fi
}

recoverpoint_tests()
{
    if [ "$RP_RUN_TESTS" = "1" ]; then
        echo '*** Run RP tests ***'

        # Setup CGs
        rp_cg_setup

        rp_src_varray=$RECOVERPOINT_VARRAY1
        rpvplex_src_varray=$RECOVERPOINT_VARRAY1
        mp_src_varray=$RECOVERPOINT_VARRAY1

        rp_noprotection_vpool='rp_noprotection'
        rpvplex_noprotection_vpool='rpvplexdist_noprotection'
        mp_noprotection_vpool='rpvplexdist_noprotection'

        rp_type=''

        if [ "$RP_CDP" = "1" ]; then
            echo 'RP CDP Tests'
            rp_type='cdp'

            # RP
            rp_tgt_varray=$RECOVERPOINT_VARRAY1
			rp_tgt_varrays=($RECOVERPOINT_VARRAY1)
            rp_tgt_vpool='rp_targets'

            # RP+VPLEX
            rpvplex_tgt_varray=$RECOVERPOINT_VARRAY1
			rpvplex_tgt_varrays=($RECOVERPOINT_VARRAY1)
            rpvplex_tgt_vpool='rpvplex_targets'
            # RP+VPLEX CDP uses VPLEX local, set this for no protection vpool
            rpvplex_noprotection_vpool='rpvplexlocal_noprotection'

            # MP
            mp_active_tgt_varray=$RECOVERPOINT_VARRAY1
            mp_standby_tgt_varray=$RECOVERPOINT_VARRAY2
			mp_tgt_varrays=($RECOVERPOINT_VARRAY1 $RECOVERPOINT_VARRAY2)
            mp_tgt_vpool='rp_targets'
        fi

        if [ "$RP_CRR" = "1" ]; then
            echo 'RP CRR Tests'
            rp_type='crr'

            # RP
            rp_tgt_varray=$RECOVERPOINT_VARRAY3
			rp_tgt_varrays=($RECOVERPOINT_VARRAY3)
            rp_tgt_vpool='rp_targets'

            # RP+VPLEX
            rpvplex_tgt_varray=$RECOVERPOINT_VARRAY3
			rpvplex_tgt_varrays=($RECOVERPOINT_VARRAY3)
            rpvplex_tgt_vpool='rpvplex_targets'

            # MP
            mp_active_tgt_varray=$RECOVERPOINT_VARRAY3
			mp_tgt_varrays=($RECOVERPOINT_VARRAY3)
            mp_standby_tgt_varray=''
            mp_tgt_vpool='rp_targets'
        fi

        if [ "$RP_CLR" = "1" ]; then
            echo 'RP CLR Tests'
            rp_type='clr'

            # RP
            rp_tgt_varray=$RECOVERPOINT_VARRAY3
			rp_tgt_varrays=($RECOVERPOINT_VARRAY1 $RECOVERPOINT_VARRAY3)
            rp_tgt_vpool='rp_targets'

            # RP+VPLEX
            rpvplex_tgt_varray=$RECOVERPOINT_VARRAY1
			rpvplex_tgt_varrays=($RECOVERPOINT_VARRAY1 $RECOVERPOINT_VARRAY3)
            rpvplex_tgt_vpool='rpvplex_targets'

            # MP
            mp_active_tgt_varray=$RECOVERPOINT_VARRAY3
			mp_tgt_varrays=($RECOVERPOINT_VARRAY1 $RECOVERPOINT_VARRAY2 $RECOVERPOINT_VARRAY3)
            mp_standby_tgt_varray=''
            mp_tgt_vpool='rp_targets'
        fi

        # RP
        rp_src_vpool='rp_'$rp_type
        rpvolume=${RP_VOLUME}
        rpvolumetarget=${rpvolume}'-target-'${rp_tgt_varray}

        # RP+VPLEX
        rpvplex_src_vpool='rpvplex_'$rp_type
        rpvplexvolume=${RP_VPLEX_VOLUME}
        rpvplexvolumetarget=${rpvplexvolume}'-target-'${rpvplex_tgt_varray}

        # MP
        mp_src_vpool='mp_'$rp_type
        mpvolume=${RP_METROPOINT_VOLUME}
        mpvolumetarget=${mpvolume}'-target-'${mp_active_tgt_varray}

        # Setup test volumes...
        # Either use volumes that have gone through the change vpool process or
        # use straight up created RP volumes.
        if [ "$RP_CHANGE_VPOOL" = "1" ]; then
            echo '*** RP change vpool volumes ***'

            if [ "$RP_TESTS" = "1" ]; then
                echo 'RP change vpool...'
                recoverpoint_vpool_change_test ${rpvolume} ${rp_base_cvp} ${rp_src_varray} ${rp_src_vpool} ${RP_CONSISTENCY_GROUP}
            fi

            if [ "$RPVPLEX_TESTS" = "1" ]; then
                echo 'RP+VPLEX change vpool...NOT SUPPORTED YET!!'
                #recoverpoint_vpool_change_test ${rpvplexvolume} ${rpvplex_base_cvp1} ${rpvplex_src_varray} ${rpvplex_src_vpool} ${RP_VPLEX_CONSISTENCY_GROUP}
            fi

            if [ "$MP_TESTS" = "1" ]; then
                echo 'MP change vpool...NOT SUPPORTED YET!!'
            fi

        elif [ "$RP_INGESTPRIMEONLY" = "1" ]; then
	    echo '*** RP ingest volumes priming only ***'
	    if [ "$RP_CDP" = "1" ] ; then
		recoverpoint_ingest_primer rp_cdp
	    elif [ "$RP_CRR" = "1" ] ; then
		recoverpoint_ingest_primer rp_crr
	    elif [ "$RP_CLR" = "1" ] ; then
		recoverpoint_ingest_primer rp_clr
	    fi
	    exit
        elif [ "$RP_INGESTTESTS" = "1" ]; then
	    echo '*** RP ingest volumes ***'
	    recoverpoint_ingest_setup

	    if [ "$RP_CDP" = "1" ] ; then
		recoverpoint_ingest_test rp_cdp
	    fi

	    if [ "$RP_CRR" = "1" ] ; then
		recoverpoint_ingest_test rp_crr
	    fi

	    if [ "$RP_CLR" = "1" ] ; then
		recoverpoint_ingest_test rp_clr
	    fi
	else
            echo '*** RP create volumes ***'

            if [ "$RP_TESTS" = "1" ]; then
                echo 'RP volume create...'
                run volume create ${rpvolume} $PROJECT ${rp_src_varray} ${rp_src_vpool} $RP_VOLUME_SIZE --consistencyGroup $RP_CONSISTENCY_GROUP --count=$RP_VOLUME_COUNT
            fi

            if [ "$RPVPLEX_TESTS" = "1" ]; then
                echo 'RP+VPLEX volume create...'
                run volume create ${rpvplexvolume} $PROJECT ${rpvplex_src_varray} ${rpvplex_src_vpool} $RP_VOLUME_SIZE --consistencyGroup $RP_VPLEX_CONSISTENCY_GROUP --count=$RP_VOLUME_COUNT
            fi

            if [ "$MP_TESTS" = "1" ]; then
                echo 'MetroPoint volume create...'
                run volume create ${mpvolume} $PROJECT ${mp_src_varray} ${mp_src_vpool} $RP_VOLUME_SIZE --consistencyGroup $RP_METROPOINT_CONSISTENCY_GROUP --count=$RP_VOLUME_COUNT
            fi
	fi

        # Have to account for "-1" being added to volume name if
        # volume count is greater than 1.
        volume_name_modifier=''
        if [ "$RP_VOLUME_COUNT" = "1" ]; then
            volume_name_modifier=''
        else
            volume_name_modifier='-1'
        fi

        # Run change vpool tests on the volume if the flag is set.
        if [ "$RP_CHANGE_VPOOL" = "1" ]; then
            echo '*** RP change vpool volumes ***'

            if [ "$RP_TESTS" = "1" ]; then
                echo 'RP change vpool...'
                recoverpoint_vpool_change_test ${rpvolume}${volume_name_modifier} ${rp_noprotection_vpool} ${rp_src_vpool} ${RP_CONSISTENCY_GROUP}
            fi

            if [ "$RPVPLEX_TESTS" = "1" ]; then
                echo 'RP+VPLEX change vpool'
                recoverpoint_vpool_change_test ${rpvplexvolume}${volume_name_modifier} ${rpvplex_noprotection_vpool} ${rpvplex_src_vpool} ${RP_VPLEX_CONSISTENCY_GROUP}
            fi

            if [ "$MP_TESTS" = "1" ]; then
                echo 'MP change vpool'
                recoverpoint_vpool_change_test ${mpvolume}${volume_name_modifier} ${mp_noprotection_vpool} ${mp_src_vpool} ${RP_METROPOINT_CONSISTENCY_GROUP}
            fi
        fi

        # Compile a list of target volume names that have been created for RP
	rp_tgt_volumes=()
	for tgt in ${rp_tgt_varrays}
	  do
	  rp_tgt_volumes=("${rp_tgt_volumes[@]}" "${rpvolume}-target-${tgt}${volume_name_modifier}")
	done
	
	# Compile a list of target volume names that have been created for RP+VPlex		
	rp_vplex_tgt_volumes=()
	for tgt in ${rpvplex_tgt_varrays}
	  do
	  rp_vplex_tgt_volumes=("${rp_vplex_tgt_volumes[@]}" "${rpvplexvolume}-target-${tgt}${volume_name_modifier}")
	done
	
	# Compile a list of target volume names that have been created for MetroPoint		
	mp_tgt_volumes=()
	for tgt in ${mp_tgt_varrays}
	  do
	  mp_tgt_volumes=("${mp_tgt_volumes[@]}" "${mpvolume}-target-${tgt}${volume_name_modifier}")
	done

        ### Begin Recoverpoint test cases ###

        # RP test cases
        # Run these test cases unless specified to only run create/delete tests
        if [ "$RP_RUN_VOLUME_CREATE_ONLY" = "0" ]; then

            if [ "$RP_TESTS" = "1" ]; then
                echo 'RP tests...'
		# Add Journal Test
		recoverpoint_add_journal_volume ${rp_tgt_varray} ${rp_tgt_varray} ${rp_tgt_vpool} ${RP_CONSISTENCY_GROUP}
		
                # Snapshot/Bookmark Test
                recoverpoint_auto_snapshot_cleanup_test ${rpvolume}${volume_name_modifier} ${rpvolumetarget}${volume_name_modifier} ${rp_src_varray}

                # Failover Test
                recoverpoint_failover_test ${rpvolume}${volume_name_modifier} ${rpvolumetarget}${volume_name_modifier}
				
		# CG Failover/Swap Test
		recoverpoint_cg_failover_test ${RP_CONSISTENCY_GROUP} ${rpvolume}${volume_name_modifier} ${rp_src_varray} ${rp_tgt_volumes} ${rp_tgt_varrays}
	    fi

            # RP+VPLEX test cases
            if [ "$RPVPLEX_TESTS" = "1" ]; then
                echo 'RP+VPLEX tests...'
                # Add Journal Test
		recoverpoint_add_journal_volume ${rpvplex_tgt_varray} ${rpvplex_tgt_varray} ${rpvplex_tgt_vpool} ${RP_VPLEX_CONSISTENCY_GROUP}
		
                # Snapshot/Bookmark Test
                recoverpoint_auto_snapshot_cleanup_test ${rpvplexvolume}${volume_name_modifier} ${rpvplexvolumetarget}${volume_name_modifier} ${rpvplex_src_varray}

                # Failover Test
                recoverpoint_failover_test ${rpvplexvolume}${volume_name_modifier} ${rpvplexvolumetarget}${volume_name_modifier}
				
		# CG Failover/Swap Test
		recoverpoint_cg_failover_test ${RP_VPLEX_CONSISTENCY_GROUP} ${rpvplexvolume}${volume_name_modifier} ${rpvplex_src_varray} ${rp_vplex_tgt_volumes} ${rp_tgt_varrays}
            fi

            # MP test cases
            if [ "$MP_TESTS" = "1" ]; then
                echo 'MetroPoint tests...'
		# Add Journal Test
		recoverpoint_add_journal_volume ${mp_active_tgt_varray} ${mp_active_tgt_varray} ${mp_tgt_vpool} ${RP_METROPOINT_CONSISTENCY_GROUP}
		
                # Snapshot/Bookmark Test
                recoverpoint_auto_snapshot_cleanup_test ${mpvolume}${volume_name_modifier} ${mpvolumetarget}${volume_name_modifier} ${mp_src_varray}

                # Failover Test
                recoverpoint_failover_test ${mpvolume}${volume_name_modifier} ${mpvolumetarget}${volume_name_modifier}
				
		# CG Failover/Swap Test
		recoverpoint_cg_failover_test ${RP_METROPOINT_CONSISTENCY_GROUP} ${mpvolume}${volume_name_modifier} ${mp_src_varray} ${mp_tgt_volumes} ${mp_tgt_varrays}
            fi
        fi

        ### End Recoverpoint test cases ###

        echo '*** RP cleanup ***'

        if [ "$RP_TESTS" = "1" ]; then
            echo 'RP volume cleanup...'
            recoverpoint_cleanup_volumes ${rpvolume} $RP_VOLUME_COUNT
        fi

        if [ "$RPVPLEX_TESTS" = "1" ]; then
            echo 'RP+VPLEX volume cleanup...'
            recoverpoint_cleanup_volumes ${rpvplexvolume} $RP_VOLUME_COUNT
        fi

        if [ "$MP_TESTS" = "1" ]; then
            echo 'MP volume cleanup...'
            recoverpoint_cleanup_volumes ${mpvolume} $RP_VOLUME_COUNT
        fi

        echo 'CG cleanup...'
        recoverpoint_cleanup_cgs

        echo '*** RP tests done ***'
    fi
}

#
#
#
######################### End of RecoverPoint ############################

hds_cos_setup()
{
    cos create block $COS_HDS               \
             --description 'CoS for HDS' true  \
                      --protocols FC \
                      --numpaths 1              \
                      --provisionType 'Thin'        \

    cos allow $COS_HDS block $TENANT
}

hds_setup()
{
    hds_setup_once
}

hds_setup_once()
{

    # Discovery the storage systems 
    storageprovider show $HDS_PROVIDER &> /dev/null && return $?
    storageprovider create $HDS_PROVIDER $HDS_PROVIDER_IP $HDS_PROVIDER_PORT $HDS_PROVIDER_USER "$HDS_PROVIDER_PASSWD" $HDS_PROVIDER_INTERFACE_TYPE --usessl false
    storagedevice discover_all
    storagedevice list

    hds_cos_setup
}

#
# hds tests
#
hds_tests()
{
    echo "**** Done hds"
}


#
# add an isilon storage device with a default pool that supports NFS and N+2:1 protection
#
isilon_setup_once()
{
    # do this only once
    discoveredsystem show $ISI_NATIVEGUID &> /dev/null && return $?

    discoveredsystem create $ISI_DEV isilon $ISI_IP 8080 $ISI_USER $ISI_PASSWD --serialno=$ISI_SN
    
    isilon_cos_setup

    storagepool   update $ISI_NATIVEGUID --type file
    storageport   update $ISI_NATIVEGUID IP --tzone $NH/$IP_ZONE

    cos update file $COS_ISIFILE --storage $ISI_NATIVEGUID
    #isilon_cos_setup
}

isilon_setup()
{
    isilon_setup_once
    cos allow $COS_ISIFILE file $TENANT
}

#
# add ECS storage device and storage pool
#
ecs_setup_once()
{
    #discoveredsystem show $ECS_DEV &> /dev/null && return $?
    discoveredsystem create $ECS_DEV ecs $ECS_IP 4443 $ECS_USER $ECS_PASSWD

    storagepool update $ECS_NATIVEGUID --nhadd $NH
    storageport update $ECS_NATIVEGUID IP --addvarrays $NH

    ecs_cos_setup
    
    tenant update_namespace $TENANT  $ECS_NAMESPACE
    project create $PROJECT --tenant $TENANT 
}

ecs_setup()
{
    echo "Performing ecs_setup"
    ecs_setup_once
}

#
# add vnx file device with a storage pool that supports NFS and COS_VNX_PROTECTION protection
# add server_{2,3,4} data mover storage ports to this device, connected to the IP transport zone
#
netapp_setup_once()
{
    #do this only once
    storagedevice show $NETAPPF_NATIVEGUID &> /dev/null && return $?

    discoveredsystem create $NETAPPF_DEV netapp $NETAPPF_IP $NETAPPF_PORT $NETAPPF_USER $NETAPPF_PW --serialno=$NETAPPF_SN
    netapp_cos_setup

    storagepool update $NETAPPF_NATIVEGUID --type file
    
    storageport update $NETAPPF_NATIVEGUID IP --tzone nh/iptz
    cos update file $COS_NETAPP --storage $NETAPPF_NATIVEGUID

   # netapp_cos_setup
}

netapp_setup()
{
    netapp_setup_once
    cos allow $COS_NETAPP file $TENANT
}

netappc_setup_once()
{
    #do this only once
    storagedevice show $NETAPPCF_NATIVEGUID &> /dev/null && return $?

    discoveredsystem create $NETAPPCF_DEV netappc $NETAPPCF_IP $NETAPPCF_PORT $NETAPPCF_USER $NETAPPCF_PW --serialno=$NETAPPCF_SN
    netappc_cos_setup

    storagepool update $NETAPPCF_NATIVEGUID --type file

    storageport update $NETAPPCF_NATIVEGUID IP --tzone nh/iptz
    cos update file $COS_NETAPPC --storage $NETAPPCF_NATIVEGUID

   # netapp_cos_setup
}

netappc_setup()
{
    netappc_setup_once
    cos allow $COS_NETAPPC file $TENANT
}

#
# add datadomain file device with a storage pool that supports NFS and CIFS
# add server_{2,3,4} data mover storage ports to this device, connected to the IP transport zone
#
datadomainfile_setup_once()
{
    #do this only once

    # Discover the storage systems 
    storageprovider show $DATADOMAINF_DEV &> /dev/null && return $?
    echo "Starting storageprovider create"
    storageprovider create $DATADOMAINF_DEV $DATADOMAINF_DEV_IP $DATADOMAINF_PORT $DATADOMAINF_USER "$DATADOMAINF_PW" $DATADOMAINF_PROVIDER_INTERFACE 
    echo "Storageprovider create done"
    storagedevice discover_all
    storagedevice list
    storageport list $DATADOMAINF_NATIVEGUID
    storagedevice show $DATADOMAINF_NATIVEGUID &> /dev/null && return $?

#    # Discover the storage systems 
#    smisprovider show $VPLEX_VMAX_SMIS_DEV_NAME &> /dev/null && return $?
#    smisprovider create $VPLEX_VMAX_SMIS_DEV_NAME $VPLEX_VMAX_SMIS_IP 5988 $VPLEX_SMIS_USER "$VPLEX_SMIS_PASSWD" false
#    smisprovider create $VPLEX_VNX_SMIS_DEV $VPLEX_VNX_SMIS_IP 5988 $VPLEX_SMIS_USER "$VPLEX_SMIS_PASSWD" false
#    storageprovider show $VPLEX_DEV_NAME &> /dev/null && return $?
#    storageprovider create $VPLEX_DEV_NAME $VPLEX_IP 443 $VPLEX_USER "$VPLEX_PASSWD" vplex
#    storagedevice discover_all
#    storagedevice list
#    storageport list $VPLEX_VNX_NATIVEGUID
#    storageport list $VPLEX_VMAX_NATIVEGUID
#    storageport list $VPLEX_GUID

    # discoveredsystem create $DATADOMAINF_DEV datadomain $DATADOMAINF_IP $DATADOMAINF_PORT $DATADOMAINF_USER $DATADOMAINF_PW --serialno=$DATADOMAINF_SN
    datadomainfile_cos_setup

    storagepool update $DATADOMAINF_NATIVEGUID --type file

    storageport update $DATADOMAINF_NATIVEGUID IP --tzone nh/iptz
    cos update file $COS_DDFILE --storage $DATADOMAINF_NATIVEGUID

}

datadomainfile_setup()
{
    datadomainfile_setup_once
    cos allow $COS_DDFILE file $TENANT
}

#
# add vnx file device with a storage pool that supports NFS and COS_VNX_PROTECTION protection
# add server_{2,3,4} data mover storage ports to this device, connected to the IP transport zone
#
vnxfile_setup_once()
{

    vnxfile_discovery

    storagepool update $VNXF_NATIVEGUID --type file

    storageport update $VNXF_NATIVEGUID IP --tzone nh/iptz
    cos update file $COS_VNXFILE --storage $VNXF_NATIVEGUID

   # vnxfile_cos_setup
}

vnxfile_setup()
{
    vnxfile_setup_once
    cos allow $COS_VNXFILE file $TENANT
}

vnxfile_discovery()
{
    #do this only once
    storagedevice show $VNXF_NATIVEGUID &> /dev/null && return $?

    discoveredsystem create $VNXF_DEV vnxfile $VNXF_IP $VNXF_PORT $VNXF_USER $VNXF_PW \
                         --smisip=$VNXF_SMIS_IP --smisport=$VNXF_SMIS_PORT --smisuser=nasadmin \
                         --smispw=nasadmin --smisssl=true --serialno=$VNXF_SN
    vnxfile_cos_setup
}

vnxfile_flex_varray_setup_once()
{
    vnxfile_discovery

    neighborhood create $NH3
    neighborhood show $NH3

    transportzone create2 $IP_ZONE3 IP --endpoints $VNXF_IP_ENDPOINT1,$VNXF_IP_ENDPOINT2,client1.emc.com,client2.emc.com

    # update the varray to add some ports
    storageport update $VNXF_NATIVEGUID IP --name 'spvnx1' --addvarrays $NH3
    storageport update $VNXF_NATIVEGUID IP --name 'spvnx2' --addvarrays $NH3
}

vnxfile_flex_varray_setup()
{
    vnxfile_flex_varray_setup_once
    cos allow $COS_VNXFILE file $TENANT
}

vnxe_setup_once()
{

    vnxe_discovery

	vnxe_cos_setup
	
    storagepool update $VNXE_NATIVEGUID --type file

    storageport update $VNXE_NATIVEGUID IP --tzone nh/iptz
    cos update file $COS_VNXE --storage $VNXE_NATIVEGUID
    
    storagepool update $VNXE_NATIVEGUID --type block --volume_type THIN_AND_THICK
    echo "vnxe block cos update"
    cos update block $COS_VNXEBLOCK_CG --storage $VNXE_NATIVEGUID
   # cos update block $COS_VNXEBLOCK_FC --storage $VNXE_NATIVEGUID
    cos update block $COS_VNXEBLOCK_ISCSI --storage $VNXE_NATIVEGUID
   
}

vnxe_setup()
{
    vnxe_setup_once
    cos allow $COS_VNXE file $TENANT
}

vnxe_discovery()
{
    #do this only once
    storagedevice show $VNXE_NATIVEGUID &> /dev/null && return $?

    discoveredsystem create $VNXE_DEV vnxe $VNXE_IP $VNXE_PORT $VNXE_USER $VNXE_PW \
                         --serialno=$VNXE_SN

}

ui_setup()
{
    echo "Nothing to do for ui setup"
}

namespace_test() {
    cos=$1; shift
    kpname=$(python -c 'import uuid; print uuid.uuid1()')
#    run namespace sanity --tenant $TENANT $NAMESPACE
}

retentionclass_test() {

    run retentionclass sanity $NAMESPACE "class_"
}

s3_baseurl_setup() {
    create_if_not_present=$1;
    if [ -n "$create_if_not_present"  ]; then
        is_present=$(run baseurl list | (grep 's3.amazonaws.com' || echo ''))
        if [ "$is_present" == '' ]; then
            echo "Default base URL entry not present, hence inserting it"
            run baseurl create "DefaultBaseUrl" "s3.amazonaws.com" false
        fi
    else
        run baseurl create "DefaultBaseUrl" "s3.amazonaws.com" false
    fi
}

s3_bucket_tests() {


    cos=$1; uid=$2; secret=$3; shift
    kpname=bucketsanitytest-$cos-$(python -c 'import uuid; print uuid.uuid1()')
    run bucket sanity $NAMESPACE $kpname --uid $uid --secret=$secret
}

s3_versioning_tests() {
    cos=$1; uid=$2; secret=$3; shift
    kpname=$(python -c 'import uuid; print uuid.uuid1()')
    run bucket create $NAMESPACE $kpname --uid $uid --secret=$secret
    run versioning sanity $NAMESPACE $kpname --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $kpname --uid $uid --secret=$secret
}

s3_multipart_upload_tests() {
    cos=$1; uid=$2; secret=$3; shift
    kpname=$(python -c 'import uuid; print uuid.uuid1()')
    keyname=key-$cos
    run bucket create $NAMESPACE $kpname --uid $uid --secret=$secret
    run s3_multipart_upload.py sanity $NAMESPACE $kpname $keyname --uid $uid --secret=$secret

    # copy part tests
    keysuffix=$(python -c 'import uuid; print uuid.uuid1()')
    srckpname=mpusrcbucket-$keysuffix
    # create source bucket
    run bucket create $NAMESPACE $srckpname --uid $uid --secret=$secret
    # create source object
    srckeyname=mpusrckey-$keysuffix
    run bucketkey create $NAMESPACE $srckpname $srckeyname copy-key-value-$cos --uid $uid --secret=$secret
    # copy source object as part to dest
    run s3_multipart_upload.py sanity_copy $NAMESPACE $kpname $keyname --srcbucket $srckpname --srckey $srckeyname --uid $uid --secret=$secret

    run bucketkey clean $NAMESPACE $srckpname --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $srckpname --uid $uid --secret=$secret

    run bucketkey clean $NAMESPACE $kpname --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $kpname --uid $uid --secret=$secret
}

swift_container_tests() {
    cos=$1; uid=$2; password=$3; shift
    kpname=contsanitytest-$cos-$(python -c 'import uuid; print uuid.uuid1()')
    run swift_container.py sanity $NAMESPACE $kpname --uid $uid --password=$password
}

swift_setup_uid_password() {
    uid=$1; password=$2; shift
    run password.py create $uid $password s3 --groups="admin"
}

swift_cleanup_uid_password() {
    uid=$1; shift
    run password.py remove $uid
}

atmos_subtenant_tests() {
    cos=$1; uid=$2; secret=$3; shift
    run atmossubtenant sanity $NAMESPACE $PROJECT $cos --uid $uid --secret=$secret
}

s3_key_tests(){
    cos=$1; uid=$2; secret=$3; testUid=$4; shift
    kpname=$(python  -c 'import uuid; print uuid.uuid1()')
    run bucket create $NAMESPACE $kpname --uid $uid --secret=$secret
    run bucketkey sanity $NAMESPACE $kpname key-$cos value-$cos  --uid $uid --secret=$secret --testUser=$testUid
    run bucket delete $NAMESPACE $kpname --uid $uid --secret=$secret

    run bucket create $NAMESPACE $kpname --uid $uid --secret=$secret --fileSystemEnabled=true
    run bucketkey filesystemsanity $NAMESPACE $kpname key-$cos value-$cos  --uid $uid --secret=$secret --testUser=$testUid
    run bucket delete $NAMESPACE $kpname --uid $uid --secret=$secret

}

s3_key_copy_tests(){
    cos=$1; uid=$2; secret=$3; shift
    sourcekpname=$(python  -c 'import uuid; print uuid.uuid1()')
    destkpname=$(python  -c 'import uuid; print uuid.uuid1()')
    run bucket create $NAMESPACE $sourcekpname --uid $uid --secret=$secret
    run bucket create $NAMESPACE $destkpname --uid $uid --secret=$secret

    keysuffix=$(python  -c 'import uuid; print uuid.uuid1()')

    # create source object
    sourcekeyname=copy-source-key-$keysuffix
    run bucketkey create $NAMESPACE $sourcekpname $sourcekeyname copy-key-value-$cos --uid $uid --secret=$secret
    # copy source object to dest
    run bucketkey copy $NAMESPACE $sourcekpname $sourcekeyname --destbucket $destkpname --destkey copy-dest-key-$keysuffix --uid $uid --secret=$secret

    # create source object with chars that need to be URL-encoded in copy-source header
    sourcekeyname2=copy,source:key/$keysuffix
    run bucketkey create $NAMESPACE $sourcekpname $sourcekeyname2 copy-key-value-$cos --uid $uid --secret=$secret
    # copy source object to dest
    run bucketkey copy $NAMESPACE $sourcekpname $sourcekeyname2 --destbucket $destkpname --destkey copy-dest-key2-$keysuffix --uid $uid --secret=$secret
    run bucketkey clean $NAMESPACE $sourcekpname --uid $uid --secret=$secret
    run bucketkey clean $NAMESPACE $destkpname --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $sourcekpname --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $destkpname --uid $uid --secret=$secret
}

s3_key_version_tests(){
    cos=$1; uid=$2; secret=$3; shift
    kpname=$(python  -c 'import uuid; print uuid.uuid1()')
    run bucket create $NAMESPACE $kpname --uid $uid --secret=$secret
    run versioning put $NAMESPACE $kpname Enabled --uid $uid --secret=$secret
    run bucketkey sanity $NAMESPACE $kpname key-$cos value-$cos  --uid $uid --secret=$secret --testUser=$testUid
    run versioning put $NAMESPACE $kpname Suspended --uid $uid --secret=$secret
    run bucketkey sanity $NAMESPACE $kpname key-$cos value-$cos  --uid $uid --secret=$secret --testUser=$testUid
    run bucketkey clean_ver $NAMESPACE $kpname --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $kpname --uid $uid --secret=$secret
}

s3_fileaccess_tests() {
    cos=$1; uid=$2; secret=$3; shift

    kpname1="$(python  -c 'import uuid; print uuid.uuid1()')-S3"
    run bucket create $NAMESPACE $kpname1 --uid $uid --secret=$secret
    run fileaccesssanity.py s3 $NAMESPACE $kpname1 $cos $uid $secret

    kpname2="$(python  -c 'import uuid; print uuid.uuid1()')-S3"
    run bucket create $NAMESPACE $kpname2 --uid $uid --secret=$secret
    run fileaccesssanity.py s3 $NAMESPACE $kpname2 $cos $uid $secret True

    fskpname1="$(python  -c 'import uuid; print uuid.uuid1()')-S3"
    run bucket create $NAMESPACE $fskpname1 --uid $uid --secret=$secret --fileSystemEnabled=True
    run fileaccesssanity.py s3 $NAMESPACE $fskpname1 $cos $uid $secret

    fskpname2="$(python  -c 'import uuid; print uuid.uuid1()')-S3"
    run bucket create $NAMESPACE $fskpname2 --uid $uid --secret=$secret --fileSystemEnabled=True
    run fileaccesssanity.py s3 $NAMESPACE $fskpname2 $cos $uid $secret True

    run bucketkey clean $NAMESPACE $kpname1 --uid $uid --secret=$secret
    run bucketkey clean $NAMESPACE $kpname2 --uid $uid --secret=$secret
    run bucketkey clean $NAMESPACE $fskpname1 --uid $uid --secret=$secret
    run bucketkey clean $NAMESPACE $fskpname2 --uid $uid --secret=$secret

    run bucket delete $NAMESPACE $kpname1 --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $kpname2 --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $fskpname1 --uid $uid --secret=$secret
    run bucket delete $NAMESPACE $fskpname2 --uid $uid --secret=$secret
}

swift_object_tests(){
    cos=$1; uid=$2; password=$3; shift
    kpname=$(python  -c 'import uuid; print uuid.uuid1()')
    run swift_container.py create $NAMESPACE $kpname --uid $uid --password=$password
    if [ "$BOURNE_IP" != "127.0.0.1" ]; then
        run swift_object.py sanity $NAMESPACE $kpname key-$cos value-$cos --uid $uid --password=$password
    fi
    run swift_container.py delete $NAMESPACE $kpname --uid $uid --password=$password
}

swift_fileaccess_tests() {
    cos=$1; uid=$2; secret=$3; shift
    kpname="$(python  -c 'import uuid; print uuid.uuid1()')-SWIFT"
    run swift_container.py create $NAMESPACE $kpname --uid $uid --password=$password
    run fileaccesssanity.py swift $NAMESPACE $kpname $cos $uid $password
    run swift_container.py delete $NAMESPACE $kpname --uid $uid --password=$password
}

atmos_object_tests(){
    cos=$1; uid=$2; secret=$3; testUid=$4; testUidSecret=$5; shift
    subtenantstr=`run atmossubtenant create $NAMESPACE $PROJECT $cos --uid $uid --secret=$secret`
    subtenant=${subtenantstr##*subtenant=}    
    run atmoskey sanity $NAMESPACE $PROJECT $subtenant key-$cos value-$cos --uid $uid --secret=$secret --testUid=$testUid --testUidSecret=$testUidSecret
    run atmossubtenant delete $NAMESPACE $subtenant --uid $uid --secret=$secret
}

object_create_secretkey() {
    echo "remove all secret keys before creating one"
    secretkey deleteuser $WS_UID
    secretkey deleteuser $WS_TEST_UID
    object_set_user_scope

    objectuser add $WS_UID $NAMESPACE
    objectuser add $WS_TEST_UID $NAMESPACE

    #object_set_user_scope_test
    WS_SECRET=`secretkeyuser add $WS_UID |tail -1`
    WS_SECRET_TEST_UID=`secretkeyuser add $WS_TEST_UID |tail -1`   
    
    #wait in case datasvc has already cache secret key from previous sanity running
    #echo "wait 3 minutes so that the secret key can be refreshed: secret key $WS_SECRET"
    #sleep 180
}

object_set_user_scope(){

    # disable set user scope  temporarily
    # to be enabled in the next patch
    SCRIPTDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
    #echo "setting user scope as global"
    #result_global=`python $SCRIPTDIR/userscope set GLOBAL`
    #echo "setting user scope as global done"

    echo "get user scope"
    result=`python $SCRIPTDIR/userscope get`

    echo "get user scope result: $result"

    #if [ "$result_global" == "$result" ]
    #then
    #    echo "User scope is set to GLOBAL"
    #else
    #    echo "Unable to set user space as GLOBAL. Response is:"
    #    echo "$result_global"
    #fi
 
}

object_set_user_scope_test(){
    
    #validate the user scope again by trying to set it as NAMESPACE
    #and it should fail
    echo "setting user scope as namespace"
    result_namespace=`python $SCRIPTDIR/userscope set NAMESPACE`

    echo "get user scope"
    result=`python $SCRIPTDIR/userscope get`

    echo "get user scope result : $result"
   
    #compare the results and it should not be same
    if [ "$result_namespace" != "$result" ]
    then 
        echo "Set user scope as namespace failed as expected"
    else
        echo "Unexpected user scope shouldnt be allowed to change!!!"
    fi

}

object_delete_secretkey() {

    #login with webstorage user so that secret key can be created
    # security login $WS_UID $WS_PASSWORD

    #remove all secret keys
    secretkeyuser delete $WS_UID --secretKey=$WS_SECRET
    objectuser delete $WS_UID
    objectuser delete $WS_TEST_UID

    #relogin with sanity testing user
    security login $SYSADMIN $SYSADMIN_PASSWORD
    if [ "$AUTH" != 'local' ] ; then
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    fi
}



s3_baseurl_tests(){
    run baseurl sanity $NAMESPACE $WS_BUCKET1 --uid $WS_UID --secret=$WS_SECRET
}

SSH(){
    ip=$1
    cmd=$2
    opt=$3
    sshpass -p ${SYSADMIN_PASSWORD} ssh $opt -q -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@${ip} ${cmd}
}

SCP(){
    local ip=$1
    shift
    local args=("${@}")
    local len=${#args[@]}
    local src=${args[@]:0:${len}-1}
    local dst=${args[@]:${len}-1}
    sshpass -p ${SYSADMIN_PASSWORD} scp -q -r -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null $src root@$ip:$dst
}

ui_tests()
{
    run platform-ui kickstart
}

#
# add vnx device and use its storage
#
vnxblock_setup_once()
{
    # do this only once
    smisprovider show $VNX_SMIS_DEV &> /dev/null && return $?

    if [ $QUICK -eq 0 ]; then
       smisprovider create $VNX_SMIS_DEV $VNX_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
    else
       smisprovider create $VNX_SMIS_DEV $SIMULATOR_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
    fi

    storagedevice discover_all --ignore_error

    sleep 60
    vnxblock_cos_setup


    echo "vnxblock - storagepools update"
    storagepool update $VNXB_NATIVEGUID --type block --volume_type THIN_AND_THICK
    storagepool update $VNXB_NATIVEGUID --type block --volume_type THICK_ONLY

    if [ $QUICK -eq 0 ]; then
       echo "vnxblock - storageports update"
       if [ $DISCOVER_SAN -eq 0 ]; then
           storageport update $VNXB_NATIVEGUID FC --tzone $NH/$FC_ZONE_A --group SP_A
           storageport update $VNXB_NATIVEGUID FC --tzone $NH/$FC_ZONE_B --group SP_B
       fi
       storageport update $VNXB_NATIVEGUID IP --tzone nh/iptz            
    fi

    echo "vnxblock - cos update"
    cos update block $COS_VNXBLOCK --storage $VNXB_NATIVEGUID
    cos update block $COS_VNXBLOCK_FC --storage $VNXB_NATIVEGUID
    cos update block $COS_VNXBLOCK_ISCSI --storage $VNXB_NATIVEGUID
    cos update block $COS_VNXBLOCK_THIN --storage $VNXB_NATIVEGUID
    cos update block $COS_VNXBLOCK_THICK --storage $VNXB_NATIVEGUID    
    sleep 30
}

vnxblock_setup()
{
    echo "begin: vnxblock_setup"
    vnxblock_setup_once
    cos allow $COS_VNXBLOCK block $TENANT
    cos allow $COS_VNXBLOCK_FC block $TENANT
    cos allow $COS_VNXBLOCK_ISCSI block $TENANT
    cos allow $COS_VNXBLOCK_THIN block $TENANT
    cos allow $COS_VNXBLOCK_THICK block $TENANT
    echo "end: vnxblock_setup"
}


vmaxblock_setup_once()
{
    # do this only once
    smisprovider show $VMAX_SMIS_DEV &> /dev/null && return $?

    # If this is using the simulator, the vnxblock already took care of the SMIS provider
    if [ $QUICK -eq 0 ]; then
       smisprovider create $VMAX_SMIS_DEV $VMAX_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false
    fi

    storagedevice discover_all --ignore_error

    vmax_cos_setup
    mirrorblock_cos_setup

    storagepool update $VMAX_NATIVEGUID --type block --volume_type THIN_ONLY
#    storagepool update $VMAX_NATIVEGUID --type block --volume_type THIN_ONLY
    storagepool update $VMAX_NATIVEGUID --type block --volume_type THICK_ONLY
    storagepool update $VMAX_NATIVEGUID --nhadd $NH --type block
    if [ $QUICK -eq 0 ]; then
      
        echo "storageports update - vmaxblock"
        if [ $DISCOVER_SAN -eq 0 ]; then
           for porta in ${VMAX_PORTS_A}
           do
	      storageport update $VMAX_NATIVEGUID FC --tzone $FCTZ_A --group ${porta}
           done

	   for portb in ${VMAX_PORTS_B}
           do
              storageport update $VMAX_NATIVEGUID FC --tzone $FCTZ_B --group ${portb}
           done
       fi
       storageport update $VMAX_NATIVEGUID IP --tzone nh/iptz
 #   else
        #storageport update $SIMULATOR_VMAX_NATIVEGUID FC --tzone $NH/$FC_ZONE_A
    fi

    cos update block $COS_VMAXBLOCK --storage $VMAX_NATIVEGUID
    cos update block $COS_VMAXBLOCK_FC --storage $VMAX_NATIVEGUID
    cos update block $COS_VMAXBLOCK_ISCSI --storage $VMAX_NATIVEGUID
    cos update block $COS_VMAXBLOCK_THIN --storage $VMAX_NATIVEGUID
    #cos update block $COS_VMAXBLOCK_THICK $VMAX_NATIVEGUID
}

vmaxblock_setup()
{
    echo "begin: vmaxblock_setup"

    vmaxblock_setup_once
    cos allow $COS_VMAXBLOCK block $TENANT
    cos allow $COS_VMAXBLOCK_FC block $TENANT
    cos allow $COS_VMAXBLOCK_ISCSI block $TENANT
    cos allow $COS_VMAXBLOCK_THIN block $TENANT
    #cos allow $COS_VMAXBLOCK_THICK block $TENANT
	
    echo "end: vmaxblock_setup"
}

vnxblock_flex_varray_setup()
{
    vnxblock_setup

    # do manual assignment of ports
    transportzone update $FC_ZONE_A --remNeighborhoods $NH
    transportzone update $FC_ZONE_B --remNeighborhoods $NH
    transportzone update $IP_ZONE --remNeighborhoods $NH

    storageport update $VNXB_NATIVEGUID FC --addvarrays $NH --group SP_A
    storageport update $VNXB_NATIVEGUID FC --addvarrays $NH --group SP_B
    storageport update $VNXB_NATIVEGUID IP --addvarrays $NH
}


vmaxblock_flex_varray_setup()
{
    vmaxblock_setup

    # remove network assignment and assign ports manually
    transportzone update $FC_ZONE_A --remNeighborhoods $NH
    transportzone update $FC_ZONE_B --remNeighborhoods $NH
    transportzone update $IP_ZONE --remNeighborhoods $NH
    for porta in ${VMAX_PORTS_A}
    do
        storageport update $VMAX_NATIVEGUID FC --addvarrays $NH --group ${porta}
    done
    for portb in ${VMAX_PORTS_B}
    do
        storageport update $VMAX_NATIVEGUID FC --addvarrays $NH --group ${portb}
    done
    storageport update $VMAX_NATIVEGUID IP --addvarrays $NH
}

#
# VMAX and VNX export group tests
#
combined_block_setup()
{
    vnxblock_setup
    vmaxblock_setup
}

# Block Mirror setup
# 
mirrorblock_setup()
{
    vmaxblock_setup
    #vnxblock_setup

    cos allow $COS_MIRROR block $TENANT
    cos update block $COS_MIRROR --storage $VMAX_NATIVEGUID

    cos allow $COS_MIRROR_WITH_OPTIONAL block $TENANT
    cos update block $COS_MIRROR_WITH_OPTIONAL --storage $VMAX_NATIVEGUID

    cos allow $COS_MIRROR_WITH_2_MIRRORS block $TENANT
    cos update block $COS_MIRROR_WITH_2_MIRRORS --storage $VMAX_NATIVEGUID

    cos allow $COS_MIRROR_BEFORE_CHANGE block $TENANT
    cos update block $COS_MIRROR_BEFORE_CHANGE --storage $VMAX_NATIVEGUID

    cos allow $COS_MIRROR_AFTER_CHANGE block $TENANT
    cos update block $COS_MIRROR_AFTER_CHANGE --storage $VMAX_NATIVEGUID

    #cos allow $COS_MIRROR_VNX block $TENANT
    #cos update block $COS_MIRROR_VNX --storage $VNXB_NATIVEGUID    

    cos allow $COS_VMAX_CG_MIRROR block $TENANT
    cos update block $COS_VMAX_CG_MIRROR --storage $VMAX_NATIVEGUID
}

#
# syssvc tests
#
syssvc_setup()
{
    echo "syssvc setup, do nothing."
}

security_setup()
{
    echo "security setup, do nothing."
}

all_setup()
{
#    ui_setup
#    webstorage_setup
    isilon_setup
#    vplex_setup
#    vnxfile_setup
    netapp_setup
#    datadomainfile_setup
    vnxblock_setup
    vmaxblock_setup
    mirrorblock_setup
    syssvc_setup
}

#
# Login, Configure SMTP, and add controller and object licenses
#
login_nd_configure_smtp_nd_add_licenses()
{
    security login $SYSADMIN $SYSADMIN_PASSWORD
    root_tenant=`tenant root|tail -1`
    echo "Verifying bulk POST request before license"
    tenant bulk_post "$root_tenant"
    echo "Finished verifying bulk POST request before license"
    echo "Configuring smtp and adding object and controller licenses."
    syssvc $CONFIG_FILE "$BOURNE_IP" setup
    echo "Finished Configuring smtp and adding licenses."
}

#
# setup cos, zone, project and add storage devices to bourne for tests
#
common_setup()
{
    sec_start_ldap_server
    login_nd_configure_smtp_nd_add_licenses

    syssvc $CONFIG_FILE "$BOURNE_IP" set_prop system_proxyuser_encpassword ${SYSADMIN_PASSWORD}
    tenant_setup
    zone_setup
    transportzone add    $NH/$FC_ZONE_A $BLK_CLIENT_FC
    transportzone add $NH/$IP_ZONE $BLK_CLIENT_iSCSI

    project_setup
    projectid=$(project query $PROJECT)
    echo "Project id of $PROJECT is $projectid."

    echo "Setup ACLs on neighborhood for $TENANT"
    neighborhood allow $NH $TENANT
    neighborhood allow $NH2 $TENANT
    ROOT_TENANT=`tenant root|tail -1`
    neighborhood allow $NH $ROOT_TENANT
    neighborhood allow $NH2 $ROOT_TENANT

    echo "Setup hosts and clusters for $TENANT"
    host_setup
}

blocksnapshot_setup()
{
    vnxblock_setup
    vmaxblock_setup
}

blocksnapshot_single_vnx()
{
    snaptest_vol="${VNX_VOLUME}-snaptest"
    run volume create ${snaptest_vol} $PROJECT $NH $COS_VNXBLOCK 1280000000

    # VMAX snap tests
    vnx_snap1_label=vnx_snap1-${HOSTNAME}-${RANDOM}
    vnx_snap2_label=vnx_snap2-${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${snaptest_vol} $vnx_snap1_label
    if [ "$EXTRA_PARAM" = "search" ] ; then
        blocksnapshot search $(echo $snaptest_vol| head -c 2)
        blocksnapshot search $(echo $snaptest_vol | head -c 2) --project $projectid

        blocksnapshot tag $PROJECT/${snaptest_vol}/${vnx_snap1_label} $TAG
        blocksnapshot search $SEARCH_PREFIX --scope $TENANT --tag true
    fi

    run blocksnapshot create $PROJECT/${snaptest_vol} $vnx_snap2_label
    run blocksnapshot list $PROJECT/${snaptest_vol}
    run blocksnapshot show $PROJECT/${snaptest_vol}/${vnx_snap1_label}
    run blocksnapshot show $PROJECT/${snaptest_vol}/${vnx_snap2_label}
    run blocksnapshot restore $PROJECT/${snaptest_vol}/${vnx_snap2_label}
    run blocksnapshot delete $PROJECT/${snaptest_vol}/${vnx_snap1_label}
    run blocksnapshot delete $PROJECT/${snaptest_vol}/${vnx_snap2_label}
    run volume delete $PROJECT/${snaptest_vol} --wait

    # ----------------------------------
    # Run tests with activate operations
    # ----------------------------------
    activate_vol="${snaptest_vol}-ac"
    run volume create ${activate_vol} $PROJECT $NH $COS_VNXBLOCK 1280000000

    # Snapshot without create_inactive operation specified ==> Use default
    snap1_label=snap1-${HOSTNAME}-${RANDOM}
    run blocksnapshot create ${PROJECT}/${activate_vol} $snap1_label
    run blocksnapshot show ${PROJECT}/${activate_vol}/${snap1_label}
    run blocksnapshot activate ${PROJECT}/${activate_vol}/${snap1_label}
    run blocksnapshot delete ${PROJECT}/${activate_vol}/${snap1_label}

    # Snapshot with create_inactive=true
    inactive_snap_label=inactive-snap-${HOSTNAME}-${RANDOM}
    run blocksnapshot create ${PROJECT}/${activate_vol} $inactive_snap_label --create_inactive=true
    run blocksnapshot show ${PROJECT}/${activate_vol}/${inactive_snap_label}
    run blocksnapshot activate ${PROJECT}/${activate_vol}/${inactive_snap_label}
    run blocksnapshot delete ${PROJECT}/${activate_vol}/${inactive_snap_label}

    # Snapshot with create_inactive=false
    active_snap_label=active-snap-${HOSTNAME}-${RANDOM}
    run blocksnapshot create ${PROJECT}/${activate_vol} $active_snap_label --create_inactive=false
    run blocksnapshot show ${PROJECT}/${activate_vol}/${active_snap_label}
    run blocksnapshot activate ${PROJECT}/${activate_vol}/${active_snap_label}
    run blocksnapshot restore ${PROJECT}/${activate_vol}/${active_snap_label}
    run blocksnapshot delete ${PROJECT}/${activate_vol}/${active_snap_label}

    # Cleanup
    run volume delete ${PROJECT}/${activate_vol} --wait
}

blocksnapshot_single_vmax()
{
    snaptest_vol="${VMAX_VOLUME}-snaptest"

    run volume create ${snaptest_vol} $PROJECT $NH $COS_VMAXBLOCK 1280000000 --thinVolume true

    # VMAX snap tests
    vmx_snap1_label=vmx_snap1-${HOSTNAME}-${RANDOM}
    vmx_snap2_label=vmx_snap2-${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${snaptest_vol} $vmx_snap1_label
    run blocksnapshot create $PROJECT/${snaptest_vol} $vmx_snap2_label
    run blocksnapshot list $PROJECT/${snaptest_vol}
    run blocksnapshot show $PROJECT/${snaptest_vol}/${vmx_snap1_label}
    run blocksnapshot show $PROJECT/${snaptest_vol}/${vmx_snap2_label}
    run blocksnapshot restore $PROJECT/${snaptest_vol}/${vmx_snap2_label}
    run blocksnapshot delete $PROJECT/${snaptest_vol}/${vmx_snap1_label}
    run blocksnapshot delete $PROJECT/${snaptest_vol}/${vmx_snap2_label}
    run volume delete $PROJECT/${snaptest_vol} --wait

    # ----------------------------------
    # Run tests with activate operations
    # ----------------------------------
    activate_vol="${snaptest_vol}-ac"
    run volume create ${activate_vol} $PROJECT $NH $COS_VMAXBLOCK 1280000000 --thinVolume true

    # Snapshot without create_inactive operation specified ==> Use default
    snap1_label=snap1-${HOSTNAME}-${RANDOM}
    run blocksnapshot create ${PROJECT}/${activate_vol} $snap1_label
    run blocksnapshot show ${PROJECT}/${activate_vol}/${snap1_label}
    run blocksnapshot activate ${PROJECT}/${activate_vol}/${snap1_label}
    run blocksnapshot delete ${PROJECT}/${activate_vol}/${snap1_label}

    # Snapshot with create_inactive=true
    inactive_snap_label=inactive-snap-${HOSTNAME}-${RANDOM}
    run blocksnapshot create ${PROJECT}/${activate_vol} $inactive_snap_label --create_inactive=true
    run blocksnapshot show ${PROJECT}/${activate_vol}/${inactive_snap_label}
    run blocksnapshot activate ${PROJECT}/${activate_vol}/${inactive_snap_label}
    run blocksnapshot delete ${PROJECT}/${activate_vol}/${inactive_snap_label}

    # Snapshot with create_inactive=false
    active_snap_label=active-snap-${HOSTNAME}-${RANDOM}
    run blocksnapshot create ${PROJECT}/${activate_vol} $active_snap_label --create_inactive=false
    run blocksnapshot show ${PROJECT}/${activate_vol}/${active_snap_label}
    run blocksnapshot activate ${PROJECT}/${activate_vol}/${active_snap_label}
    run blocksnapshot restore ${PROJECT}/${activate_vol}/${active_snap_label}
    run blocksnapshot delete ${PROJECT}/${activate_vol}/${active_snap_label}

    # Cleanup
    run volume delete ${PROJECT}/${activate_vol} --wait
}

blocksnapshot_consistency_group_vnx()
{
    snaptest_vol="${VNX_VOLUME}-cg"
    consistency_group=`openssl passwd "$RANDOM" | cut -c1-8`

    # Create consistency group
    run blockconsistencygroup create $PROJECT $consistency_group

    # Create volumes
    run volume create ${snaptest_vol}1 $PROJECT $NH $COS_VNXBLOCK 1280000000 --consistencyGroup consistency_group
    run volume create ${snaptest_vol}2 $PROJECT $NH $COS_VNXBLOCK 1280000000 --consistencyGroup consistency_group
    run volume create ${snaptest_vol}3 $PROJECT $NH $COS_VNXBLOCK 1280000000 --consistencyGroup consistency_group
    # Create snaps
    snap1_label=snap1-${HOSTNAME}-${RANDOM}
    snap2_label=snap2-${HOSTNAME}-${RANDOM}
    snap3_label=snap3-${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${snaptest_vol}1 $snap1_label
    run blocksnapshot create $PROJECT/${snaptest_vol}1 $snap2_label
    run blocksnapshot create $PROJECT/${snaptest_vol}1 $snap3_label
    # Show it
    run blocksnapshot list $PROJECT/${snaptest_vol}1
    run blocksnapshot list $PROJECT/${snaptest_vol}2
    run blocksnapshot list $PROJECT/${snaptest_vol}3
    # Restore
    run blocksnapshot restore $PROJECT/${snaptest_vol}2/${snap2_label}
    # Clean up - delete one snap, will delete all in snapset
    run blocksnapshot delete $PROJECT/${snaptest_vol}1/${snap1_label}
    run blocksnapshot delete $PROJECT/${snaptest_vol}1/${snap2_label}
    run blocksnapshot delete $PROJECT/${snaptest_vol}1/${snap3_label}
    # Delete
    run volume delete $PROJECT/${snaptest_vol}1 --wait
    run volume delete $PROJECT/${snaptest_vol}2 --wait
    run volume delete $PROJECT/${snaptest_vol}3 --wait
    run blockconsistencygroup delete $consistency_group

    # --------------------------------------------
    # Consistency Group snap tests with activation
    # --------------------------------------------
    consistency_group=`openssl passwd "$RANDOM" | cut -c1-8`

    # Create consistency group
    run blockconsistencygroup create $PROJECT $consistency_group

    volumename="${VNX_VOLUME}-CG-VOL-TO-SNAP"
    cg_vol1=${volumename}1
    cg_vol2=${volumename}2
    run volume create ${cg_vol1} $PROJECT $NH $COS_VNXBLOCK 1280000000 --consistencyGroup consistency_group
    run volume create ${cg_vol2} $PROJECT $NH $COS_VNXBLOCK 1280000000 --consistencyGroup consistency_group

    # Create CG snap with create_inactive=true
    inactive_snap_label=inactive-snap--${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${cg_vol1} $inactive_snap_label --create_inactive=true
    # This requires an OPT to be fixed for it work
    # run blocksnapshot activate $PROJECT/${cg_vol1}/${inactive_snap_label}
    # run blocksnapshot restore $PROJECT/${cg_vol1}/${inactive_snap_label}
    run blocksnapshot show $PROJECT/${cg_vol1}/${inactive_snap_label}

    # Create CG snap with create_inactive=false
    active_snap_label=active-snap-${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${cg_vol1} $active_snap_label --create_inactive=false
    run blocksnapshot show $PROJECT/${cg_vol1}/${active_snap_label}
    run blocksnapshot activate $PROJECT/${cg_vol1}/${active_snap_label}
    run blocksnapshot restore $PROJECT/${cg_vol1}/${active_snap_label}

    # Create CG snap without specifying create_inactive value
    snap_label=snap-${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${cg_vol1} $snap_label
    run blocksnapshot show $PROJECT/${cg_vol1}/${snap_label}
    run blocksnapshot activate $PROJECT/${cg_vol1}/${snap_label}
    run blocksnapshot restore $PROJECT/${cg_vol1}/${snap_label}
    run blocksnapshot delete $PROJECT/${cg_vol1}/${snap_label}

    # Clean up
    run blocksnapshot delete $PROJECT/${cg_vol1}/${inactive_snap_label}
    run blocksnapshot delete $PROJECT/${cg_vol1}/${active_snap_label}
    run volume delete $PROJECT/${cg_vol1} --wait
    run volume delete $PROJECT/${cg_vol2} --wait
    run blockconsistencygroup delete $consistency_group
}

blocksnapshot_consistency_group_vmax()
{
    snaptest_vol="${VMAX_VOLUME}-cg"
    consistency_group=`openssl passwd "$RANDOM" | cut -c1-8`
	
    # Create volumes
    run volume create ${snaptest_vol}1 $PROJECT $NH $COS_VMAXBLOCK_FC 1280000000 --consistencyGroup consistency_group
    run volume create ${snaptest_vol}2 $PROJECT $NH $COS_VMAXBLOCK_FC 1280000000 --consistencyGroup consistency_group
    # Create snaps
    snap1_label=snap1-${HOSTNAME}-${RANDOM}
    snap2_label=snap2-${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${snaptest_vol}1 $snap1_label 
    run blocksnapshot create $PROJECT/${snaptest_vol}1 $snap2_label
    # Show it
    run blocksnapshot list $PROJECT/${snaptest_vol}1
    run blocksnapshot list $PROJECT/${snaptest_vol}2
    # Restore
    # run blocksnapshot restore $PROJECT/${snaptest_vol}2/${snap1_label}
    # Clean up
    run blocksnapshot delete $PROJECT/${snaptest_vol}1/${snap1_label}
    run blocksnapshot delete $PROJECT/${snaptest_vol}1/${snap2_label}
    # Delete
    run volume delete $PROJECT/${snaptest_vol}1 --wait
    run volume delete $PROJECT/${snaptest_vol}2 --wait

    # --------------------------------------------
    # Consistency Group snap tests with activation
    # --------------------------------------------
    volumename="${VMAX_VOLUME}-CG-VOL-TO-SNAP"
    cg_vol1=${volumename}1
    cg_vol2=${volumename}2
    consistency_group=`openssl passwd "$RANDOM" | cut -c1-8`
    
    run volume create ${cg_vol1} $PROJECT $NH $COS_VMAXBLOCK 1280000000 --consistencyGroup consistency_group
    run volume create ${cg_vol2} $PROJECT $NH $COS_VMAXBLOCK 1280000000 --consistencyGroup consistency_group

    # Create CG snap with create_inactive=true
    nactive_snap_label=inactive-snap--${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${cg_vol1} $inactive_snap_label --create_inactive=true
    # This requires an OPT to be fixed for it work
    # run blocksnapshot activate $PROJECT/${cg_vol1}/${inactive_snap_label}
    # run blocksnapshot restore $PROJECT/${cg_vol1}/${inactive_snap_label}
    run blocksnapshot show $PROJECT/${cg_vol1}/${inactive_snap_label}

    # Create CG snap with create_inactive=false
    active_snap_label=active-snap-${HOSTNAME}-${RANDOM}
    run blocksnapshot create $PROJECT/${cg_vol1} $active_snap_label --create_inactive=false
    run blocksnapshot show $PROJECT/${cg_vol1}/${active_snap_label}
    run blocksnapshot activate $PROJECT/${cg_vol1}/${active_snap_label}
    run blocksnapshot restore $PROJECT/${cg_vol1}/${active_snap_label}

    # Create CG snap without specifying create_inactive value
    #snap_label=snap-${HOSTNAME}-${RANDOM}
    #run blocksnapshot create $PROJECT/${cg_vol1} $snap_label
    #run blocksnapshot show $PROJECT/${cg_vol1}/${snap_label}
    #run blocksnapshot activate $PROJECT/${cg_vol1}/${snap_label}
    #run blocksnapshot restore $PROJECT/${cg_vol1}/${snap_label}
    #run blocksnapshot delete $PROJECT/${cg_vol1}/${snap_label}

    # Clean up
    run blocksnapshot delete $PROJECT/${cg_vol1}/${inactive_snap_label}
    run blocksnapshot delete $PROJECT/${cg_vol1}/${active_snap_label}
    run volume delete $PROJECT/${cg_vol1} --wait
    run volume delete $PROJECT/${cg_vol2} --wait
}

blocksnapshot_tests()
{
    blocksnapshot_single_vnx
    blocksnapshot_single_vmax

#    blocksnapshot_consistency_group_vnx
#    blocksnapshot_consistency_group_vmax
}


#
# fileshare tests
#
file_tests()
{
    echo "File tests started"
    cos=$1; shift
    perms=${@}
    datetime=`date +%m%d%y%H%M%S`
    fsname=fs-$cos-$macaddr-$datetime
    fsname=$(echo $fsname | sed s/-/_/g)
    fsname=$(echo $fsname | sed s/:/_/g)
    echo $fsname
    
	if [ $cos = $COS_VNXFILE ] ; then
	    run vnas list
	fi
    
    run fileshare create $fsname $PROJECT $NH $cos $FS_SIZEMB
    if [ "$EXTRA_PARAM" = "search" ] ; then
        run fileshare search --name $(echo $fsname | head -c 2)
        run fileshare search --name $(echo $fsname | head -c 2) --project $projectid

        run fileshare tag $PROJECT/${fsname} $TAG
        run fileshare search --tag $SEARCH_PREFIX 
    fi

    run fileshare show $PROJECT/$fsname
    run fileshare expand $PROJECT/$fsname $FS_EXPAND_SIZE
    run fileshare show $PROJECT/$fsname
    if [ $cos = $COS_ISIFILE ] ; then
        run snapshot create $PROJECT/$fsname $fsname-$datetime
        if [ "$EXTRA_PARAM" = "search" ] ; then
            snapshot search $(echo $fsname| head -c 2)
            snapshot search $(echo $fsname| head -c 2) --project $projectid

            snapshot tag $PROJECT/$fsname-$datetime $PROJECT/${fsname} $TAG
            snapshot search $SEARCH_PREFIX --scope $TENANT --tag true
        fi
        run snapshot create $PROJECT/$fsname $fsname-$datetime-2
        run bulkapi filesnapshots $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    for p in $perms
    do
        case $p in
        ro)
            exp_args="$FSEXP_RO_EPS --perm ro --comments TESTCOMMENTS"
            exp_upd_args="--readonlyhosts $FSEXP1"
            snap_exp_args="$FSEXP_RO_EPS --perm ro"
            snap_share_args="--perm read"
            ;;
        rw)
            exp_args="$FSEXP_RW_EPS --perm rw --comments TESTCOMMENTS"
            exp_upd_args="--readwritehosts $FSEXP2"
            snap_exp_args="$FSEXP_RW_EPS --perm ro"
            snap_share_args="--perm read"
            ;;
        root)
            exp_args="$FSEXP_ROOT_EPS --perm root --rootuser root --comments TESTCOMMENTS"
            exp_upd_args="--roothosts $FSEXP3"
            snap_exp_args="$FSEXP_ROOT_EPS --perm ro --rootuser root"
            snap_share_args="--perm read"
            ;;
        default)
            exp_args="$FSEXP_DEFAULT_EPS --comments TESTCOMMENTS"
            exp_upd_args="--readwritehosts $FSEXP4"
            snap_exp_args="$FSEXP_DEFAULT_EPS"
            snap_share_args="--perm read"
            ;;
        esac
        echo "exp args = $exp_args"
        run fileshare export $PROJECT/$fsname $exp_args
        run fileshare show $PROJECT/$fsname

        echo "exp upd args = $exp_upd_args"
        run fileshare export_update $PROJECT/$fsname $exp_upd_args --operation modify --securityflavor sys 

        if [ $cos != $COS_VNXE ] ; then
            let "FS_EXPAND_SIZE = $FS_SIZE + $FS_EXPAND_SIZE"
            run fileshare expand $PROJECT/$fsname $FS_EXPAND_SIZE
        fi

        if [ $cos = $COS_VNXFILE ] ; then
            run snapshot create $PROJECT/$fsname $fsname-$datetime
            run snapshot export $PROJECT/$fsname-$datetime $PROJECT/$fsname $snap_exp_args
            run snapshot show $PROJECT/$fsname-$datetime $PROJECT/$fsname
            run snapshot restore $PROJECT/$fsname-$datetime $PROJECT/$fsname
            run snapshot unexport $PROJECT/$fsname-$datetime $PROJECT/$fsname
            run snapshot delete $PROJECT/$fsname-$datetime $PROJECT/$fsname
            run snapshot create $PROJECT/$fsname $fsname-$datetime-2
            run snapshot export $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $SNAPEXP_DEFAULT_EPS
            run snapshot show $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot unexport $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot create $PROJECT/$fsname $fsname-$datetime-3
            run snapshot export $PROJECT/$fsname-$datetime-3 $PROJECT/$fsname $SNAPEXP_SECKRP_EPS
            run snapshot show $PROJECT/$fsname-$datetime-3 $PROJECT/$fsname
            run snapshot unexport $PROJECT/$fsname-$datetime-3 $PROJECT/$fsname
            run snapshot show $PROJECT/$fsname-$datetime-3 $PROJECT/$fsname
            run snapshot delete $PROJECT/$fsname-$datetime-3 $PROJECT/$fsname
        fi
        run fileshare unexport $PROJECT/$fsname

    	if [ $cos = $COS_NETAPP ] ; then
            run snapshot create $PROJECT/$fsname $fsname-$datetime-2
            run snapshot export $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $snap_exp_args
            run snapshot show $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot restore $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot unexport $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot share $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE1 --description 'New_SNAPSHOT_SMB_Share1' --perm 'read'
	        run snapshot share $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE2 --description 'New_SNAPSHOT_SMB_Share2' --perm 'read'
            echo "Snapshot Share ACL testing for NetApp7 Started===========>>>"
			run snapshot share_acl $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE1 --user 'Everyone' --permission 'read' --operation add
            run snapshot share_acl_show $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE1
	        run snapshot share_acl $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE1 --user 'Everyone' --permission 'read' --operation modify
            run snapshot share_acl $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE1 --user 'Everyone' --permission 'read' --operation delete
	        run snapshot share_acl $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE2 --user 'Everyone' --permission 'read' --operation add
    	    run snapshot share_acl_delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname  $NETAPPF_SMBSNAPSHARE2
			echo "Snapshot Share ACL testing for NetApp7 Finished===========<<<"
            run snapshot unshare $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE1 
	        run snapshot unshare $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPF_SMBSNAPSHARE2 
            run snapshot delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
        fi

        if [ $cos = $COS_NETAPPC ] ; then
            run snapshot create $PROJECT/$fsname $fsname-$datetime-2
            run snapshot show $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname	    
           run snapshot share $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE1 --description 'New_SNAPSHOT_SMB_Share1' --perm 'read'
	        run snapshot share $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE2 --description 'New_SNAPSHOT_SMB_Share2' --perm 'read'
			echo "Snapshot Share ACL testing for NetApp Cluster Started===========>>>"
            run snapshot share_acl $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE1 --user 'Everyone' --permission 'read' --operation add
            run snapshot share_acl_show $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE1
	        run snapshot share_acl $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE1 --user 'Everyone' --permission 'read' --operation modify
            run snapshot share_acl $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE1 --user 'Everyone' --permission 'read' --operation delete
	        run snapshot share_acl $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE2 --user 'Everyone' --permission 'read' --operation add
    	    run snapshot share_acl_delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname  $NETAPPCF_SMBSNAPSHARE2
			echo "Snapshot Share ACL testing for NetApp Cluster done===========<<<"
            run snapshot unshare $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE1 
	        run snapshot unshare $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $NETAPPCF_SMBSNAPSHARE2
		    run snapshot delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
        fi
        
        if [ $cos = $COS_VNXE ] ; then
            run snapshot create $PROJECT/$fsname $fsname-$datetime-2
            run snapshot restore $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot export $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname $snap_exp_args
            run snapshot show $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot unexport $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
            run snapshot delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
        fi
        
    done

    # Run only for Isilon (temporary until vnx implements smb)
    if [ $cos = $COS_ISIFILE ] ; then

        run fileshare share $PROJECT/$fsname  $ISI_SMBFILESHARE1 --description 'New_SMB_Share'
        run fileshare share $PROJECT/$fsname  $ISI_SMBFILESHARE2 --description 'New_SMB_Share2'
		echo "File Share ACL testing for ISILON Started"
        run fileshare share_acl $PROJECT/$fsname  $ISI_SMBFILESHARE1 --user 'Everyone' --permission 'change' --operation add
	    run fileshare share_acl_show $PROJECT/$fsname  $ISI_SMBFILESHARE1
	    run fileshare share_acl $PROJECT/$fsname  $ISI_SMBFILESHARE1 --user 'Everyone' --permission 'read' --operation modify
	    run fileshare share_acl $PROJECT/$fsname  $ISI_SMBFILESHARE1 --user 'Everyone' --permission 'read' --operation delete
	    run fileshare share_acl $PROJECT/$fsname  $ISI_SMBFILESHARE2 --user 'Everyone' --permission 'read' --operation add
    	run fileshare share_acl_delete $PROJECT/$fsname  $ISI_SMBFILESHARE2
		echo "File Share ACL testing for ISILON done"
        run fileshare show $PROJECT/$fsname

	    # Deleting the FileSystem Shares.
        run fileshare unshare $PROJECT/$fsname $ISI_SMBFILESHARE1
        run fileshare unshare $PROJECT/$fsname $ISI_SMBFILESHARE2
    fi

    # Run only for Data Domain
    if [ $cos = $COS_DDFILE ] ; then
        echo "DD SMB share tests started...create 2 fileshares"
        run fileshare share $PROJECT/$fsname  $DATADOMAINF_SMBFILESHARE1 --description 'New_SMB_Share'
        run fileshare share $PROJECT/$fsname  $DATADOMAINF_SMBFILESHARE2 --description 'New_SMB_Share2'
        echo "DD SMB share tests started...create 2 fileshares done"
        run fileshare show $PROJECT/$fsname

        # Deleting the FileSystem Shares.
        echo "Delete 1st fileshare..."
        run fileshare unshare $PROJECT/$fsname $DATADOMAINF_SMBFILESHARE1
        echo "Delete 1st fileshare done...deleting 2nd fileshare"
        run fileshare unshare $PROJECT/$fsname $DATADOMAINF_SMBFILESHARE2
        echo "Delete fileshares done"

    fi
    
    # Run only for Netapp 
    if [ $cos = $COS_NETAPP ] ; then
        run fileshare share $PROJECT/$fsname  $NETAPPF_SMBFILESHARE1 --description 'New_SMB_Share'
		run fileshare share $PROJECT/$fsname  $NETAPPF_SMBFILESHARE2 --description 'New_SMB_Share2'
        run fileshare show $PROJECT/$fsname
		echo "File Share ACL testing for NetApp7 Started"
		run fileshare share_acl $PROJECT/$fsname  $NETAPPF_SMBFILESHARE1 --user 'Everyone' --permission 'change' --operation add
	    run fileshare share_acl_show $PROJECT/$fsname  $NETAPPF_SMBFILESHARE1
	    run fileshare share_acl $PROJECT/$fsname  $NETAPPF_SMBFILESHARE1 --user 'Everyone' --permission 'read' --operation modify
	    run fileshare share_acl $PROJECT/$fsname  $NETAPPF_SMBFILESHARE1 --user 'Everyone' --permission 'read' --operation delete
	    run fileshare share_acl $PROJECT/$fsname  $NETAPPF_SMBFILESHARE2 --user 'Everyone' --permission 'read' --operation add
    	run fileshare share_acl_delete $PROJECT/$fsname  $NETAPPF_SMBFILESHARE2
		echo "File Share ACL testing for NetApp7 Finished"
        run fileshare unshare $PROJECT/$fsname $NETAPPF_SMBFILESHARE1
		run fileshare unshare $PROJECT/$fsname $NETAPPF_SMBFILESHARE2
		
    fi

    if [ $cos = $COS_NETAPPC ] ; then
        run fileshare share $PROJECT/$fsname  $NETAPPCF_SMBFILESHARE1 --description 'New_SMB_Share'
		run fileshare share $PROJECT/$fsname  $NETAPPCF_SMBFILESHARE2 --description 'New_SMB_Share2'
        run fileshare show $PROJECT/$fsname
		echo "File Share ACL testing for NetApp Cluster Started"
		run fileshare share_acl $PROJECT/$fsname  $NETAPPCF_SMBFILESHARE1 --user 'Everyone' --permission 'change' --operation add
	    run fileshare share_acl_show $PROJECT/$fsname  $NETAPPCF_SMBFILESHARE1
	    run fileshare share_acl $PROJECT/$fsname  $NETAPPCF_SMBFILESHARE1 --user 'Everyone' --permission 'read' --operation modify
	    run fileshare share_acl $PROJECT/$fsname  $NETAPPCF_SMBFILESHARE1 --user 'Everyone' --permission 'read' --operation delete
	    run fileshare share_acl $PROJECT/$fsname  $NETAPPCF_SMBFILESHARE2 --user 'Everyone' --permission 'read' --operation add
    	run fileshare share_acl_delete $PROJECT/$fsname  $NETAPPCF_SMBFILESHARE2
		echo "File Share ACL testing for NetApp Cluster Finished"
        run fileshare unshare $PROJECT/$fsname $NETAPPCF_SMBFILESHARE1
		run fileshare unshare $PROJECT/$fsname $NETAPPCF_SMBFILESHARE2
    fi
    
    if [ $cos = $COS_VNXFILE ] ; then
        fscifs=filesysCifs-$datetime
        run fileshare create $fscifs $PROJECT $NH $cos $FS_SIZEMB
        run fileshare share $PROJECT/$fscifs  $VNXF_SMBFILESHARE1 --description 'New_SMB_Share'
        run fileshare show $PROJECT/$fscifs
        run fileshare unshare $PROJECT/$fscifs $VNXF_SMBFILESHARE1
        run fileshare delete $PROJECT/$fscifs
    fi
    
    if [ $cos = $COS_VNXE ] ; then
        run fileshare share $PROJECT/$fsname  $VNXE_SMBFILESHARE1 --description 'New_SMB_Share'
        run fileshare show $PROJECT/$fsname
        run fileshare unshare $PROJECT/$fsname $VNXE_SMBFILESHARE1 
    fi
    
    if [ $cos = $COS_ISIFILE ] ; then
        run snapshot delete $PROJECT/$fsname-$datetime $PROJECT/$fsname
        run snapshot delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
    fi
   
    # create some fileshares for bulk get test
     if [ $cos != $COS_VNXE ] ; then
	    fs1=sanityFs1-$datetime
	    fs2=sanityFs2-$datetime
	    run fileshare create ${fs1} $PROJECT $NH $cos $FS_SIZE
	    run fileshare create ${fs2} $PROJECT $NH $cos $FS_SIZE
	    run fileshare bulkget
	    run fileshare delete $PROJECT/${fs1}
	    run fileshare delete $PROJECT/${fs2}
    fi

    run fileshare delete $PROJECT/$fsname --forceDelete true

    if [ $cos = $COS_VNXFILE ] ; then
        fsForceDelete="forceDeleteTestVNX"
        echo "--Force Delete tests for VNXFile--"
        run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
        run fileshare export $PROJECT/$fsForceDelete $exp_args
        run snapshot create $PROJECT/$fsForceDelete $fsForceDelete-$datetime
        run snapshot create $PROJECT/$fsForceDelete $fsForceDelete-$datetime-2
        run snapshot export $PROJECT/$fsForceDelete-$datetime-2 $PROJECT/$fsForceDelete $SNAPEXP_DEFAULT_EPS
        run fileshare delete $PROJECT/$fsForceDelete --forceDelete true
        # duplicate label Test - Should fail
        # run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
        # run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE

    fi


    if [ $cos = $COS_NETAPP ] ; then
        fsForceDelete="forceDeleteTestNETAPP"
        echo "--Force Delete tests for NETAPP--"
        run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
        run snapshot create $PROJECT/$fsForceDelete $fsForceDelete-$datetime
        run snapshot create $PROJECT/$fsForceDelete $fsForceDelete-$datetime-2
        run fileshare delete $PROJECT/$fsForceDelete --forceDelete true
        # duplicate label Test - Should fail
        # run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
        # run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE

    fi

    if [ $cos = $COS_NETAPPC ] ; then
        fsForceDelete="forceDeleteTestNETAPPC"
        echo "--Force Delete tests for NETAPPC--"
        run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
        run snapshot create $PROJECT/$fsForceDelete $fsForceDelete-$datetime
        run snapshot create $PROJECT/$fsForceDelete $fsForceDelete-$datetime-2
        run fileshare delete $PROJECT/$fsForceDelete --forceDelete true
        # duplicate label Test - Should fail
        # run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
        # run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE

    fi

    if [ $cos = $COS_ISIFILE ] ; then
        fsForceDelete="forceDeleteTestISILON"
        echo "--Force Delete tests for ISILON--"
        run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
        run snapshot create $PROJECT/$fsForceDelete $fsForceDelete-$datetime
        run snapshot create $PROJECT/$fsForceDelete $fsForceDelete-$datetime-2
        run fileshare delete $PROJECT/$fsForceDelete --forceDelete true
	# duplicate label Test - Should fail
	# run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
	# run fileshare create $fsForceDelete $PROJECT $NH $cos $FS_SIZE
    fi

    # Force Delete test for Data Domain
    if [ $cos = $COS_DDFILE ] ; then
        fsForceDelete="forceDeleteTestDATADOMAIN"
        #File systems (mtrees) are not deleted from DDMC, just marked inactive
        #until the GC runs.  To avoid conflict with the previous run, we attach
        #a timestamp to FS name.
        fsForceDeleteTimed=$fsForceDelete-$datetime
        echo "--Force Delete tests for DATADOMAIN--"
        run fileshare create $fsForceDeleteTimed $PROJECT $NH $cos $FS_SIZE
        run fileshare delete $PROJECT/$fsForceDeleteTimed --forceDelete true
    fi

    # File System Quota directory ops.
    if [ $cos = $COS_NETAPP ] ; then
        echo "--Quota directory operations for NETAPP--"
        fsQuotaDir="FileSystemQuotaDirTest"--$datetime
        quotaDir1="NetAppQuotaDirTest1"
        quotaDir2="NetAppQuotaDirTest1234" 
        run fileshare create $fsQuotaDir $PROJECT $NH $cos $FS_SIZE
        run fileshare create_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --sec "unix" --size $FS_SIZE --oplock true
        run fileshare show_quota_dir $PROJECT/$fsQuotaDir $quotaDir2
        run fileshare update_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --sec "ntfs" 
        run fileshare show_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 
        run fileshare delete_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --forceDelete true
        run fileshare delete $PROJECT/$fsQuotaDir --forceDelete true
    fi
    
    # File System Quota directory ops.
    if [ $cos = $COS_NETAPPC ] ; then
        echo "--Quota directory operations for NETAPP Cluster--"
        fsQuotaDir="FileSystemQuotaDirTest"--$datetime
        quotaDir1="NetAppQuotaDirTest1"
        quotaDir2="NetAppQuotaDirTest1234" 
        run fileshare create $fsQuotaDir $PROJECT $NH $cos $FS_SIZE
        run fileshare create_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --sec "unix" --size $FS_SIZE --oplock true
        run fileshare show_quota_dir $PROJECT/$fsQuotaDir $quotaDir2
        run fileshare update_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --sec "ntfs" 
        run fileshare show_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 
        run fileshare delete_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --forceDelete true
    fi
    
    # File System Quota directory ops.
    if [ $cos = $COS_ISIFILE ] ; then
        echo "--Quota directory operations for Isilon--"
        fsQuotaDir="FileSystemQuotaDirTest"--$datetime
        quotaDir1="IsilonQuotaDirTest1"
        quotaDir2="IsilonQuotaDirTest2" 
        run fileshare create $fsQuotaDir $PROJECT $NH $cos $FS_SIZE
        run fileshare create_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --sec "unix" --size $FS_SIZE --oplock true
        run fileshare show_quota_dir $PROJECT/$fsQuotaDir $quotaDir2
        run fileshare update_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --sec "ntfs" 
        run fileshare show_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 
        run fileshare delete_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --forceDelete true
        run fileshare delete $PROJECT/$fsQuotaDir --forceDelete true
    fi
    
    # File System Quota directory ops.
    if [ $cos = $COS_VNXFILE ] ; then
        echo "--Quota directory operations for VNXFile--"
        fsQuotaDir="FileSystemQuotaDirTest"--$datetime
        quotaDir1="VNXQuotaDir1"
        quotaDir2="VNXQuotaDir2"
        quotafs_exp_args="$FSEXP_SHARED_VARRAY_RW_EPS --perm rw  --comments TESTCOMMENTS"
        run fileshare create $fsQuotaDir $PROJECT $NH $cos $FS_SIZE
        run fileshare export $PROJECT/$fsQuotaDir $quotafs_exp_args
        run fileshare create_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --sec "unix" --size $FS_SIZE --oplock true
        run fileshare show_quota_dir $PROJECT/$fsQuotaDir $quotaDir2
        run fileshare update_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --sec "ntfs"
        run fileshare show_quota_dir $PROJECT/$fsQuotaDir $quotaDir2
        run fileshare delete_quota_dir $PROJECT/$fsQuotaDir $quotaDir2 --forceDelete true
        run fileshare delete $PROJECT/$fsQuotaDir --forceDelete true
    fi

}

quick_file_tests()
{
    cos=$1; shift
    perms=${@}
    datetime=`date +%m%d%y%H%M%S`
    fsname=fs-$cos-$macaddr-$datetime
    fsname=$(echo $fsname | sed s/-/_/g)
    fsname=$(echo $fsname | sed s/:/_/g)
    echo $fsname

    run fileshare create $fsname $PROJECT $NH $cos $FS_SIZE
    if [ $cos = $COS_ISIFILE ] ; then
        run snapshot create $PROJECT/$fsname $fsname-$datetime
        run snapshot create $PROJECT/$fsname $fsname-$datetime-2
    fi

    if [ $cos = $COS_DDFILE ] ; then
        echo "DD snapshot create"
        run snapshot create $PROJECT/$fsname $fsname-$datetime
        run snapshot create $PROJECT/$fsname $fsname-$datetime-2
    fi

    for p in $perms
    do
        case $p in
        ro)
            exp_args="$FSEXP_RO_EPS --perm ro"
            snap_share_args="--perm read"
            ;;
        rw)
            exp_args="$FSEXP_RW_EPS --perm rw"
            snap_share_args="--perm read"
            ;;
        root)
            exp_args="$FSEXP_ROOT_EPS --perm root --rootuser root"
            snap_share_args="--perm read"
            ;;
        default)
            exp_args="$FSEXP_DEFAULT_EPS"
            snap_share_args="--perm read"
            ;;
        esac

        run fileshare export $PROJECT/$fsname   $exp_args
        run fileshare show $PROJECT/$fsname
        if [ $cos = $COS_VNXFILE ] ; then
            run snapshot create $PROJECT/$fsname $fsname-$datetime
            run snapshot export $PROJECT/$fsname-$datetime $PROJECT/$fsname $exp_args
            run snapshot show $PROJECT/$fsname-$datetime $PROJECT/$fsname
            run snapshot restore $PROJECT/$fsname-$datetime $PROJECT/$fsname
            run snapshot unexport $PROJECT/$fsname-$datetime $PROJECT/$fsname 
            run snapshot delete $PROJECT/$fsname-$datetime $PROJECT/$fsname
        fi
        run fileshare unexport $PROJECT/$fsname

       # if [ $cos = $COS_ISIFILE ] ; then
       #     run snapshot export $PROJECT/$fsname-$datetime $PROJECT/$fsname $exp_args
       #     run snapshot show $PROJECT/$fsname-$datetime $PROJECT/$fsname
       #     run snapshot unexport $PROJECT/$fsname-$datetime $PROJECT/$fsname 
       # fi
    done

    # Run only for Isilon (temporary until vnx implements smb)
    if [ $cos = $COS_ISIFILE ] ; then
        run fileshare share $PROJECT/$fsname  $ISI_SMBFILESHARE1 --description 'New_SMB_Share'
        run fileshare show $PROJECT/$fsname
        run fileshare unshare $PROJECT/$fsname $ISI_SMBFILESHARE1 
        #
        run snapshot share $PROJECT/$fsname-$datetime $PROJECT/$fsname  $ISI_SMBSNAPSHARE1  --description 'New_SMB_Share_For_Snapshot' $snap_share_args
        run snapshot share_list $PROJECT/$fsname-$datetime $PROJECT/$fsname
        run snapshot show $PROJECT/$fsname-$datetime $PROJECT/$fsname
        run snapshot unshare $PROJECT/$fsname-$datetime $PROJECT/$fsname $ISI_SMBSNAPSHARE1 
        run snapshot share_list $PROJECT/$fsname-$datetime $PROJECT/$fsname
        run snapshot show $PROJECT/$fsname-$datetime $PROJECT/$fsname
    fi

    if [ $cos = $COS_ISIFILE ] ; then
        run snapshot delete $PROJECT/$fsname-$datetime $PROJECT/$fsname
        run snapshot delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
    fi
    # Data Domain share tests for both fileshare and snapshot
    if [ $cos = $COS_DDFILE ] ; then
        echo "DD tests for fileshare and snapshot"
        run fileshare share $PROJECT/$fsname  $DATADOMAINF_SMBFILESHARE1 --description 'New_SMB_Share'
        run fileshare show $PROJECT/$fsname
        run fileshare unshare $PROJECT/$fsname $DATADOMAINF_SMBFILESHARE1
    fi

    if [ $cos = $COS_DDFILE ] ; then
        echo "DD snapshot delete 2"
        run snapshot delete $PROJECT/$fsname-$datetime $PROJECT/$fsname
        run snapshot delete $PROJECT/$fsname-$datetime-2 $PROJECT/$fsname
    fi 

    run fileshare delete $PROJECT/$fsname
}

#
# do fileshare tests using isilon specific cos to exercise Isilon tests
#
isilon_tests()
{
    file_tests $COS_ISIFILE default ro rw root

    if [ "$AUTH" != 'local' && "$AUTH" != 'ipv6' ] ; then
        bulkapi tenants $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi projects $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi neighborhoods $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        # hosts, clusters and vcenters will need to ran through a setup/create process before beeing called
        #bulkapi hosts $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        #bulkapi clusters $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        #bulkapi vcenters $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1

        bulkapi storage-systems $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi storage-ports $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi storage-pools $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi transport-zones $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi filecos $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi fileshares $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1 $NH $COS_ISIFILE $FS_SIZE
    fi
}

ecs_tests()
{
    echo "Performing ecs_tests"
    bucket create $ECS_BUCKET $PROJECT $NH $COS_ECS $ECS_SOFT_QUOTA $ECS_HARD_QUOTA $ECS_BUCKET_OWNER
    #bucket delete bkt_id  #currently create itself deletes bucket
}


#
# do fileshare tests using isilon specific cos to exercise Isilon tests
#
vnxfile_tests()
{
    file_tests $COS_VNXFILE default
}

#
# do fileshare tests using manually assigned ports to varray
#
vnxfile_flex_varray_tests () {
    cos=$COS_VNXFILE
    fsname=fs-$cos-$macaddr
    exp_args="$FSEXP_SHARED_VARRAY_RW_EPS --perm rw"
    NH=$NH3
    FSEXP_RW_EPS=$FSEXP_SHARED_VARRAY_RW_EPS
    file_tests $COS_VNXFILE rw
}

netapp_tests()
{
    file_tests $COS_NETAPP default
}

netappc_tests()
{
    file_tests $COS_NETAPPC default
}

vnxe_tests()
{
	FS_SIZEMB=$FS_VNXE_SIZE;
	FS_SIZE=$FS_VNXE_SIZE;
	FS_EXPAND_SIZE=$FS_VNXE_EXPAND_SIZE;
	file_tests $COS_VNXE default
	
	echo "vnxe block tests begin"
	vnxe_block_tests
}

vnxe_block_tests() {
	vol1=vnxe1-${RANDOM};
	vol2=vnxe-cg-${RANDOM};
    host=$PROJECT.lss.emc.com
    hostLbl=$PROJECT
	iqn1=iqn.1998-01.com.vmware:lgly6193-7ae20d76
	consistency_group=cg-${RANDOM}
	snap1_label=snap1-${RANDOM}
	snap2_label=snap2-${RANDOM}
	eg=eg-${RANDOM}
    
    transportzone add $NH/$IP_ZONE $iqn1
    run volume create $vol1 $PROJECT $NH $COS_VNXEBLOCK_ISCSI $BLK_SIZE
    run volume expand $PROJECT/$vol1 $BLK_SIZE_EXPAND

    run hosts create $hostLbl $TENANT Windows $host --port 8111 --username user --password 'password' --osversion 1.0
    run initiator create $hostLbl iSCSI $iqn1

    run export_group create $PROJECT $eg $NH --type Host --volspec $PROJECT/$vol1 --hosts $hostLbl
	
	run blocksnapshot create $PROJECT/$vol1 $snap1_label
	run blocksnapshot list $PROJECT/$vol1
	run blocksnapshot restore $PROJECT/$vol1/${snap1_label}
	run blocksnapshot delete $PROJECT/$vol1/${snap1_label}
	run export_group delete $PROJECT/$eg
    run volume delete $PROJECT/$vol1 --wait
    run hosts delete $hostLbl
    
    echo "vnxe consistency group tests"
    
    run blockconsistencygroup create $PROJECT $consistency_group
    run volume create $vol2 $PROJECT $NH $COS_VNXEBLOCK_CG 1280000000 --consistencyGroup $consistency_group
   	run blocksnapshot create $PROJECT/$vol2 $snap2_label
	run blocksnapshot delete $PROJECT/$vol2/${snap2_label}
    run volume delete $PROJECT/$vol2 --wait
    run blockconsistencygroup delete $consistency_group
    echo "**** Done vnxe"
}

datadomainfile_tests()
{
    echo "DD file tests started"
    file_tests $COS_DDFILE default
    echo "DD file tests completed succesfully"
}

#
# do vmax block tests using network assignment to varray
#
vmaxblock_tests()
{
    block_tests $VMAXEXPORT_GROUP $VMAXEXPORT_GROUP_HOST $VMAX_VOLUME $COS_VMAXBLOCK $VMAX_VOLUME $COS_VMAXBLOCK
    # meta_volume_block_tests $VMAXEXPORT_GROUP $VMAXEXPORT_GROUP_HOST $VMAX_META_VOLUME $COS_VMAXBLOCK $VMAX_META_VOLUME $COS_VMAXBLOCK
    volume_expand_test $VMAX_VOLUME $COS_VMAXBLOCK_THIN   # work only for concatenate, stripe tbd
    # Tests for thick meta can not be ran on VMAX10K provider.
    #    volume_expand_test $VMAX_VOLUME $COS_VMAXBLOCK_THICK   # works for concatenate and stripe

    if [ "${AUTH}" != "local" -a "${AUTH}" != "ipv6" ]
    then
        bulkapi tenants $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi projects $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi neighborhoods $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        # hosts, clusters and vcenters will need to ran through a setup/create process before beeing called
        #bulkapi hosts $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        #bulkapi clusters $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        #bulkapi vcenters $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1

        bulkapi smis-providers $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi storage-systems $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi storage-ports $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi storage-pools $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi transport-zones $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
        bulkapi blockcos $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
#        bulkapi volumes $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1 $NH $COS_VMAXBLOCK $BLK_SIZE
    fi

    # ---------------------------------------------------------
    # Thick/Thin volume testing
    # ---------------------------------------------------------
    # The following tests depend on the VMAX array type.
    # Some arrays only support thin pools, so the thick test
    # cases would not work against them.
    TkOnTk=vmax-thick-on-thick-${seed}
    TnOnTn=vmax-thin-on-thin-${seed}

#    run volume create $TkOnTk $PROJECT $NH $COS_VMAXBLOCK_THICK $BLK_SIZE
#    run volume create $TnOnTn $PROJECT $NH $COS_VMAXBLOCK_THIN $BLK_SIZE --thinVolume true

#    run volume delete $PROJECT/${TkOnTk} --wait &
#    run volume delete $PROJECT/${TnOnTn} --wait &
#    wait
}

#
# do vmax block tests using using manual port assignments tp varray
#

# Before proceeding with ingestion, we need to substitute volumes & host details here.
ingestblock_setup() {
    echo "begin: ingestblock setup"

    xtremio_setup

    storagedevice discover_namespace $XTREMIO_NATIVEGUID 'UNMANAGED_VOLUMES'
    hosts create $XTREMIO_INGEST_HOST_LABEL $TENANT Windows $XTREMIO_INGEST_HOST --port 8111 --username user --password 'password' --osversion 1.0 

    PWWN1=10:00:00:E0:E0:E0:E0:E0
    WWNN1=20:00:00:E0:E0:E0:E0:E0
    PWWN2=10:00:00:E0:E0:E0:E0:E1
    WWNN2=20:00:00:E0:E0:E0:E0:E1

    initiator create 'ingesthost' FC ${PWWN1} --node ${WWNN1}
    initiator create 'ingesthost' FC ${PWWN2} --node ${WWNN2}
    
    echo "End: ingestblock setup"
}

ingestblock_tests() {

    echo "begin: ingestvmaxblock_tests"
    vol1=ingestvol1

    unmanagedvolume ingest_export --host $XTREMIO_INGEST_HOST_LABEL $NH $XTREMIO_COS_FC $PROJECT --volspec $vol1

#   unmanagedvolume ingest_unexport $NH $XTREMIO_COS_FC $PROJECT --volspec "vol1,vol2"
#   unmanagedvolume ingest_unexport $NH $vpool $PROJECT --volspec $vol1
   
    echo "end: ingestvmaxblock_tests"
}

vmaxblock_flex_varray_tests() {
    # run the usual tests
    vmaxblock_tests

    # restore network assignment and remove manual port assignment
    transportzone update $FC_ZONE_A --addNeighborhoods $NH
    transportzone update $FC_ZONE_B --addNeighborhoods $NH
    transportzone update $IP_ZONE --addNeighborhoods $NH

    for porta in ${VMAX_PORTS_A}
    do
        storageport update $VMAX_NATIVEGUID FC --tzone $FCTZ_A --group ${porta}
    done
    for portb in ${VMAX_PORTS_B}
    do
        storageport update $VMAX_NATIVEGUID FC --tzone $FCTZ_B --group ${portb}
    done
    storageport update $VMAX_NATIVEGUID IP --tzone nh/iptz
}

#
# do vnx block tests using network assignment to varray
#
vnxblock_tests()
{
    block_tests $VNXEXPORT_GROUP $VNXEXPORT_GROUP_HOST $VNX_VOLUME $COS_VNXBLOCK $VNX_VOLUME $COS_VNXBLOCK
    volume_expand_test $VNX_VOLUME $COS_VNXBLOCK_THIN

    # Thick/Thin volume testing
    TkOnTn=vnx-thick-on-thin-${seed}
    TkOnTk=vnx-thick-on-thick-${seed}
    TnOnTn=vnx-thin-on-thin-${seed}

    run volume create $TkOnTn $PROJECT $NH $COS_VNXBLOCK $BLK_SIZE
    run volume create $TkOnTk $PROJECT $NH $COS_VNXBLOCK_THICK $BLK_SIZE
    run volume create $TnOnTn $PROJECT $NH $COS_VNXBLOCK $BLK_SIZE --thinVolume true

    run volume delete $PROJECT/${TkOnTn} --wait &
    run volume delete $PROJECT/${TkOnTk} --wait &
    run volume delete $PROJECT/${TnOnTn} --wait &
    wait
}

#
# do vnx block tests using using manual port assignments tp varray
#
vnxblock_flex_varray_tests()
{
    vnxblock_tests

    # undo manual assignment of ports
    transportzone update $FC_ZONE_A --addNeighborhoods $NH
    transportzone update $FC_ZONE_B --addNeighborhoods $NH
    transportzone update $IP_ZONE --addNeighborhoods $NH

    storageport update $VNXB_NATIVEGUID FC --rmvarrays $NH --group SP_A
    storageport update $VNXB_NATIVEGUID FC --rmvarrays $NH --group SP_B
    storageport update $VNXB_NATIVEGUID IP --rmvarrays $NH
}

#
# do block tests that spans arrays
#
combined_block_tests()
{
    block_tests $BLOCKEXPORT_GROUP $VMAX_VNXEXPORT_GROUP_HOST $VNX_VOLUME $COS_VNXBLOCK $VMAX_VOLUME $COS_VMAXBLOCK
}

block_tests()
{
    export_name=$1
    export_host=$2
    v1=${3}1
    cos1=$4
    v2=${5}2
    cos2=$6

    run volume create ${v1} $PROJECT $NH $cos1 $BLK_SIZE --thinVolume true
    if [ "$EXTRA_PARAM" = "search" ] ; then
        run volume search --name $(echo ${v1}| head -c 2)
        run volume search --name $(echo ${v1}| head -c 2) --project $projectid

        run volume tag $PROJECT/"$v1" $TAG
        run volume search --tag $SEARCH_PREFIX 
    fi

    run volume create ${v2} $PROJECT $NH $cos2 $BLK_SIZE --thinVolume true

#    export_test_1 ${export_name}1 ${export_host}1 ${v1} ${v2}
#    export_test_2 ${export_name}2 ${export_host}2 ${v1} ${v2}
#    export_test_3 ${export_name}3 ${export_host}3 ${v1} ${v2}
#    export_test_4 ${export_name}4 ${export_host}4 ${v1} ${v2}
    export_initiator ${export_name}1 ${v1} ${v2}
#    export_host ${export_name}2 ${v1} ${v2}
#    export_cluster ${export_name}3 ${v1} ${v2}

    run volume bulkget
    
    run volume delete $PROJECT/${v1} --wait
    run volume delete $PROJECT/${v2} --wait
}


meta_volume_block_tests()
{
#    size=1099511627776    # 1TB
    size=322122547200      # 300GB
    export_name=$1
    export_host=$2
    v1=${3}1
    cos1=$4
    v2=${5}2
    cos2=$6

    run volume create ${v1} $PROJECT $NH $cos1 $size --thinVolume true
    run volume create ${v2} $PROJECT $NH $cos2 $size --thinVolume true
    sleep 15 # sleep to make sure that volume binding completed

#    export_test_1 ${export_name}1 ${export_host}1 ${v1} ${v2}
#    export_test_2 ${export_name}2 ${export_host}2 ${v1} ${v2}
#    export_test_3 ${export_name}3 ${export_host}3 ${v1} ${v2}
#    export_test_4 ${export_name}4 ${export_host}4 ${v1} ${v2}
    
    run volume delete $PROJECT --project --wait
}

quick_block_tests()
{
    export_name=$1
    export_host=$2
    v=$3
    cos1=$4

    v1=${3}-1
    v2=${3}-2

    run volume create $v $PROJECT $NH $cos1 $BLK_SIZE --thinVolume true --count=2
    export_initiator_quick ${export_name}Q ${v1} ${v2}
    run volume delete $PROJECT --project --wait
}

volume_expand_test()
{
    ev=$1-${seed}
    cos=$2

    run volume create ${ev} $PROJECT $NH $cos $BLK_SIZE
    run volume expand $PROJECT/$ev $BLK_SIZE_EXPAND
    run volume show $PROJECT/$ev
    run volume expand $PROJECT/$ev $BLK_SIZE_EXPAND_2
    run volume show $PROJECT/$ev
    run volume expand $PROJECT/$ev $BLK_SIZE_EXPAND_3
    run volume show $PROJECT/$ev

    run volume delete $PROJECT/${ev} --wait
}

# =======================================================================================
# Export Group 1
# =======================================================================================
export_test_1()
{
    expname=$1
    host=$2
    vol1=$PROJECT/$3
    vol2=$PROJECT/$4

    proj=$PROJECT
    exp=$proj/$expname
    NWWN=$BLK_CLIENT_FC_NODE
    PWWN1=`pwwn A1`
    PWWN2=`pwwn A2`

    run export_group create $proj $expname $NH
    run export_group add_volume $exp "$vol1+1"
    run export_group add_volume $exp "$vol2+2"
    run export_group show $exp
    run export_group remove_volume $exp "$vol1"
    run export_group show $exp
    run export_group add_volume $exp "$vol1+1"

    run export_group add_initiator $exp "FC+$NWWN+$PWWN1+$host"
    run export_group show $exp

    run export_group add_initiator $exp "FC+$NWWN+$PWWN2+$host"
    run export_group remove_initiator $exp "FC+$PWWN1"
    run export_group show $exp

    run export_group add_initiator $exp "FC+$NWWN+$PWWN1+$host"
    run export_group remove_initiator $exp "FC+$PWWN2"
    run export_group show $exp

    run export_group remove_volume $exp "$vol1"
    run export_group show $exp

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi exportgroups $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group delete $exp
    run export_group show $exp
}

# =======================================================================================
# Export Exclusive Type
# =======================================================================================
export_initiator()
{   
    snap1_label=snap1-${HOSTNAME}-${RANDOM}
    vol1=$PROJECT/$2
    vol2=$PROJECT/$3
    snap1=${vol1}/${snap1_label}
    proj=$PROJECT
    tenant=$TENANT
    c=1
    h=1
    expname=$1
    hostname=$hostbase$tenant$c$h
    echo $vol1 $vol2 $proj $tenant $hostname $expname
    
    exp=$proj/$expname
    nwwn=`nwwn $i$j`
    k=`wwnIdx $c $h`
    pwwn1=`pwwn A$k`
    pwwn2=`pwwn B$k`
    pwwn3=`pwwn C$k`
    pwwn4=`pwwn D$k`

    run blocksnapshot create $vol1 ${snap1_label}

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi blocksnapshots $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group create $proj $expname $NH --volspec "$vol1+1,$snap1+2" --inits "$hostname/$pwwn1"
    run export_group show $exp
    run export_group update $exp --addVolspec "$vol2+3" --remVols $vol1
    run export_group show $exp
    run export_group update $exp --addInits "$hostname/$pwwn2"
    run export_group show $exp
    run export_group update $exp --remInits "$hostname/$pwwn1"
    run export_group show $exp
    run export_group update $exp --remVols $vol2,$snap1
    run export_group show $exp

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi exportgroups $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group delete $exp
    run blocksnapshot delete $snap1
}

# =======================================================================================
# Export Initiator Type (Quick)
# =======================================================================================
export_initiator_quick()
{
    snap1_label=snap1-${HOSTNAME}-${RANDOM}
    vol1=$PROJECT/$2
    vol2=$PROJECT/$3
    snap1=${vol1}/${snap1_label}
    proj=$PROJECT
    tenant=$TENANT
    c=1
    h=1
    expname=$1
    hostname=$hostbase$tenant$c$h
    echo $vol1 $vol2 $proj $tenant $hostname $expname

    exp=$proj/$expname
    nwwn=`nwwn $i$j`
    k=`wwnIdx $c $h`
    pwwn1=`pwwn A$k`
    pwwn2=`pwwn B$k`
    pwwn3=`pwwn C$k`
    pwwn4=`pwwn D$k`

    run blocksnapshot create $vol1 ${snap1_label}

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi blocksnapshots $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group create $proj $expname $NH --volspec "$vol1+1,$snap1+2" --inits "$hostname/$pwwn1"
    run export_group show $exp

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi exportgroups $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group delete $exp
    run blocksnapshot delete $snap1
}

# =======================================================================================
# Export Host Type
# =======================================================================================
export_host()
{
    vol1=$PROJECT/$2
    vol2=$PROJECT/$3
    proj=$PROJECT
    tenant=$TENANT
    expname=$1
    exp=$proj/$expname
    
    c=1
    h=1
    hostname=$hostbase$tenant$c$h
    nwwn1=`nwwn $i$j`
    k=`k $c $h`
    pwwn11=`pwwn A$k`
    pwwn12=`pwwn B$k`
    pwwn13=`pwwn C$k`
    pwwn14=`pwwn D$k`
    
    h=2
    hostname2=$hostbase$tenant$c$h
    nwwn2=`nwwn $i$j`
    k=`k $c $h`
    pwwn21=`pwwn A$k`
    pwwn22=`pwwn B$k`
    pwwn23=`pwwn C$k`
    pwwn24=`pwwn D$k`

    run export_group create --type Host $proj $expname $NH --volspec "$vol1+1" --hosts "$hostname1"
    run export_group show $exp
    run export_group update $exp --addVolspec "$vol2+1" --remVols $vol1
    run export_group show $exp
    run export_group update $exp --addHosts "$hostname2" --remHosts "$hostname1"
    run export_group show $exp
    run export_group update $exp --remInits "$hostname2/pwwn21,$hostname2/pwwn23"
    run export_group show $exp
    run export_group update $exp --remVols $vol2
    run export_group show $exp

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi exportgroups $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group delete $exp
    run export_group show $exp
}

# =======================================================================================
# Export Cluster Type
# =======================================================================================
export_cluster()
{
    vol1=$PROJECT/$2
    vol2=$PROJECT/$3
    proj=$PROJECT
    tenant=$TENANT
    expname=$1
    exp=$proj/$expname
    
    cluster1=${proj}Cluster1
    cluster2=${proj}Cluster2

    c=1
    h=1
    hostname=$hostbase$tenant$c$h
    nwwn1=`nwwn $i$j`
    k=`k $c $h`
    pwwn11=`pwwn A$k`
    pwwn12=`pwwn B$k`
    pwwn13=`pwwn C$k`
    pwwn14=`pwwn D$k`
    
    c=2
    h=2
    hostname2=$hostbase$tenant$c$h
    nwwn2=`nwwn $i$j`
    k=`k $c $h`
    pwwn21=`pwwn A$k`
    pwwn22=`pwwn B$k`
    pwwn23=`pwwn C$k`
    pwwn24=`pwwn D$k`

    run export_group create --type Cluster $proj $expname $NH --volspec "$vol1+1" --clusters "$cluster1"
    run export_group show $exp
    run export_group update $exp --addVolspec "$vol2+1" --remVols $vol1
    run export_group show $exp
    run export_group update $exp --addClusters "$cluster2" --remClusters "$cluster1"
    run export_group show $exp
    run export_group update $exp --remHosts "$hostname2"
    run export_group show $exp
    run export_group update $exp --addHosts "$hostname2"
    run export_group show $exp
    run export_group update $exp --remInits "$hostname2/pwwn21,$hostname2/pwwn23"
    run export_group show $exp
    run export_group update $exp --remVols $vol2
    run export_group show $exp

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi exportgroups $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group delete $exp
    run export_group show $exp
}

# =======================================================================================
# - create empty export group
# - add initiators, try to add duplicate initiators
# - add/remove volumes with initiator list non-empty
# =======================================================================================
export_test_2()
{
    expname=$1
    host=$2
    vol1=$PROJECT/$3
    vol2=$PROJECT/$4

    proj=$PROJECT
    exp=$proj/$expname
    NWWN=$BLK_CLIENT_FC_NODE
    PWWN1=`pwwn A3`
    PWWN2=`pwwn A4`

    run export_group create $proj $expname $NH
    run export_group show $exp

    run export_group add_initiator $exp "FC+$NWWN+$PWWN1+$host"
    run export_group add_initiator $exp "FC+$NWWN+$PWWN2+$host"
    run export_group show $exp

    run export_group add_volume $exp "$vol1+1"
    run export_group show $exp

    run export_group add_volume $exp "$vol2+2"
    run export_group show $exp

    run export_group remove_volume $exp "$vol1"
    run export_group show $exp

    run export_group remove_volume $exp "$vol2"
    run export_group show $exp

    run export_group add_volume $exp "$vol2+2"
    run export_group show $exp

    run export_group delete $exp
    run export_group show $exp
}

#
# create block export
#
export_test_3()
{
    expname=$1
    host=$2
    vol1=$PROJECT/$3
    vol2=$PROJECT/$4

    proj=$PROJECT
    exp=$proj/$expname
    NWWN=$BLK_CLIENT_FC_NODE
    PWWN1=`pwwn A1`
    PWWN2=`pwwn A2`

    run export_group create $proj $expname $NH --volspec "$vol1+1,$vol2+2" --initspec "FC+$NWWN+$PWWN1+$host,FC+$NWWN+$PWWN2+$host,iSCSI++$BLK_CLIENT_iSCSI+$host"
    run export_group show $exp

    run export_group remove_volume $exp $vol2
    run export_group show $exp

    run export_group remove_initiator $exp "FC+$PWWN1"
    run export_group show $exp

    run export_group delete $exp
    run export_group show $exp

    expname=${expname}2
    exp=$proj/$expname
    run export_group create $proj $expname $NH --volspec "$vol1,$vol2" --initspec "FC+$NWWN+$PWWN2+$host,iSCSI++$BLK_CLIENT_iSCSI+$host"
    run export_group remove_volume $exp $vol2
    run export_group show $exp

    run export_group add_initiator $exp "FC+$NWWN+$PWWN1+$host"
    run export_group delete $exp
    run export_group show $exp
}

#
# Test blocksnapshot and volume exports
#
export_test_4()
{
    expname=$1
    host=$2
    vol1=$PROJECT/$3
    vol2=$PROJECT/$4
    snap1_label=snap1-${HOSTNAME}-${RANDOM}
    snap1="${vol1}/${snap1_label}"

    proj=$PROJECT
    exp=$proj/$expname
    NWWN=$BLK_CLIENT_FC_NODE
    PWWN1=`pwwn A1`
    PWWN2=`pwwn A2`
    
    
    run blocksnapshot create $vol1 $snap1_label 

    if [ "$BOURNE_SECURITY_DISABLED" != '1' ] ; then
        run bulkapi blocksnapshots $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD $LOCAL_LDAP_USER_PASSWORD_1
    fi

    run export_group create $proj $expname $NH --volspec "$vol1,$vol2,$snap1" --initspec "FC+$NWWN+$PWWN2+$host"
    run export_group show $exp
    run volume exports $vol2
    run export_group remove_volume $exp $vol2
    run volume exports $vol2
    run export_group show $exp
    run blocksnapshot exports $snap1
    run export_group remove_volume $exp $snap1
    run blocksnapshot exports $snap1
    run export_group add_volume $exp $snap1
    run blocksnapshot exports $snap1

    run export_group add_initiator $exp "FC+$NWWN+$PWWN1+$host"
    run export_group delete $exp
    run export_group show $exp

    run blocksnapshot delete $snap1
}

syssvc_tests()
{
    syssvc $CONFIG_FILE "$BOURNE_IP"
}

security_tests()
{
    if [ "$AUTH" = 'local' ] ; then
        echo 'no security tests for local security'
        return
    fi

    # done in setupe: security login $SYSADMIN $SYSADMIN_PASSWORD
    security test_firewall
    security test_proxy_token
    security test_formlogin $SYSADMIN $SYSADMIN_PASSWORD
    security test_vulnerability $SYSADMIN $SYSADMIN_PASSWORD
    security login $SYSADMIN $SYSADMIN_PASSWORD
    security test_logout $SYSADMIN
    security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    
    security update_authn_provider $LOCAL_LDAP_AUTHN_PROVIDER_NEWNAME
    balance run security add_tenant_role subject_id $LOCAL_LDAP_TENANTADMIN_USERNAME TENANT_ADMIN
    balance run security add_tenant_role subject_id $LOCAL_LDAP_TENANTADMIN_USERNAME TENANT_APPROVER
    balance run security login $LOCAL_LDAP_TENANTADMIN_USERNAME $LOCAL_LDAP_TENANTADMIN_PASSWORD
    balance run security add_tenant_role group $LOCAL_LDAP_TENANT_PROJECT_ADMINS_GROUP PROJECT_ADMIN
    balance run security login $LOCAL_LDAP_PROJECT_ADMIN_USERNAME $LOCAL_LDAP_PROJECT_ADMIN_PASSWORD
    balance run project create $PROJECT.securitytest
    balance run security login $LOCAL_LDAP_MAXGROUPSUSER_USERNAME $LOCAL_LDAP_MAXGROUPSUSER_PASSWORD
    for(( i=0; i<${#BOURNE_IP_ARRAY[@]};i++ ));
    do
        run security verify_user $LOCAL_LDAP_MAXGROUPSUSER_USERNAME --ip=${BOURNE_IP_ARRAY[$i]}
    done

    #run security logout
    #Test the ldaps provider
    balance run security login $SYSADMIN $SYSADMIN_PASSWORD
    balance security add_authn_provider $LOCAL_LDAP_AUTHN_MODE $LOCAL_SECURE_LDAP_AUTHN_URLS $LOCAL_SECURE_LDAP_AUTHN_MANAGER_DN $LOCAL_SECURE_LDAP_AUTHN_MANAGER_PWD $LOCAL_SECURE_LDAP_AUTHN_SEARCH_BASE $LOCAL_LDAP_AUTHN_SEARCH_FILTER $LOCAL_LDAP_AUTHN_AUTHN_GROUP_ATTR "$LOCAL_SECURE_LDAP_AUTHN_NAME" $LOCAL_SECURE_LDAP_AUTHN_DOMAINS "$LOCAL_SECURE_LDAP_AUTHN_WHITELIST" $LOCAL_LDAP_AUTHN_SEARCH_SCOPE --group_object_classes "$LOCAL_LDAP_AUTHN_GROUP_OBJECT_CLASSES" --group_member_attributes "$LOCAL_LDAP_AUTHN_GROUP_MEMBER_ATTRIBUTES"
    balance tenant add_attribute $LOCAL_SECURE_LDAP_AUTHN_DOMAINS $LOCAL_SECURE_LDAP_TENANT_ATTRIBUTE_KEY $LOCAL_SECURE_LDAP_TENANT_ATTRIBUTE_VALUE
    for(( i=0; i<${#BOURNE_IP_ARRAY[@]};i++ ));
    do
        run security login $LOCAL_SECURE_LDAP_USER_USERNAME $LOCAL_SECURE_LDAP_USER_PASSWORD --ip=${BOURNE_IP_ARRAY[$i]} 
    done
    
    #Test the LDAP provider
    balance run security login $SYSADMIN $SYSADMIN_PASSWORD
    balance tenant add_attribute $LOCAL_LDAP_AUTHN_DOMAINS $LOCAL_LDAP_TENANT_ATTRIBUTE_KEY $LOCAL_LDAP_TENANT_ATTRIBUTE_ROOT_SUBTENANT1_VALUE
        
    balance run security login $SYSADMIN $SYSADMIN_PASSWORD
    for(( i=0; i<${#BOURNE_IP_ARRAY[@]};i++ ));
    do
        run security verify_user $SYSADMIN --ip=${BOURNE_IP_ARRAY[$i]}
    done
    
    balance run security add_tenant_role subject_id $LOCAL_LDAP_USER_USERNAME_1 TENANT_ADMIN
    balance run security add_tenant_role subject_id $LOCAL_LDAP_USER_USERNAME_2 PROJECT_ADMIN
    
    # end of proxy token test
    
    # Leave the security test suite logged in as the super user
    balance tenant add_attribute $LOCAL_LDAP_AUTHN_DOMAINS $LOCAL_LDAP_TENANT_ATTRIBUTE_KEY $LOCAL_LDAP_TENANT_ATTRIBUTE_ROOT_TENANT_VALUE
    balance run security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD 
    security test_tenant_access_permissions $LOCAL_SECURE_LDAP_USER_USERNAME $LOCAL_SECURE_LDAP_USER_PASSWORD
    
    # test the domain name with spaces at the beginning and at the end CQ 603992
    # Tenant update with Whitespace before/after domain name and Group Name returns 400 before this change
    security login $SYSADMIN $SYSADMIN_PASSWORD
    security test_tenant_domain_update $SYSADMIN $SYSADMIN_PASSWORD $(toLower ${LOCAL_SECURE_LDAP_AUTHN_DOMAINS}) $LOCAL_SECURE_LDAP_TENANT_ATTRIBUTE_KEY $LOCAL_SECURE_LDAP_TENANT_ATTRIBUTE_VALUE
    
    # test adding and removing a group with spaces before and after the group's name CQ 603992
    tenant add_group $LOCAL_LDAP_AUTHN_DOMAINS "$LOCAL_LDAP_VIPR_USER_GROUP"
    tenant remove_group $LOCAL_LDAP_AUTHN_DOMAINS "$LOCAL_LDAP_VIPR_USER_GROUP"
    
    # test adding role with subject ID with spaces at the beginning and at the end and removing it for roles
    security add_tenant_role subject_id $LOCAL_SECURE_LDAP_USER_USERNAME_WITH_SPACES TENANT_ADMIN
    security remove_tenant_role subject_id $LOCAL_SECURE_LDAP_USER_USERNAME_WITH_SPACES TENANT_ADMIN
    
    # test the sequence: create a subtenant (TENANT_ID), get the URI of that tenant, 
    # deactivate the tenant and then try to create that tenant again. In the reply we should have the tenant ID like:
    # duplicated in another tenant (urn:storageos:TenantOrg:TENANT_ID)
    # The argument "true" means that we expect the tenant ID be reported in the error
    security test_tenant_duplicate_message $LOCAL_LDAP_AUTHN_DOMAINS "TEST_SUBTENANT_$$" "true"
    
    # The argument "false" means that we do not expect the tenant ID to be reported in the error
    security test_tenant_duplicate_message $LOCAL_LDAP_AUTHN_DOMAINS "TEST_SUBTENANT_$$" "false"
    
    # test that the password change with the same value returns the error 400
    security login $SYSADMIN $SYSADMIN_PASSWORD
    security test_password_change $SVCUSER $SYSADMIN_PASSWORD

    #Test the ad provider
	if [ "$TEST_AD_PROVIDER" = 'yes' ] ; then
		balance run security login $SYSADMIN $SYSADMIN_PASSWORD
		balance security add_authn_provider $AD_AUTHN_MODE $AD_AUTHN_URLS $AD_AUTHN_MANAGER_DN $AD_AUTHN_MANAGER_PWD $AD_AUTHN_SEARCH_BASE $AD_AUTHN_SEARCH_FILTER $AD_AUTHN_AUTHN_GROUP_ATTR "$AD_AUTHN_NAME" $AD_AUTHN_DOMAINS "$AD_AUTHN_WHITELIST" $AD_AUTHN_SEARCH_SCOPE 
		balance tenant add_attribute $AD_AUTHN_DOMAINS $AD_TENANT_ATTRIBUTE_KEY $AD_TENANT_ATTRIBUTE_VALUE
		for(( i=0; i<${#BOURNE_IP_ARRAY[@]};i++ ));
		do
			run security login $AD_USER_USERNAME $AD_USER_PASSWORD --ip=${BOURNE_IP_ARRAY[$i]} 
		done
	fi
}


##### full_copy tests 
#######################

VMAX3_FC_SMIS_DEV=VMAX3_FC_SMIS_DEV
VMAX3_FC_PORTS_A="FA-1D FA-3D"
VMAX3_FC_PORTS_B="FA-2D FA-4D"
COS_VMAX3BLOCK_FC=COS_VMAX3BLOCK_FC

vmax3_fc_setup_once()
{
    echo "begin: vmax3_fc_setup_once"

    smisprovider show $VMAX3_FC_SMIS_DEV &> /dev/null && return $?

    smisprovider create $VMAX3_FC_SMIS_DEV $VMAX3_FC_SMIS_IP 5988 $SMIS_USER "$SMIS_PASSWD" false

    storagedevice discover_all --ignore_error
    sleep 300

    echo "vmax3 fc - storagepools update"
    storagepool update $VMAX3_FC_NATIVEGUID --type block --volume_type THIN_ONLY
    storagepool update $VMAX3_FC_NATIVEGUID --type block --volume_type THICK_ONLY
    storagepool update $VMAX3_FC_NATIVEGUID --nhadd $NH --type block

    if [ $QUICK -eq 0 ]; then     
        echo "vmax3 fc storageports update"
        if [ $DISCOVER_SAN -eq 0 ]; then
           for porta in ${VMAX3_FC_PORTS_A}
           do
	      storageport update $VMAX3_FC_NATIVEGUID FC --tzone $FCTZ_A --group ${porta}
           done
	    for portb in ${VMAX3_FC_PORTS_B}
           do
              storageport update $VMAX3_FC_NATIVEGUID FC --tzone $FCTZ_B --group ${portb}
           done
       fi
       storageport update $VMAX3_FC_NATIVEGUID IP --tzone nh/iptz
    fi

    echo "vmax3 fc vpools"
    cos create block $COS_VMAX3BLOCK_FC false \
			 --description 'CoS for VMAX3 block FC' \
                      --protocols FC 			\
                      --numpaths 2 \
                      --max_snapshots 10 \
	               --system_type vmax \
                      --provisionType 'Thin' \
			 --neighborhoods $NH


    cos update block $COS_VMAX3BLOCK_FC --storage $VMAX3_FC_NATIVEGUID
    cos allow $COS_VMAX3BLOCK_FC block $TENANT

    echo "end: vmax3_fc_setup_once"
}

vmax_fc_setup()
{
    echo "begin: vmax_fc_setup"
    vmaxblock_setup
    # This vpool is used for the standard vmax tests and we
    # want to make sure the vmax3 is not used for those tests,
    # so we make sure to use only assigned pools, which are
    # those for the standard vmax array.
    cos update block $COS_VMAXBLOCK_FC --use_matched false
    vmax3_fc_setup_once
    echo "end: vmax_fc_setup"
}

full_copy_setup()
{
    echo Tenant is $TENANT
    echo Project is $PROJECT
    cos list block
    echo System components configured, ready for requests
    vmax_fc_setup
    vnxblock_setup
}

full_copy_single_volume_vnx()
{
    echo "Finished vnx full-copy"

    full_copy_source="${FULL_COPY_VOLUME}-source${RANDOM}"
    full_copy_clone="${FULL_COPY_VOLUME}-clone${RANDOM}"

    echo "Creating source volume for VNX"
    run volume create ${full_copy_source} $PROJECT $NH $COS_VNXBLOCK_FC 1073741825 --thinVolume true

    echo "Creating 1 full copy"
    # TODO sanity_utils does not yet handle the count arg.  If you change this, perform manual cleanup of +1 copies
    run volume full_copy ${full_copy_clone} $PROJECT/${full_copy_source} --count=1

    echo "Listing all full copies for source volume"
    run volume full_copy_list $PROJECT/${full_copy_source}

    echo "Resynchronizing full copy from source"
    run volume full_copy_resync $PROJECT/${full_copy_clone}

    echo "Restoring source from full copy"
    run volume full_copy_restore $PROJECT/${full_copy_clone}

    echo "Detaching full copy..."
    run volume detach ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}

    echo "Deactivating full copy volume"
    run volume delete $PROJECT/${full_copy_clone} --wait

    echo "Deactivating source volume"
    run volume delete $PROJECT/${full_copy_source} --wait
    
    echo "Finished vnx full-copy"
}

full_copy_single_volume_vmax()
{
    echo "Started vmax full-copy"

    full_copy_source="${FULL_COPY_VOLUME}-source${RANDOM}"
    full_copy_clone="${FULL_COPY_VOLUME}-clone${RANDOM}"

    echo "Creating source volume"
    run volume create ${full_copy_source} $PROJECT $NH $COS_VMAXBLOCK_FC 1073741825 --thinVolume true

    echo "Creating 1 full copy"
    # TODO sanity_utils does not yet handle the count arg.  If you change this, perform manual cleanup of +1 copies
    run volume full_copy ${full_copy_clone} $PROJECT/${full_copy_source} --count=1

    echo "Listing all full copies for source volume"
    run volume full_copy_list $PROJECT/${full_copy_source}

    echo "Resynchronizing full copy from source"
    run volume full_copy_resync $PROJECT/${full_copy_clone}

    echo "Restoring source from full copy"
    run volume full_copy_restore $PROJECT/${full_copy_clone}

    echo "Detaching full copy..."
    run volume detach ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}

    echo "Deactivating full copy volume"
    run volume delete $PROJECT/${full_copy_clone} --wait

    echo "Deactivating source volume"
    run volume delete $PROJECT/${full_copy_source} --wait

    echo "Finished vmax full-copy"
}

full_copy_single_volume_vmax_inactive()
{
    echo "Started vmax inactive full-copy"

    full_copy_source="${FULL_COPY_VOLUME}-source${RANDOM}"
    full_copy_clone="${FULL_COPY_VOLUME}-clone${RANDOM}"

    echo "Creating source volume"
    run volume create ${full_copy_source} $PROJECT $NH $COS_VMAXBLOCK_FC 1073741825 --thinVolume true

    echo "Creating 1 full copy"
    # TODO sanity_utils does not yet handle the count arg.  If you change this, perform manual cleanup of +1 copies
    run volume full_copy ${full_copy_clone} $PROJECT/${full_copy_source} --count=1 --create_inactive true

    echo "Checking synchronization progress"
    run volume full_copy_check_progress ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}

    echo "Activating full copy..."
    sleep 10
    run volume activate ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}

    echo "Checking synchronization progress"
    run volume full_copy_check_progress ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}
    echo "Checking synchronization progress"
    run volume full_copy_check_progress ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}
    echo "Checking synchronization progress"
    run volume full_copy_check_progress ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}

    echo "Detaching full copy..."
    sleep 10
    run volume detach ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}

    echo "Listing all full copies for source volume"
    run volume full_copy_list $PROJECT/${full_copy_source}

    echo "Deactivating source volume"
    run volume delete $PROJECT/${full_copy_source} --wait

    echo "Deactivating full copy volume"
    run volume delete $PROJECT/${full_copy_clone} --wait

    echo "Finished vmax inactive full-copy"
}

full_copy_single_volume_vmax3()
{
    echo "Started vmax3 full-copy"

    full_copy_source="${FULL_COPY_VOLUME}-source${RANDOM}"
    full_copy_clone="${FULL_COPY_VOLUME}-clone${RANDOM}"

    echo "Creating source volume"
    run volume create ${full_copy_source} $PROJECT $NH $COS_VMAX3BLOCK_FC 1073741825 --thinVolume true

    echo "Creating 1 full copy"
    # TODO sanity_utils does not yet handle the count arg.  If you change this, perform manual cleanup of +1 copies
    run volume full_copy ${full_copy_clone} $PROJECT/${full_copy_source} --count=1

    echo "Listing all full copies for source volume"
    run volume full_copy_list $PROJECT/${full_copy_source}

    echo "Resynchronizing full copy from source"
    run volume full_copy_resync $PROJECT/${full_copy_clone}

    echo "Restoring source from full copy"
    run volume full_copy_restore $PROJECT/${full_copy_clone}

    echo "Detaching full copy..."
    run volume detach ${PROJECT}/${full_copy_source} ${PROJECT}/${full_copy_clone}

    echo "Deactivating full copy volume"
    run volume delete $PROJECT/${full_copy_clone} --wait

    echo "Deactivating source volume"
    run volume delete $PROJECT/${full_copy_source} --wait

    echo "Finished vmax3 full-copy"
}

full_copy_tests()
{
    echo "Started full-copy tests"
    full_copy_single_volume_vmax_inactive
    full_copy_single_volume_vmax
    full_copy_single_volume_vmax3
    full_copy_single_volume_vnx
    echo "Finished full-copy tests"
}

##### end of full_copy tests

##### blockmirror tests 
#######################


blockmirror_setup()
{
    echo Tenant is $TENANT
    echo Project is: $PROJECT
    cos list block
    echo System components configured, ready for requests
    mirrorblock_setup
}

blockmirror_single_mirror()
{
    mirrortest_vol="${MIRROR_VOLUME}-single"

    echo "Creating source volume"
    run volume create ${mirrortest_vol} $PROJECT $NH $COS_MIRROR 1073741825 --thinVolume true

    echo "Attaching a single mirror"
    run blockmirror attach $PROJECT/${mirrortest_vol} "foo" 1 

    echo "Listing active mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}

    echo "Deactivating source volume"
    run volume delete $PROJECT/${mirrortest_vol} --wait
}

blockmirror_attach_mirror_with_optional()
{
    mirrortest_vol="${MIRROR_VOLUME}-mirrorcos"

    echo "Creating source volume"
    run volume create ${mirrortest_vol} $PROJECT $NH $COS_MIRROR_WITH_OPTIONAL 1073741825 --thinVolume true

    echo "Attaching a mirror"
    run blockmirror attach $PROJECT/${mirrortest_vol} "foo" 1 

    echo "Listing active mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}
    
    echo "Deactivating source volume"
    run volume delete $PROJECT/${mirrortest_vol} --wait
}

blockmirror_attach_2mirrors()
{
    mirrortest_vol="${MIRROR_VOLUME}-test-attach2"

    echo "Creating source volume"
    run volume create ${mirrortest_vol} $PROJECT $NH $COS_MIRROR_WITH_2_MIRRORS 1073741825 --thinVolume true

    echo "Attaching two mirrors"
    run blockmirror attach $PROJECT/${mirrortest_vol} "foo" 2 

    echo "Listing active mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}
    
    echo "Deactivating source volume and all mirrors"
    run volume delete $PROJECT/${mirrortest_vol} --wait
}

blockmirror_detach_mirror_all()
{
    mirrortest_vol="${MIRROR_VOLUME}-test-detach"

    echo "Creating source volume"
    run volume create ${mirrortest_vol} $PROJECT $NH $COS_MIRROR_WITH_2_MIRRORS 1073741825 --thinVolume true

    echo "Listing active mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}

    echo "Attaching first mirror"
    run blockmirror attach $PROJECT/${mirrortest_vol} "foo" 1 

    echo "Attaching second mirror"
    run blockmirror attach $PROJECT/${mirrortest_vol} "bar" 1 

    echo "Listing active mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}

    echo "Detaching all mirrors"
    run blockmirror detach $PROJECT/${mirrortest_vol}
    
    echo "Deactivating source volume and all mirrors"
    run volume delete $PROJECT/${mirrortest_vol} --wait
}

blockmirror_pause_resume_all()
{
    mirrortest_vol="${MIRROR_VOLUME}-test-pause-resume-all"

    echo "Creating source volume"
    run volume create ${mirrortest_vol} $PROJECT $NH $COS_MIRROR 1073741825 --thinVolume true 

    echo "Attaching first mirror"
    run blockmirror attach $PROJECT/${mirrortest_vol} "foo" 1 

    echo "Pausing all mirrors"
    run blockmirror pause $PROJECT/${mirrortest_vol}

    echo "Listing paused mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}

    echo "Resuming all mirrors"
    run blockmirror resume $PROJECT/${mirrortest_vol}

    echo "Listing resumed mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}

    echo "Deactivating source volume and all mirrors"
    run volume delete $PROJECT/${mirrortest_vol} --wait
}

blockmirror_vpool_change()
{
    mirrortest_vol="${MIRROR_VOLUME}-test-vpool-change"

    echo "Creating source volume with no mirrors explicitly"
    run volume create ${mirrortest_vol} $PROJECT $NH $COS_MIRROR_BEFORE_CHANGE 1073741825 --thinVolume true 

    echo "Change virtual pool to one that has 1 explicit maximum mirror"
    run volume change_cos $PROJECT/${mirrortest_vol} $COS_MIRROR_AFTER_CHANGE

    echo "Attaching a mirror"
    run blockmirror attach $PROJECT/${mirrortest_vol} "foo" 1 

    echo "Listing mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}

    echo "Deactivating source volume and all mirrors"
    run volume delete $PROJECT/${mirrortest_vol} --wait
}

blockmirror_vnx()
{
    mirrortest_vol="${MIRROR_VOLUME_VNX}-test-vnx"

    echo "Creating source volume on VNX"
    run volume create ${mirrortest_vol} $PROJECT $NH $COS_MIRROR_VNX 1073741825 --thinVolume true 

    echo "Attaching a mirror"
    run blockmirror attach $PROJECT/${mirrortest_vol} "foo" 1 

    echo "Pausing all mirrors"
    run blockmirror pause $PROJECT/${mirrortest_vol}

    echo "Listing paused mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}

    echo "Resuming all mirrors"
    run blockmirror resume $PROJECT/${mirrortest_vol}

    echo "Listing resumed mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}

    echo "Deactivating source volume and all mirrors"
    run volume delete $PROJECT/${mirrortest_vol} --wait
}

blockmirror_group_mirrors()
{
    mirrortest_vol="${MIRROR_VOLUME}-group"
    consistency_group=`openssl passwd "$RANDOM" | cut -c1-8`
    group_mirror="sanitytest"
    run blockconsistencygroup create $PROJECT $consistency_group

    # Create source volumes
    echo "Creating source volumes"
    run volume create ${mirrortest_vol}1 $PROJECT $NH $COS_VMAX_CG_MIRROR 1073741825 --thinVolume true --consistencyGroup $consistency_group
    run volume create ${mirrortest_vol}2 $PROJECT $NH $COS_VMAX_CG_MIRROR 1073741825 --thinVolume true --consistencyGroup $consistency_group

    run blockconsistencygroup show $consistency_group
    run volume list $PROJECT

    echo "Attaching group mirrors"
    run blockmirror attach $PROJECT/${mirrortest_vol}1 $group_mirror 1

    echo "Listing active mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}1
    run blockmirror list $PROJECT/${mirrortest_vol}2

    echo "Pausing group mirrors"
    run blockmirror pause $PROJECT/${mirrortest_vol}1

    echo "Listing group mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}1
    run blockmirror list $PROJECT/${mirrortest_vol}2

    echo "Resuming group mirrors"
    run blockmirror resume $PROJECT/${mirrortest_vol}1

    echo "Listing group mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}1
    run blockmirror list $PROJECT/${mirrortest_vol}2

    echo "Deactivating group mirrors"
    run blockmirror deactivate $PROJECT/${mirrortest_vol}1 ${mirrortest_vol}1-${group_mirror}

    echo "Listing group mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}1
    run blockmirror list $PROJECT/${mirrortest_vol}2

    echo "Attaching group mirrors"
    run blockmirror attach $PROJECT/${mirrortest_vol}1 ${group_mirror}1 1

    echo "Listing group mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}1
    run blockmirror list $PROJECT/${mirrortest_vol}2

    echo "Detaching group mirrors"
    run blockmirror detach $PROJECT/${mirrortest_vol}1

    echo "Listing group mirrors"
    run blockmirror list $PROJECT/${mirrortest_vol}1
    run blockmirror list $PROJECT/${mirrortest_vol}2

    echo "Deleting promoted volumes"
    run volume delete $PROJECT/${mirrortest_vol}1-${group_mirror}1 --wait
    run volume delete $PROJECT/${mirrortest_vol}2-${group_mirror}1 --wait

    echo "Deactivating source volumes"
    run volume delete $PROJECT/${mirrortest_vol}1 --wait
    echo "delete $PROJECT/${mirrortest_vol}2"
    run volume delete $PROJECT/${mirrortest_vol}2 --wait
}

blockmirror_tests()
{
    # quick_file_tests $COS_VNXFILE default
    # quick_block_tests $VMAXEXPORT_GROUP $VMAXEXPORT_GROUP_HOST $VMAX_VOLUME $COS_VMAXBLOCK
    # quick_block_tests $VNXEXPORT_GROUP $VNXEXPORT_GROUP_HOST $VNX_VOLUME $COS_VNXBLOCK
    blockmirror_single_mirror
    blockmirror_attach_mirror_with_optional
    blockmirror_attach_2mirrors
    blockmirror_detach_mirror_all
    blockmirror_pause_resume_all
    blockmirror_vpool_change

    #blockmirror_vnx
    blockmirror_group_mirrors
}

#### end of blockmirror test section

##### errorhandling tests 
#################################

errorhandling_setup()
{
    masa=`date +%s | cut -c5-10`
    mainvalue=value"$masa"
    mainkey=key"$masa"
    MAINERRORHANDLING=mainerrorhandling"$masa"
    PROJECTERRORHANDLING=prjcterrorhandling"$masa"
    echo
    echo System components configured, ready for requests
}

errorhandling_tests()
{
    ## CoS ErrorHandling tests
    cos errorhandling file $COS_VNXFILE 				\
			 --description 'CoS for VNX file' false 	\
                         --protocols NFS CIFS --provisionType 'Thin'
}

#### end of errorhandling test section

##### blockconsistencygroup tests
#################################

blockconsistencygroup_setup()
{
    # Run setup
    init_setup

    # Create MultiVolumeConsistency CoS
    consistencygroup_block_cos_setup

    # Create a Second Project
    date=`date +%s | cut -c5-10`
    PROJECT_GROUP_OTHER=cgProject"$date"
    project create $PROJECT_GROUP_OTHER --tenant $TENANT

    # Create Consistency Group
    blockconsistencygroup_create_test

    # Print environment
    echo System components configured for blockconsistencygroup tests, ready for requests
    echo Tenant is $TENANT
    echo Project is $PROJECT
    echo Project Other is $PROJECT_GROUP_OTHER  
    echo SMIS IP is $VNX_SMIS_IP
    echo VNX CG CoS is $VNX_COS_GROUP
    echo VMAX CG CoS is $VMAX_COS_GROUP
    echo CoS without MiltiVolumeConsistency $COS_GROUP_INVALID
    echo Consistency Group is $CONSISTENCY_GROUP
    echo Consistency Group Snapshot is $CONSISTENCY_GROUP_SNAPSHOT
}

blockconsistencygroup_create_test()
{
    ### create blockconsistencygroup
    echo "Creating consistency group"
    run blockconsistencygroup create $PROJECT $CONSISTENCY_GROUP
}

blockconsistencygroup_show_test()
{
    echo "Getting consistency group"
    run blockconsistencygroup show $CONSISTENCY_GROUP
}

blockconsistencygroup_bulk_test()
{
    echo "Getting bulk data for consistency groups"
    run blockconsistencygroup bulk
}

blockconsistencygroup_delete_test()
{
    ### delete blockconsistencygroup
    echo "Deleting consistency group"
    run blockconsistencygroup delete $CONSISTENCY_GROUP
}

blockconsistencygroup_add_volume_test()
{
    ### Create Volume
    echo "Adding volume to consistency group"
    run volume create  volume-${CONSISTENCY_GROUP} $PROJECT $NH $VNX_COS_GROUP 1280000000 --consistencyGroup $CONSISTENCY_GROUP

    ### Check that volume is inside the group
    echo "Checking volume is part of consistency group"
    run blockconsistencygroup check_volume  $PROJECT volume-${CONSISTENCY_GROUP} $CONSISTENCY_GROUP --expected

    ### Check that consistencygroup cannot be deleted at this point
    echo "Checking consistency group cannot be deleted with active volumes"
    run blockconsistencygroup delete_with_volumes $CONSISTENCY_GROUP
}

blockconsistencygroup_add_volume_invalid_project(){
    echo "Checking Volume creation fails when the consistency group project and the volume project don't match"

    # Create Volume in a different project: this should fail
    blockconsistencygroup check_volume_error volume-${CONSISTENCY_GROUP} $PROJECT_GROUP_OTHER $NH $VNX_COS_GROUP 1280000000 'Objects should all be in the project $projid' --consistencyGroup $CONSISTENCY_GROUP --consistencyGroupProject $PROJECT
}

blockconsistencygroup_add_volume_invalid_CoS(){
    echo "Checking volume creation fails when consistency group is provided but MultiVolumeConsistency attribute in VirtualPool is false"

    # Create Volume in a different project: this should fail
    blockconsistencygroup check_volume_error volume-${CONSISTENCY_GROUP} $PROJECT $NH $COS_GROUP_INVALID 1280000000 'Consistency group $cgid was provided but multi_volume_consistency attribute in the virtual pool $cosid is false' --consistencyGroup $CONSISTENCY_GROUP
}

blockconsistencygroup_add_volume_no_consistency_group(){
    echo "Checking volume creation fails when MultiVolumeConsistency attribute in VirtualPool is true but consistency group is not provided"

    # Create Volume in a different project: this should fail
    blockconsistencygroup check_volume_error volume-${CONSISTENCY_GROUP} $PROJECT $NH $VNX_COS_GROUP 1280000000 'Required parameter consistencyGroup was missing or empty' --servicecode 1005
}

blockconsistencygroup_create_snapshot()
{
    ### create blockconsistencygroup snapshot
    echo "Creating consistency group snapshot"
    run blockconsistencygroup create_snapshot $1 $2 --createInactive 
}

blockconsistencygroup_activate_snapshot()
{
    ### activate blockconsistencygroup snapshot
    echo "Activating consistency group snapshot"
    run blockconsistencygroup activate_snapshot $1 $2
}

blockconsistencygroup_deactivate_snapshot()
{
    ### deactivate blockconsistencygroup snapshot
    echo "Deactivating consistency group snapshot"
    run blockconsistencygroup deactivate_snapshot $1 $2
}

blockconsistencygroup_restore_snapshot()
{
    ### restore blockconsistencygroup snapshot
    echo "Restoring consistency group snapshot"
    run blockconsistencygroup restore_snapshot $1 $2
}

blockconsistencygroup_show_snapshot()
{
    ### show blockconsistencygroup snapshot
    echo "Showing consistency group snapshot"
    run blockconsistencygroup show_snapshot $1 $2
}

blockconsistencygroup_list_snapshot()
{
    ### list blockconsistencygroup snapshot
    echo "Listing consistency group snapshot"
    run blockconsistencygroup list_snapshots $1 $2
}

blockconsistencygroup_cleanup(){
    echo "Cleaning up after running blockconsistencygroup test"

    ### Delete volume from consistency group
    echo "Deleting volume from consistency group"
    run volume delete $PROJECT/volume-${CONSISTENCY_GROUP} --wait

    # Remove Invalid CoS
    cos delete $COS_GROUP_INVALID block

    # Delete the project
    project delete $PROJECT_GROUP_OTHER

    # Remove Consistency Group
    blockconsistencygroup_delete_test
}

blockconsistencygroup_setup_snapshot()
{
    echo "Creating setup for Consistency Group Snapshot tests"

    # Creating Consisstency Group for the snapshot
    run blockconsistencygroup create $PROJECT $1

    # Adding a Volume to the Consistency Group
    run volume create  volume-$1 $PROJECT $NH $2 1280000000 --consistencyGroup $1
}

blockconsistencygroup_snapshot_tests()
{    
    cg_name=$1
    cg_cos=$2
    cg_snapshot=$3
    
    echo "Running Consistency Group Snapshot tests"
    echo "Consistency Group: $cg_name"
    echo "CoS: $cg_cos"
    echo "CG Snapshot: $cg_snapshot" 
    
    blockconsistencygroup_setup_snapshot $cg_name $cg_cos
    blockconsistencygroup_create_snapshot $cg_name $cg_snapshot
    blockconsistencygroup_activate_snapshot $cg_name $cg_snapshot
    blockconsistencygroup_restore_snapshot $cg_name $cg_snapshot
    blockconsistencygroup_show_snapshot $cg_name $cg_snapshot
    blockconsistencygroup_list_snapshot $cg_name $cg_snapshot
    blockconsistencygroup_deactivate_snapshot $cg_name $cg_snapshot   
}

blockconsistencygroup_update_tests()
{
    cg1=$1
    cg1_vpool=$2

    cg2=$3
    cg2_vpool=$4

    run volume create vnx-vol $PROJECT $NH cosvnxb 1GB
    run volume create vmax-vol $PROJECT $NH cosvmaxb 1GB

    blockconsistencygroup create $PROJECT $cg1
    blockconsistencygroup create $PROJECT $cg2

    echo Trying to update CG that is not on array
    blockconsistencygroup update $cg1 --add $PROJECT/vnx-vol
    blockconsistencygroup update $cg2 --add $PROJECT/vmax-vol

    echo Creating volumes and adding them to the CG
    run volume create vnx-vol-cg $PROJECT $NH $cg1_vpool 1GB --count=2 --consistencyGroup=$cg1
    run volume create vmax-vol-cg $PROJECT $NH $cg2_vpool 1GB --count=2 --consistencyGroup=$cg2

    blockconsistencygroup show $cg1
    blockconsistencygroup show $cg2

    echo Creating volumes to update
    run volume create vnx-update $PROJECT $NH $cg1_vpool 1GB --count=3
    run volume create vmax-update $PROJECT $NH $cg2_vpool 1GB --count=3

    echo Adding volumes to CG
    run blockconsistencygroup update $cg1 --add $PROJECT/vnx-update-1,$PROJECT/vnx-update-2,$PROJECT/vnx-update-3
    run blockconsistencygroup update $cg2 --add $PROJECT/vmax-update-1,$PROJECT/vmax-update-2,$PROJECT/vmax-update-3

    echo Remove volumes from CG
    run blockconsistencygroup update $cg1 --remove $PROJECT/vnx-update-1
    run blockconsistencygroup update $cg2 --remove $PROJECT/vmax-update-1

    echo Add and Remove volumes from CG
    run blockconsistencygroup update $cg1 --remove $PROJECT/vnx-update-2 --add $PROJECT/vnx-update-3
    run blockconsistencygroup update $cg2 --remove $PROJECT/vmax-update-2 --add $PROJECT/vmax-update-3

    echo Cleaning up after CG update tests
    volume delete $PROJECT --project --wait
    blockconsistencygroup delete $cg1
    blockconsistencygroup delete $cg2
}

blockconsistencygroup_tests()
{
    blockconsistencygroup_show_test
    blockconsistencygroup_add_volume_test
    blockconsistencygroup_add_volume_invalid_project
    blockconsistencygroup_add_volume_invalid_CoS
#    blockconsistencygroup_add_volume_no_consistency_group
    blockconsistencygroup_snapshot_tests vnx-$CONSISTENCY_GROUP $VNX_COS_GROUP vnx-$CONSISTENCY_GROUP_SNAPSHOT 
    blockconsistencygroup_snapshot_tests vmax-$CONSISTENCY_GROUP $VMAX_COS_GROUP vmax-$CONSISTENCY_GROUP_SNAPSHOT
    blockconsistencygroup_bulk_test
    blockconsistencygroup_cleanup
    blockconsistencygroup_update_tests vnx-update $VNX_COS_GROUP vmax-update $VMAX_COS_GROUP
}

#### end of blockconsistencygroup test section

init_setup()
{
#    vnxfile_setup
    vnxblock_setup
    vmaxblock_setup
}

# ------------------------------------------------------------------------------------
# The 'init' operation is way to set up Bourne with all the configuration, but not run
# any tests. This would be useful for setting up for running manual test cases.
# ------------------------------------------------------------------------------------
init_tests()
{
    echo Tenant is $TENANT
    echo Project is $PROJECT
    cos list block
    echo System components configured, ready for requests
}

quick_setup()
{
    echo "quick setup"
#    vnxfile_setup
    VNXB_NATIVEGUID=$SIMULATOR_VNX_NATIVEGUID
    VMAX_NATIVEGUID=$SIMULATOR_VMAX_NATIVEGUID
    vnxblock_setup
#    datadomainfile_setup
    vmaxblock_setup
    errorhandling_setup

}

quick_tests()
{
#    quick_file_tests $COS_NETAPP default
#    quick_file_tests $COS_VNXFILE default
    # TODO Add isilon simulator WJEIV
    quick_block_tests $VMAXEXPORT_GROUP $VMAXEXPORT_GROUP_HOST $VMAX_VOLUME $COS_VMAXBLOCK
    quick_block_tests $VNXEXPORT_GROUP $VNXEXPORT_GROUP_HOST $VNX_VOLUME $COS_VNXBLOCK
    #quick_file_tests $COS_DDFILE default
    errorhandling_tests
}

all_tests()
{
#    ui_tests
#    webstorage_tests
    isilon_tests
#    vplex_tests
#    vnxfile_tests
#    datadomainfile_tests
    vnxblock_tests
    vmaxblock_tests
    blocksnapshot_tests
    blockmirror_tests
    blockconsistencygroup_tests
    syssvc_tests
    security_tests
    errorhandling_tests	
    ingestblock_tests
}

# query auditlogs happened in specific timeslot and return them in desired language
audit_setup()
{
    echo "Nothing to do for audit setup"
}

audit_tests()
{
    language="en_US"
    if [ -z ${EXTRA_PARAM} ]; then
        timeslot=`date -u +%Y-%m-%dT%H`
    else 
        timeslot=${EXTRA_PARAM}
    fi
    audit query $timeslot $language
}

# query monitorlogs happened in specific timeslot and return them in desired language
monitor_setup()
{
    echo "Nothing to do for monitor setup"
}

monitor_tests()
{
    language="en_US"
    if [ -z ${EXTRA_PARAM} ]; then
        timeslot=`date -u +%Y-%m-%dT%H`
    else
        timeslot=${EXTRA_PARAM}
    fi
    monitor query $timeslot $language
}

vdc_setup()
{
	vdc_common_setup	
	vdc_federation_setup
}

vdc_common_setup()
{
	login_nd_configure_smtp_nd_add_licenses

    syssvc $CONFIG_FILE "$BOURNE_IP" set_prop system_proxyuser_encpassword ${SYSADMIN_PASSWORD}
    tenant_setup
    
    project_setup
    projectid=$(project query $PROJECT)
    echo "Project id of $PROJECT is $projectid."
    
    export BOURNE_API_SYNC_TIMEOUT=5600
}

sec_start_ldap_server()
{
    echo "Starting the in memory ldap server at http://${LOCAL_LDAP_SERVER_IP}:8082."
    resp_status=0
    while (($resp_status != 200))
    do
	  exec 3>&1
	  resp_status=$(curl -sw "%{http_code}" -o >(cat >&3) -k -H "Content-Type:application/json" -X POST -d '{"listener_name":"ViPRSanityLDAP"}' http://${LOCAL_LDAP_SERVER_IP}:8082/ldap-service/start)
	  if (($resp_status != 200))
	  then
	     echo "Response received : $resp_status. Retrying. Make sure ldap simulator service is started and listening at http://${LOCAL_LDAP_SERVER_IP}:8082."
	  else
	     echo "Response received : $resp_status. In memory ldap server started successfully."
	  fi
    done
}

# after this setup, vdcs will combine a federation
vdc_federation_setup()
{
	if [ "$VDC_ENDPOINT_B" == "$VDC_DEFAULT_ENDPOINT" ] ; then
        echo -e "\nFail: Usage of vdc sanity test is like:\n ./sanity 255.254.253.vdc1 vdc 255.254.253.vdc2"
        echo -e "\nOr you can test more vdcs use:\n ./sanity 255.254.253.vdc1 vdc 255.254.253.vdc2 255.254.253.vdc3"
        exit 1
    fi

    VDC_ENDPOINT_A=$BOURNE_IPADDR
    export BOURNE_IPADDR=$VDC_ENDPOINT_B
    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        security login $SYSADMIN $SYSADMIN_PASSWORD
    fi

    echo "do Login, Configure SMTP, and add controller and object licenses in $BOURNE_IPADDR"
    BOURNE_IP=$BOURNE_IPADDR
    login_nd_configure_smtp_nd_add_licenses
    syssvc $CONFIG_FILE "$BOURNE_IP" set_prop system_permit_root_ssh yes
    sleep 60
    vdc waitforstablestate 10 600
    echo "login_nd_configure_smtp_nd_add_licenses in $BOURNE_IPADDR done"

    echo "Get security key from $VDC_ENDPOINT_B"
    VDC_ENDPOINT_B_SECRETKEY=`vdc get_key|tail -1`
    echo "Key: $VDC_ENDPOINT_B_SECRETKEY"

    echo "Get cert chain from $VDC_ENDPOINT_B"
    VDC_ENDPOINT_B_CERTCHAIN=`vdc get_certchain`
    echo "Certchain: $VDC_ENDPOINT_B_CERTCHAIN"

    # if ${4} exists, will test three vdcs' CRUD operations
    if [ "$VDC_ENDPOINT_C" != "$VDC_DEFAULT_ENDPOINT" ] ; then
        VDC_ENDPOINT_C_NAME=vdc_name_C_$$
        VDC_ENDPOINT_C_SECRETKEY=
        VDC_ENDPOINT_C_ID=
        VDC_ENDPOINT_C_CERTCHAIN=

        export BOURNE_IPADDR=$VDC_ENDPOINT_C
        if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
            security login $SYSADMIN $SYSADMIN_PASSWORD
        fi

        echo "do Login, Configure SMTP, and add controller and object licenses in the 3rd vdc: $BOURNE_IPADDR"
        BOURNE_IP=$BOURNE_IPADDR
        login_nd_configure_smtp_nd_add_licenses
        syssvc $CONFIG_FILE "$BOURNE_IP" set_prop system_permit_root_ssh yes
        sleep 60
        vdc waitforstablestate 10 600
        echo "login_nd_configure_smtp_nd_add_licenses in the 3rd vdc: $BOURNE_IPADDR done"

        echo "Get security key from $VDC_ENDPOINT_C"
        VDC_ENDPOINT_C_SECRETKEY=`vdc get_key|tail -1`
        echo "Key: $VDC_ENDPOINT_C_SECRETKEY"

        echo "Get cert chain from $VDC_ENDPOINT_C"
        VDC_ENDPOINT_C_CERTCHAIN=`vdc get_certchain`
        echo "Certchain: $VDC_ENDPOINT_C_CERTCHAIN"
    fi

    export BOURNE_IPADDR=$VDC_ENDPOINT_A
    export BOURNE_IP=$VDC_ENDPOINT_A
    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    fi
    
    echo "Adding new vdc into current vipr system"
    vdc add $VDC_ENDPOINT_B_NAME $VDC_ENDPOINT_B $VDC_ENDPOINT_B_SECRETKEY "$VDC_ENDPOINT_B_CERTCHAIN"
    if [ $? -ne 0 ]; then
        echo "Add vdc B failed."
        exit 1
    fi
    sleep 30
    vdc waitforstablestate 10 600
    echo "Adding vdc done"
    
    if [ "$VDC_ENDPOINT_C" != "$VDC_DEFAULT_ENDPOINT" ] ; then
        echo "Adding the 3rd vdc into current vipr system"
        vdc add $VDC_ENDPOINT_C_NAME $VDC_ENDPOINT_C $VDC_ENDPOINT_C_SECRETKEY "$VDC_ENDPOINT_C_CERTCHAIN"
        if [ $? -ne 0 ]; then
            echo "Add vdc C failed."
            exit 1
        fi
        sleep 30
        vdc waitforstablestate 10 600
        echo "Adding the 3rd vdc done"
    fi

	echo "Test on global resource after vdc joined"
    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    fi
    project show $VDC_TEST_PROJECT &> /dev/null && return $?
    project create $VDC_TEST_PROJECT --tenant $TENANT
    echo "Project $VDC_TEST_PROJECT created on first vdc."
    echo "Login next vdc to list the created vdc"
    VDC_ENDPOINT_A=$BOURNE_IPADDR
    export BOURNE_IPADDR=$VDC_ENDPOINT_B
    security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    project search $(echo $VDC_TEST_PROJECT | head -c 2)
    if [ "$VDC_ENDPOINT_C" != "$VDC_DEFAULT_ENDPOINT" ] ; then
        export BOURNE_IPADDR=$VDC_ENDPOINT_C
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
        project search $(echo $VDC_TEST_PROJECT | head -c 2)
    fi
    export BOURNE_IPADDR=$VDC_ENDPOINT_A
    echo "Test on global resource done"
    
    security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    VDC_ENDPOINT_B_ID=`vdc get_id $VDC_ENDPOINT_B_NAME|tail -1`
    echo "new vdc id: $VDC_ENDPOINT_B_ID"

    if [ "$VDC_ENDPOINT_C" != "$VDC_DEFAULT_ENDPOINT" ] ; then
        VDC_ENDPOINT_C_ID=`vdc get_id $VDC_ENDPOINT_C_NAME|tail -1`
        echo "the 3rd vdc id: $VDC_ENDPOINT_C_ID"
    fi
}

vdc_discon_reconn_test()
{
	echo "Disconnecting the vdc in current vipr system"
    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    fi
    echo "Disconnecting with $VDC_ENDPOINT_B"

    # Stop all the services on the vdc which we want to disconnect, make it to inaccessable.
    stop_vdc_services $VDC_ENDPOINT_B 
    sleep 30
    vdc disconnect $VDC_ENDPOINT_B_ID
    if [ $? -ne 0 ]; then
        echo "Disconnect vdc failed."
        exit 1
    fi
    sleep 30
    vdc waitforstablestate 10 600
    echo "Disconnecting vdc done"
    
    project show $VDC_TEST_DISCONN_RECONN_PROJECT &> /dev/null && return $?
    project create $VDC_TEST_DISCONN_RECONN_PROJECT --tenant $TENANT
    echo "Project $VDC_TEST_DISCONN_RECONN_PROJECT created on remain vdc after disconnect."
    echo "Will check above project data after reconnecting vdc."
    
    echo "Reconnecting the vdc in current vipr system"
    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    fi

    # Restart all the services on the vdc which we disconnected, make it back online to reconnect.
    start_vdc_services $VDC_ENDPOINT_B
    sleep 180 
    vdc reconnect $VDC_ENDPOINT_B_ID
    if [ $? -ne 0 ]; then
        echo "Resconnect vdc failed."
        exit 1
    fi
    sleep 30
    vdc waitforstablestate 10 600
    echo "Reconnecting vdc done"
    
    echo "Start to check the Project $VDC_TEST_DISCONN_RECONN_PROJECT data."

    VDC_ENDPOINT_A=$BOURNE_IPADDR
    export BOURNE_IPADDR=$VDC_ENDPOINT_B
    security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD

    j=0
    success=false
    while [ $j -lt 60 ]
    do
        project search $(echo $VDC_TEST_DISCONN_RECONN_PROJECT | head -c 5)

        if [ $? -eq 0 ]
        then
            success=true
            break
        fi

        echo "The cluster ${BOURNE_IP} is not stable yet sleep 30 seconds"
        sleep 30
        j=j+1
    done

    if [ $success = true ];
    then
        echo "Find project data after reconnecting vdc."
    else
        echo "Failed to find project data after reconnecting vdc."
        exit 1
    fi

    echo "Test on disconnect and reconnect vdc done"
    export BOURNE_IPADDR=$VDC_ENDPOINT_A
}
	
vdc_tests()
{
	vdc_discon_reconn_test

    echo "Updating the new vdc in current vipr system"
    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    fi
    VDC_ENDPOINT_B_NAME='VDC_B_NEW_NAME'
    vdc update $VDC_ENDPOINT_B_ID $VDC_ENDPOINT_B_NAME
    if [ $? -ne 0 ]; then
        echo "Update vdc failed."
        exit 1
    fi
    sleep 30
    vdc waitforstablestate 10 600
    echo "Updating vdc done"

    if [ "$VDC_ENDPOINT_C" != "$VDC_DEFAULT_ENDPOINT" ] ; then
        echo "Updating the 3rd vdc in current vipr system"
        VDC_ENDPOINT_C_NAME='VDC_C_NEW_NAME'
        vdc update $VDC_ENDPOINT_C_ID $VDC_ENDPOINT_C_NAME
        sleep 30
        vdc waitforstablestate 10 600
        echo "Updating the 3rd vdc done"
    fi

    echo "Removing the new vdc"
    vdc del $VDC_ENDPOINT_B_ID
    if [ $? -ne 0 ]; then
        echo "Remove vdc failed."
        exit 1
    fi
    sleep 30
    vdc waitforstablestate 10 600
    echo "Removing vdc done"

    if [ "$VDC_ENDPOINT_C" != "$VDC_DEFAULT_ENDPOINT" ] ; then
        echo "Removing the 3rd vdc"
        vdc del $VDC_ENDPOINT_C_ID
        sleep 30
        vdc waitforstablestate 10 600
        echo "Removing the 3rd vdc done"
    fi

    echo "Test on resource after vdc removed"
    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    fi
    project show $VDC_TEST_REMOVE_PROJECT &> /dev/null && return $?
    project create $VDC_TEST_REMOVE_PROJECT --tenant $TENANT
    echo "Project $VDC_TEST_REMOVE_PROJECT created on first vdc."
    echo "Login other vdc to search the created vdc"
    VDC_ENDPOINT_A=$BOURNE_IPADDR
    export BOURNE_IPADDR=$VDC_ENDPOINT_B

    security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    # finding nothing is right, and it will throw python exception, we must catch it
    VDC_REMOVE_TEST_RESULT=`project search $(echo $VDC_TEST_REMOVE_PROJECT | head -c 5)\
    >> /tmp/pythonexception 2>&1 || echo "ok"`
    if [ "$VDC_REMOVE_TEST_RESULT" != "ok" ] ; then
        echo -e "\nError Happens in Test on resource after vdc removed in $BOURNE_IPADDR"
        exit 1
    fi
    echo "Find nothing, the result is $VDC_REMOVE_TEST_RESULT"
    if [ "$VDC_ENDPOINT_C" != "$VDC_DEFAULT_ENDPOINT" ] ; then
        export BOURNE_IPADDR=$VDC_ENDPOINT_C
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
        VDC_REMOVE_TEST_RESULT=`project search $(echo $VDC_TEST_REMOVE_PROJECT | head -c 5)\
        >> /tmp/pythonexception 2>&1 || echo "ok"`
        if [ "$VDC_REMOVE_TEST_RESULT" != "ok" ] ; then
            echo -e "\nError Happens in Test on resource after vdc removed in $BOURNE_IPADDR"
            exit 1
        fi
        echo "Find nothing, the result is $VDC_REMOVE_TEST_RESULT"
    fi
    export BOURNE_IPADDR=$VDC_ENDPOINT_A
    echo "Test on resource after vdc removed done"

    echo "Delete project $VDC_TEST_PROJECT."
    if [ "$BOURNE_SECURITY_DISABLED" != '1' -a "$AUTH" != 'local' ] ; then
        security login $LOCAL_LDAP_SUPERUSER_USERNAME $LOCAL_LDAP_SUPERUSER_PASSWORD
    fi
    project delete $VDC_TEST_PROJECT

    echo "ALL VDC TEST DONE"
}

stop_vdc_services()
{
    VIP=$1
    OPT=""
    NETWORK_PATTERN='^network_.*_ipaddr='
    if [[ $VIP == \[* ]];
    then
        tmp=${VIP#*[}
        VIP=${tmp%]*}
        OPT="-6"
        NETWORK_PATTERN='^network_.*_ipaddr6='
    fi

    echo "VIP=$VIP OPT=$OPT"
    IP_ADDRESS_LIST=`SSH $VIP "/etc/systool --getprops | grep '$NETWORK_PATTERN' | cut -d= -f 2 " $OPT`

    echo "stop services on VDC($VIP) that has following IP addresses $IP_ADDRESS_LIST"
    for ip_addr in $IP_ADDRESS_LIST
    do
        SSH $ip_addr 'service nginx stop;' $OPT
        SSH $ip_addr '/etc/storageos/storageos stop;' $OPT
    done
}

start_vdc_services()
{
    VIP=$1
    NETWORK_PATTERN='^network_.*_ipaddr='
    if [[ $VIP == \[* ]];
    then
        tmp=${VIP#*[}
        VIP=${tmp%]*}
        OPT="-6"
        NETWORK_PATTERN='^network_.*_ipaddr6='
    fi

    echo "VIP=$VIP OPT=$OPT"
    IP_ADDRESS_LIST=`SSH $VIP "/etc/systool --getprops | grep '$NETWORK_PATTERN' | cut -d= -f 2 " $OPT`
    echo "start services on VDC($VIP) that has following IP addresses $IP_ADDRESS_LIST"
    for ip_addr in $IP_ADDRESS_LIST
    do
        SSH $ip_addr '/etc/storageos/storageos start;' $OPT
        SSH $ip_addr 'service nginx start;' $OPT
    done
}

#Usage: sanity <conf path> <vip> backuprestore
# E.g.: sanity conf/sanity.conf 137.69.169.21 backuprestore
backuprestore_setup()
{
    echo "Setup backup restore environment begin"
    vip=$BOURNE_IPADDR

    echo "Enable root ssh permit"
    syssvc $CONFIG_FILE "$vip" set_prop system_permit_root_ssh yes
    echo "Enable root ssh permit done"
}

backuprestore_tests()
{
    backupname='sanity'
    filepath='/tmp/sanity.zip'

    backup_tests "${backupname}" "${filepath}"
    restore_tests "${filepath}"
}

backup_tests()
{
    backupname=$1
    filepath=$2

    echo "Creating backup(${backupname})"
    backup create "${backupname}"
    if [ $? == 0 ]; then
        echo "Create backup successful"
    else
        echo "Create backup failed"
        exit 1
    fi

    echo "Creating backup(${backupname}-tmp)"
    backup create "${backupname}-tmp"
    if [ $? == 0 ]; then
        echo "Create backup successful"
    else
        echo "Create backup failed"
        exit 1
    fi

    echo "Listing backup(${backupname})"
    found=`backup list "${backupname}"`
    echo "found=$found"
    if [ "$found"x == "${backupname}"x ]; then
        echo "List backup successful"
    else
        echo "List backup failed"
        exit 1
    fi

    echo "Deleting backup(${backupname}-tmp)"
    backup delete "${backupname}-tmp"
    if [ $? == 0 ]; then
        echo "Delete backup successful"
    else
        echo "Delete backup failed"
        exit 1
    fi

    echo "Listing backup(${backupname}-tmp)"
    found=`backup list "${backupname}-tmp"`
    echo "found=$found"
    if [ "$found"x == "${backupname}-tmp"x ]; then
        echo "Backup(${backupname}-tmp) should not exist"
        exit 1
    fi

    echo "Downloading backup(${backupname}) to ${filepath}"
    backup download "${backupname}" "${filepath}"
    if [[ $? == 0 && -f ${filepath} ]]; then
        echo "Download backup successful"
    else
        echo "Download backup failed"
        exit 1
    fi

    echo "Deleting backup(${backupname})"
    backup delete "${backupname}"
    if [ $? == 0 ]; then
        echo "Delete backup successful"
    else
        echo "Delete backup failed"
        exit 1
    fi
}

restore_tests()
{
    filepath=$1
    password=$SYSADMIN_PASSWORD

    echo "Uploading backup file ${filepath} to $BOURNE_IPADDR"
    SCP $BOURNE_IPADDR ${filepath} ${filepath}

    echo "Restoring backup file ${filepath} on $BOURNE_IPADDR"    
    result=`SSH $BOURNE_IPADDR "echo -e 'yes\n$password' | /opt/storageos/bin/restore '${filepath}'" | grep 'Restore'`
    echo "$result"
    if [ "$result"x != "Restore successful!"x ]; then
        echo "Please check /opt/storageos/logs/bkutils.log for details"
        exit 1
    fi
}

recovery_setup()
{
    echo "Setup minority node corrupted cluster($BOURNE_IPADDR) begin"
    vip=$BOURNE_IPADDR
    corrupted_node_id=2

    echo "Enable root ssh permit"
    syssvc $CONFIG_FILE "$vip" set_prop system_permit_root_ssh yes
    echo "Enable root ssh permit done"
    recovery wait_for_stable 10 600

    if [[ $vip == \[* ]]; then
        tmp=${vip#*[}
        vip=${tmp%]*}
        opt="-6"
        network_patten="^network_${corrupted_node_id}_ipaddr6="
    else
        opt=""
        network_patten="^network_${corrupted_node_id}_ipaddr="
    fi

    echo "network_patten=$network_patten opt=$opt"
    node_count=`SSH $vip "/etc/systool --getprops | grep '^node_count=' | cut -d= -f 2" $opt`
    if [[ $node_count -lt 3 ]]; then
        echo "Could not do node recovery on cluster that node count($node_count) less then 3"
        exit 2
    fi

    ip_addr=`SSH $vip "/etc/systool --getprops | grep '$network_patten' | cut -d= -f 2 " $opt`
    export RECOVERY_CORRUPTED_NODE_IP=$ip_addr

    echo "Simulating vipr${corrupted_node_id}($RECOVERY_CORRUPTED_NODE_IP) crash"
    recovery_node_crash $RECOVERY_CORRUPTED_NODE_IP
    echo "Make vipr${corrupted_node_id}($RECOVERY_CORRUPTED_NODE_IP) corrupted done"
 
    sleep 60
    echo "Setup minority node corrupted cluster($BOURNE_IPADDR) successful"
}

recovery_tests()
{
    echo "Begin to run node recovery on $BOURNE_IPADDR"
    recovery trigger
 
    for(( i=0; i<10; i++ )); do
       recovery_status=`recovery get_status`
       echo "Cuttent recovery status is: $recovery_status"
       if [ recovery_status != '' ]; then
           break;
       fi
       sleep 3 
    done

    recovery_status=`recovery get_status`
    if [ recovery_status != '' ]; then
        echo "Simulating vipr${corrupted_node_id}($RECOVERY_CORRUPTED_NODE_IP) redeployment"
        recovery_node_redeploy $RECOVERY_CORRUPTED_NODE_IP
        echo "Make vipr${corrupted_node_id}($RECOVERY_CORRUPTED_NODE_IP) redeployed done"
    else
        echo "Unexcepted error"
        recovery_node_startup $RECOVERY_CORRUPTED_NODE_IP
        exit 1                         
    fi

    while true; do
        recovery_status=`recovery get_status`
        echo "Cuttent recovery status is: $recovery_status"
        if [ recovery_status == '' ]; then
            echo "Unexcepted error"
            exit 1
        elif [[ "${recovery_status[*]}" == *"DONE"* ]]; then
            echo "Node recovery successful"
            break
        elif [[ "${recovery_status[*]}" == *"FAILED"* ]]; then
            echo "Node recovery failed"
            exit 1
        elif [[ "${recovery_status[*]}" == *"REPAIRING"* ]]; then
            db_repair_status=`recovery get_db_repair_status`
            echo "Db repair status is: $db_repair_status"
            sleep 10
        else
            sleep 5
        fi
    done
}

recovery_node_crash()
{
    ip_addr=$1
    opt=$2
    SSH $ip_addr '/etc/storageos/storageos stop; rm -rf /data/db/1 /data/geodb/1 /data/zk/*' $opt
}

recovery_node_redeploy()
{
    ip_addr=$1
    opt=$2
    SSH $ip_addr 'echo startupmode=hibernate > /data/db/startupmode; echo startupmode=hibernate > /data/geodb/startupmode; chown -R storageos:storageos /data; /etc/storageos/storageos start' $opt
}

recovery_node_startup()
{
    ip_addr=$1
    opt=$2
    SSH $ip_addr '/etc/storageos/storageos start' $opt
}

objcontrolsvc_setup()
{
    echo "Nothing to do for objcontrol setup"
}

objcontrolsvc_tests()
{
    nodeobj create "datanode-001"
    echo "Create node object datanode-001 succeed."
    nodeobj create "datanode-002"
    echo "Create node object datanode-002 succeed."
    nodeobj create "datanode-003"
    echo "Create node object datanode-003 succeed."
}

# Save the latest token file to token.txt on error for debugging and remove the current one
save_token_file() {
    if [ "$BOURNE_SECURITY_DISABLED" != "1" ]; then
       [ -f ${BOURNE_TOKEN_FILE} ] && mv ${BOURNE_TOKEN_FILE} ${BOURNE_SAVED_TOKEN_FILE}
    fi
}

_failure() {
    echo "***"                                                   >&2
    echo "*** FAILED! $0:${LINENO}: `eval echo ${BASH_COMMAND}`" >&2
    echo "***"                                                   >&2
    date
    run_undo_commands
    save_token_file
    exit 1
}

_success() {
    echo "***"                                                   >&2
    echo "*** PASSED!"                                           >&2
    echo "***"                                                   >&2
    date
    save_token_file
    finalize_undo_log
}

#counterpart for run
#executes a command that is expected to fail
fail(){
    cmd=$*
    echo $cmd
    trap - ERR
    $cmd 2>&1
    status=$?
    if [ $status -eq 0 ] ; then
        echo '**********************************************************************'
        echo $cmd succeeded, which should not have happened
        echo '**********************************************************************'
        trap _failure ERR
        set_undo $cmd
        exit 1
    fi
    echo $cmd failed, which is the expected ouput
    trap _failure ERR
}

trap _failure ERR INT
set -E
if [ "$2" != "recoverpoint" ] && [ "$2" != "vdc" ]; then
    common_setup	
fi

datastore_setup(){
    opname=$1
    fileCos=$2
    opsize=$3
    deviceType=$4

    echo "create datastore for device" $deviceType
    if [ "$deviceType" = "nfsexportpoints" ]; then
        run datastore create nfsexportpoints $opname $NH --size $opsize --mountpoint $opname
    fi
    if [ "$deviceType" = "filesystems" ]; then
        run datastore create filesystems $opname $NH --filecos $fileCos --size $opsize
    fi
}

output_conf(){
    file=$WS_SETUP
    echo "nh="$NH > "$file"
    echo "tenant="$TENANT >> "$file"
    echo "namespace="$NAMESPACE >> "$file"
    echo "project="$PROJECT >> "$file"
    echo "cos="${WS_SETUP_COS#,} >> "$file"
    echo "user=$WS_UID" >> "$file"
    echo "secretkey=$WS_SECRET" >> "$file"
    echo "bucket=${WS_SETUP_BUCKETS# }" >> "$file"
}

vplexsnap_setup()
{
    echo "**** Executing vplexsnap setup"
    vplex_setup
}

vplexsnap_tests()
{
    echo "**** Executing VPLEX snapshot export tests"

    hname=$(hostname)
    if [ $hname = "standalone" ]; then
        hname=$SHORTENED_HOST
    fi
    echo "hostname is $hname"

    localVolume=$hname-${RANDOM}-VPlexLocal1
    localSnapshot=$hname-${RANDOM}-VPlexLocalSnap
    host=$PROJECT.lss.emc.com
    hostLbl=$PROJECT
    PWWN1=10:00:00:E0:7E:00:00:0F
    WWNN1=20:00:00:E0:7E:00:00:0F
    PWWN2=10:00:00:90:FA:18:0E:99
    WWNN2=20:00:00:90:FA:18:0E:99

    echo "**** Creating source VPLEX local volume"
    run volume create $localVolume $PROJECT $NH cosvplexlocal $BLK_SIZE

    echo "**** Creating VPLEX snapshot for source"
    run blocksnapshot create $PROJECT/$localVolume $localSnapshot
    blocksnapshot list $PROJECT/$localVolume
    blocksnapshot show $PROJECT/$localVolume/$localSnapshot

    echo "**** Creating VPLEX volume from snapshot"
    blocksnapshot expose $PROJECT/$localVolume/$localSnapshot

    echo "**** Creating host"
    hosts create $hostLbl $TENANT Windows $host --port 8111 --username user --password 'password' --osversion 1.0

    echo "**** Creating initiators"
    initiator create $hostLbl FC $PWWN1 --node $WWNN1
    initiator create $hostLbl FC $PWWN2 --node $WWNN2

    echo "**** Export VPLEX volume built from snapshot"
    run export_group create $PROJECT $hname-1$host $NH --volspec "$PROJECT/$localSnapshot+1" --inits "$hostLbl/$PWWN1","$hostLbl/$PWWN2"

    echo "**** Unexport VPLEX volume built from snapshot"
    run export_group delete $PROJECT/$hname-1$host

    echo "**** Deleting VPLEX volume built on snapshot"
    run volume delete $PROJECT/$localSnapshot --wait

    echo "**** Deleting snapshot"
    run blocksnapshot delete $PROJECT/$localVolume/$localSnapshot

    echo "**** Deleting source VPLEX local volume"
    run volume delete $PROJECT/$localVolume --wait

    echo "**** Deleting Host"
    hosts delete $hostLbl

    echo "**** Completed VPLEX snapshot export tests"
}

${SS}_setup
${SS}_tests

if [ $WS_SETUP_MODE -eq 1 ] ; then
    output_conf
fi

_success
